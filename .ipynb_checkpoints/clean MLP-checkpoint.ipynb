{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(dense_size, input_dim):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_size, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19445\n",
      "8676\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>h2s</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>n_points</th>\n",
       "      <th>so2</th>\n",
       "      <th>h2s_ref</th>\n",
       "      <th>captor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-23 09:15:00</td>\n",
       "      <td>1.673433</td>\n",
       "      <td>0.047316</td>\n",
       "      <td>0.996046</td>\n",
       "      <td>-1.610853</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.259294</td>\n",
       "      <td>-0.709240</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-05-23 10:30:00</td>\n",
       "      <td>1.530588</td>\n",
       "      <td>0.202130</td>\n",
       "      <td>0.996046</td>\n",
       "      <td>-1.677224</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.259294</td>\n",
       "      <td>-0.709240</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-05-23 13:15:00</td>\n",
       "      <td>1.637722</td>\n",
       "      <td>0.356944</td>\n",
       "      <td>0.996046</td>\n",
       "      <td>-1.809965</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.259294</td>\n",
       "      <td>-0.709240</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-05-23 14:30:00</td>\n",
       "      <td>1.655577</td>\n",
       "      <td>0.356944</td>\n",
       "      <td>0.996046</td>\n",
       "      <td>-1.809965</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.259294</td>\n",
       "      <td>-0.561424</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016-05-23 16:00:00</td>\n",
       "      <td>1.566299</td>\n",
       "      <td>0.356944</td>\n",
       "      <td>0.996046</td>\n",
       "      <td>-1.876336</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.259294</td>\n",
       "      <td>-0.709240</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date       h2s  pressure  temperature  humidity n_points  \\\n",
       "4   2016-05-23 09:15:00  1.673433  0.047316     0.996046 -1.610853       15   \n",
       "9   2016-05-23 10:30:00  1.530588  0.202130     0.996046 -1.677224       15   \n",
       "20  2016-05-23 13:15:00  1.637722  0.356944     0.996046 -1.809965       15   \n",
       "25  2016-05-23 14:30:00  1.655577  0.356944     0.996046 -1.809965       15   \n",
       "31  2016-05-23 16:00:00  1.566299  0.356944     0.996046 -1.876336       15   \n",
       "\n",
       "         so2   h2s_ref captor  \n",
       "4  -0.259294 -0.709240   1303  \n",
       "9  -0.259294 -0.709240   1303  \n",
       "20 -0.259294 -0.709240   1303  \n",
       "25 -0.259294 -0.561424   1303  \n",
       "31 -0.259294 -0.709240   1303  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement et normalisation des données\n",
    "df = pd.read_pickle('data/data.pkl')\n",
    "data = df[['h2s', 'pressure', 'temperature', 'humidity', 'so2', 'h2s_ref']]\n",
    "df[['h2s', 'pressure', 'temperature', 'humidity', 'so2', 'h2s_ref']] =  data.apply(pd.to_numeric, errors=\"coerce\").apply(lambda x: (x - np.mean(x)) / (np.std(x)))\n",
    "print(len(df))\n",
    "df = df[pd.notnull(df).all(axis=1)] # On ne garde que les données sans NaN etc..\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(dataframe, percent):\n",
    "    nb_rows = int(np.floor(percent * len(dataframe)))\n",
    "    return dataframe[:nb_rows], dataframe[nb_rows:]\n",
    "\n",
    "def dataframe_to_xy(df):\n",
    "    return np.array(df[['h2s', 'pressure', 'temperature', 'humidity', 'so2']]), np.array(df['h2s_ref'])\n",
    "\n",
    "df_train, df_test = split_dataframe(df, 0.5) \n",
    "df_valid, df_test = split_dataframe(df_test, 0.5)\n",
    "\n",
    "X_train, y_train = dataframe_to_xy(df_train)\n",
    "X_valid, y_valid = dataframe_to_xy(df_valid)\n",
    "X_test, y_test = dataframe_to_xy(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mpld3\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4338 samples, validate on 2169 samples\n",
      "Epoch 1/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.2320 - val_loss: 0.4562\n",
      "Epoch 2/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.2111 - val_loss: 0.4616\n",
      "Epoch 3/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.2024 - val_loss: 0.4808\n",
      "Epoch 4/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1992 - val_loss: 0.4733\n",
      "Epoch 5/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1981 - val_loss: 0.4795\n",
      "Epoch 6/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1975 - val_loss: 0.4650\n",
      "Epoch 7/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1980 - val_loss: 0.4695\n",
      "Epoch 8/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1970 - val_loss: 0.4699\n",
      "Epoch 9/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1970 - val_loss: 0.4588\n",
      "Epoch 10/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1965 - val_loss: 0.4777\n",
      "Epoch 11/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1958 - val_loss: 0.4516\n",
      "Epoch 12/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1950 - val_loss: 0.4695\n",
      "Epoch 13/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1942 - val_loss: 0.4638\n",
      "Epoch 14/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1943 - val_loss: 0.4579\n",
      "Epoch 15/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1935 - val_loss: 0.4727\n",
      "Epoch 16/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1934 - val_loss: 0.4663\n",
      "Epoch 17/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1930 - val_loss: 0.4508\n",
      "Epoch 18/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1926 - val_loss: 0.4529\n",
      "Epoch 19/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1916 - val_loss: 0.4656\n",
      "Epoch 20/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1910 - val_loss: 0.4667\n",
      "Epoch 21/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1901 - val_loss: 0.4410\n",
      "Epoch 22/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1896 - val_loss: 0.4669\n",
      "Epoch 23/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1892 - val_loss: 0.4704\n",
      "Epoch 24/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1887 - val_loss: 0.4453\n",
      "Epoch 25/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1879 - val_loss: 0.4561\n",
      "Epoch 26/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1872 - val_loss: 0.4533\n",
      "Epoch 27/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1869 - val_loss: 0.4449\n",
      "Epoch 28/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1866 - val_loss: 0.4528\n",
      "Epoch 29/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1866 - val_loss: 0.4555\n",
      "Epoch 30/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1864 - val_loss: 0.4399\n",
      "Epoch 31/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1859 - val_loss: 0.4353\n",
      "Epoch 32/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1860 - val_loss: 0.4598\n",
      "Epoch 33/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1848 - val_loss: 0.4486\n",
      "Epoch 34/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1846 - val_loss: 0.4563\n",
      "Epoch 35/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1835 - val_loss: 0.4547\n",
      "Epoch 36/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1842 - val_loss: 0.4625\n",
      "Epoch 37/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1838 - val_loss: 0.4449\n",
      "Epoch 38/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1833 - val_loss: 0.4563\n",
      "Epoch 39/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1838 - val_loss: 0.4575\n",
      "Epoch 40/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1834 - val_loss: 0.4373\n",
      "Epoch 41/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1835 - val_loss: 0.4701\n",
      "Epoch 42/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1834 - val_loss: 0.4701\n",
      "Epoch 00041: early stopping\n",
      "1965/2169 [==========================>...] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 4)                 24        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 29\n",
      "Trainable params: 29\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4338 samples, validate on 2169 samples\n",
      "Epoch 1/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.2325 - val_loss: 0.4906\n",
      "Epoch 2/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.2030 - val_loss: 0.4944\n",
      "Epoch 3/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1943 - val_loss: 0.4975\n",
      "Epoch 4/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1894 - val_loss: 0.4799\n",
      "Epoch 5/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1865 - val_loss: 0.4717\n",
      "Epoch 6/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1855 - val_loss: 0.4541\n",
      "Epoch 7/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1843 - val_loss: 0.4598\n",
      "Epoch 8/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1837 - val_loss: 0.4549\n",
      "Epoch 9/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1830 - val_loss: 0.4696\n",
      "Epoch 10/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1833 - val_loss: 0.4571\n",
      "Epoch 11/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1826 - val_loss: 0.4671\n",
      "Epoch 12/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1827 - val_loss: 0.4562\n",
      "Epoch 13/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1820 - val_loss: 0.4646\n",
      "Epoch 14/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1821 - val_loss: 0.4700\n",
      "Epoch 15/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1819 - val_loss: 0.4643\n",
      "Epoch 16/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1813 - val_loss: 0.4555\n",
      "Epoch 17/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1816 - val_loss: 0.4714\n",
      "Epoch 00016: early stopping\n",
      "1865/2169 [========================>.....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4338 samples, validate on 2169 samples\n",
      "Epoch 1/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.2212 - val_loss: 0.4566\n",
      "Epoch 2/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1964 - val_loss: 0.4836\n",
      "Epoch 3/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1915 - val_loss: 0.4431\n",
      "Epoch 4/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1898 - val_loss: 0.4689\n",
      "Epoch 5/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1886 - val_loss: 0.4461\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4338/4338 [==============================] - 2s - loss: 0.1872 - val_loss: 0.4402\n",
      "Epoch 7/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1854 - val_loss: 0.4632\n",
      "Epoch 8/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1838 - val_loss: 0.4365\n",
      "Epoch 9/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1830 - val_loss: 0.4432\n",
      "Epoch 10/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1824 - val_loss: 0.4430\n",
      "Epoch 11/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1813 - val_loss: 0.4279\n",
      "Epoch 12/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1806 - val_loss: 0.4614\n",
      "Epoch 13/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1800 - val_loss: 0.4554\n",
      "Epoch 14/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1794 - val_loss: 0.4483\n",
      "Epoch 15/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1785 - val_loss: 0.4370\n",
      "Epoch 16/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1790 - val_loss: 0.4381\n",
      "Epoch 17/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1782 - val_loss: 0.4561\n",
      "Epoch 18/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1780 - val_loss: 0.4396\n",
      "Epoch 19/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1777 - val_loss: 0.4549\n",
      "Epoch 20/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1770 - val_loss: 0.4314\n",
      "Epoch 21/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1768 - val_loss: 0.4247\n",
      "Epoch 22/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1763 - val_loss: 0.4355\n",
      "Epoch 23/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1764 - val_loss: 0.4460\n",
      "Epoch 24/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1757 - val_loss: 0.4350\n",
      "Epoch 25/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1755 - val_loss: 0.4505\n",
      "Epoch 26/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1753 - val_loss: 0.4196\n",
      "Epoch 27/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1744 - val_loss: 0.4430\n",
      "Epoch 28/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1742 - val_loss: 0.4360\n",
      "Epoch 29/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1740 - val_loss: 0.4457\n",
      "Epoch 30/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1740 - val_loss: 0.4435\n",
      "Epoch 31/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1737 - val_loss: 0.4402\n",
      "Epoch 32/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1733 - val_loss: 0.4399\n",
      "Epoch 33/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1731 - val_loss: 0.4495\n",
      "Epoch 34/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1724 - val_loss: 0.4440\n",
      "Epoch 35/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1726 - val_loss: 0.4581\n",
      "Epoch 36/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1720 - val_loss: 0.4596\n",
      "Epoch 37/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1712 - val_loss: 0.4249\n",
      "Epoch 00036: early stopping\n",
      "1900/2169 [=========================>....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 16)                96        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4338 samples, validate on 2169 samples\n",
      "Epoch 1/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.2156 - val_loss: 0.4657\n",
      "Epoch 2/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1925 - val_loss: 0.4478\n",
      "Epoch 3/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1853 - val_loss: 0.4626\n",
      "Epoch 4/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1817 - val_loss: 0.4405\n",
      "Epoch 5/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1789 - val_loss: 0.4234\n",
      "Epoch 6/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1768 - val_loss: 0.4229\n",
      "Epoch 7/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1746 - val_loss: 0.4278\n",
      "Epoch 8/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1737 - val_loss: 0.4184\n",
      "Epoch 9/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1715 - val_loss: 0.4210\n",
      "Epoch 10/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1710 - val_loss: 0.4211\n",
      "Epoch 11/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1699 - val_loss: 0.4380\n",
      "Epoch 12/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1690 - val_loss: 0.4020\n",
      "Epoch 13/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1680 - val_loss: 0.3885\n",
      "Epoch 14/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1679 - val_loss: 0.4182\n",
      "Epoch 15/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1659 - val_loss: 0.4178\n",
      "Epoch 16/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1643 - val_loss: 0.4260\n",
      "Epoch 17/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1643 - val_loss: 0.4427\n",
      "Epoch 18/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1623 - val_loss: 0.4256\n",
      "Epoch 19/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1609 - val_loss: 0.4291\n",
      "Epoch 20/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1597 - val_loss: 0.4049\n",
      "Epoch 21/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1588 - val_loss: 0.4475\n",
      "Epoch 22/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1581 - val_loss: 0.4376\n",
      "Epoch 23/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1558 - val_loss: 0.4422\n",
      "Epoch 24/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1556 - val_loss: 0.4412\n",
      "Epoch 00023: early stopping\n",
      "1845/2169 [========================>.....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 32)                192       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 225\n",
      "Trainable params: 225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4338 samples, validate on 2169 samples\n",
      "Epoch 1/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.2079 - val_loss: 0.4538\n",
      "Epoch 2/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1848 - val_loss: 0.4382\n",
      "Epoch 3/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1794 - val_loss: 0.4436\n",
      "Epoch 4/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1757 - val_loss: 0.4247\n",
      "Epoch 5/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1726 - val_loss: 0.4002\n",
      "Epoch 6/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1706 - val_loss: 0.4076\n",
      "Epoch 7/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1690 - val_loss: 0.4134\n",
      "Epoch 8/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1671 - val_loss: 0.4325\n",
      "Epoch 9/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1648 - val_loss: 0.4302\n",
      "Epoch 10/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1629 - val_loss: 0.4246\n",
      "Epoch 11/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1610 - val_loss: 0.4421\n",
      "Epoch 12/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1602 - val_loss: 0.4194\n",
      "Epoch 13/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1593 - val_loss: 0.4151\n",
      "Epoch 14/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1576 - val_loss: 0.4258\n",
      "Epoch 15/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1551 - val_loss: 0.4667\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4338/4338 [==============================] - 2s - loss: 0.1537 - val_loss: 0.4453\n",
      "Epoch 00015: early stopping\n",
      "2080/2169 [===========================>..] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 64)                384       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 449\n",
      "Trainable params: 449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4338 samples, validate on 2169 samples\n",
      "Epoch 1/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.2034 - val_loss: 0.4663\n",
      "Epoch 2/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1832 - val_loss: 0.4370\n",
      "Epoch 3/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1775 - val_loss: 0.4289\n",
      "Epoch 4/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1738 - val_loss: 0.4330\n",
      "Epoch 5/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1704 - val_loss: 0.3811\n",
      "Epoch 6/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1678 - val_loss: 0.4156\n",
      "Epoch 7/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1651 - val_loss: 0.4122\n",
      "Epoch 8/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1653 - val_loss: 0.4225\n",
      "Epoch 9/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1591 - val_loss: 0.4566\n",
      "Epoch 10/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1589 - val_loss: 0.4628\n",
      "Epoch 11/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1554 - val_loss: 0.4373\n",
      "Epoch 12/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1513 - val_loss: 0.4539\n",
      "Epoch 13/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1499 - val_loss: 0.4350\n",
      "Epoch 14/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1469 - val_loss: 0.4623\n",
      "Epoch 15/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1475 - val_loss: 0.4732\n",
      "Epoch 16/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1431 - val_loss: 0.4940\n",
      "Epoch 00015: early stopping\n",
      "1845/2169 [========================>.....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 128)               768       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 897\n",
      "Trainable params: 897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4338 samples, validate on 2169 samples\n",
      "Epoch 1/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1978 - val_loss: 0.4054\n",
      "Epoch 2/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1812 - val_loss: 0.4614\n",
      "Epoch 3/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1758 - val_loss: 0.3987\n",
      "Epoch 4/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1694 - val_loss: 0.4051\n",
      "Epoch 5/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1685 - val_loss: 0.4066\n",
      "Epoch 6/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1656 - val_loss: 0.4550\n",
      "Epoch 7/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1599 - val_loss: 0.4175\n",
      "Epoch 8/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1565 - val_loss: 0.4255\n",
      "Epoch 9/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1555 - val_loss: 0.4532\n",
      "Epoch 10/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1499 - val_loss: 0.3980\n",
      "Epoch 11/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1483 - val_loss: 0.4368\n",
      "Epoch 12/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1378 - val_loss: 0.4490\n",
      "Epoch 13/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1388 - val_loss: 0.4643\n",
      "Epoch 14/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1335 - val_loss: 0.4549\n",
      "Epoch 15/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1331 - val_loss: 0.4920\n",
      "Epoch 16/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1296 - val_loss: 0.4905\n",
      "Epoch 17/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1257 - val_loss: 0.4957\n",
      "Epoch 18/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1251 - val_loss: 0.4523\n",
      "Epoch 19/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1201 - val_loss: 0.4427\n",
      "Epoch 20/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1158 - val_loss: 0.4447\n",
      "Epoch 21/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1127 - val_loss: 0.4789\n",
      "Epoch 00020: early stopping\n",
      "1835/2169 [========================>.....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 256)               1536      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,793\n",
      "Trainable params: 1,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4338 samples, validate on 2169 samples\n",
      "Epoch 1/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1942 - val_loss: 0.3804\n",
      "Epoch 2/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1796 - val_loss: 0.4071\n",
      "Epoch 3/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1725 - val_loss: 0.4316\n",
      "Epoch 4/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1704 - val_loss: 0.4497\n",
      "Epoch 5/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1581 - val_loss: 0.4260\n",
      "Epoch 6/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1639 - val_loss: 0.4175\n",
      "Epoch 7/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1529 - val_loss: 0.5271\n",
      "Epoch 8/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1464 - val_loss: 0.4143\n",
      "Epoch 9/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1430 - val_loss: 0.4161\n",
      "Epoch 10/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1351 - val_loss: 0.5189\n",
      "Epoch 11/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1343 - val_loss: 0.4608\n",
      "Epoch 12/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1257 - val_loss: 0.4822\n",
      "Epoch 00011: early stopping\n",
      "1840/2169 [========================>.....] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 512)               3072      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,585\n",
      "Trainable params: 3,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4338 samples, validate on 2169 samples\n",
      "Epoch 1/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.2104 - val_loss: 0.4277\n",
      "Epoch 2/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1830 - val_loss: 0.4370\n",
      "Epoch 3/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1806 - val_loss: 0.4507\n",
      "Epoch 4/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1627 - val_loss: 0.4643\n",
      "Epoch 5/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1593 - val_loss: 0.4110\n",
      "Epoch 6/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1531 - val_loss: 0.4729\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4338/4338 [==============================] - 1s - loss: 0.1423 - val_loss: 0.4025\n",
      "Epoch 8/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1444 - val_loss: 0.4106\n",
      "Epoch 9/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1438 - val_loss: 0.4449\n",
      "Epoch 10/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1247 - val_loss: 0.4985\n",
      "Epoch 11/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1170 - val_loss: 0.4953\n",
      "Epoch 12/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1091 - val_loss: 0.5932\n",
      "Epoch 13/100\n",
      "4338/4338 [==============================] - 3s - loss: 0.1121 - val_loss: 0.5263\n",
      "Epoch 14/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.0979 - val_loss: 0.6116\n",
      "Epoch 15/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.0927 - val_loss: 0.6923\n",
      "Epoch 16/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.0940 - val_loss: 0.7850\n",
      "Epoch 17/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.0931 - val_loss: 0.6592\n",
      "Epoch 18/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.0872 - val_loss: 0.7512\n",
      "Epoch 00017: early stopping\n",
      "1975/2169 [==========================>...] - ETA: 0s_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 1024)              6144      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 7,169\n",
      "Trainable params: 7,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4338 samples, validate on 2169 samples\n",
      "Epoch 1/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.2306 - val_loss: 0.3876\n",
      "Epoch 2/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1879 - val_loss: 0.4376\n",
      "Epoch 3/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1743 - val_loss: 0.4552\n",
      "Epoch 4/100\n",
      "4338/4338 [==============================] - 3s - loss: 0.1560 - val_loss: 0.4211\n",
      "Epoch 5/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1633 - val_loss: 0.4644\n",
      "Epoch 6/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1497 - val_loss: 0.4576\n",
      "Epoch 7/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1338 - val_loss: 0.4714\n",
      "Epoch 8/100\n",
      "4338/4338 [==============================] - 2s - loss: 0.1191 - val_loss: 0.4604\n",
      "Epoch 9/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1162 - val_loss: 0.4550\n",
      "Epoch 10/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1113 - val_loss: 0.6052\n",
      "Epoch 11/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1009 - val_loss: 0.7354\n",
      "Epoch 12/100\n",
      "4338/4338 [==============================] - 1s - loss: 0.1018 - val_loss: 0.6816\n",
      "Epoch 00011: early stopping\n",
      "1790/2169 [=======================>......] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "p = 10\n",
    "input_dim = 5\n",
    "models_info = {}\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto', patience=10)\n",
    "tolerances = np.linspace(0, 1, 10)\n",
    "\n",
    "for i in range(p):\n",
    "    info_dict = {}\n",
    "\n",
    "    model = baseline_model(2**(i+1), input_dim)\n",
    "    info_dict['history'] = model.fit(X_train, y_train, batch_size=5, epochs=100, validation_data=(X_valid, y_valid), callbacks=[early_stopping], verbose=1)\n",
    "    \n",
    "    info_dict['score'] = model.evaluate(X_test, y_test, batch_size=5)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = []\n",
    "    for tol in tolerances:\n",
    "        y_tol = tol*y_train.flatten()\n",
    "        accur = np.sum(np.abs(y_pred.flatten() - y_test.flatten()) <= tol) / len(y_test)\n",
    "        acc.append(accur)\n",
    "    info_dict['accuracies'] = acc\n",
    "    models_info[2**(p+1)] = info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Env_QH.csv',\n",
       " 'micro_sud3.pkl',\n",
       " 'AllPM_QH.csv',\n",
       " 'micro_sud3_normalized.pkl',\n",
       " 'AllNO2_QH.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>PM_ref</th>\n",
       "      <th>PM_6182</th>\n",
       "      <th>PM_6179</th>\n",
       "      <th>PM_617B</th>\n",
       "      <th>PM25_6182</th>\n",
       "      <th>PM25_6179</th>\n",
       "      <th>PM25_617B</th>\n",
       "      <th>NO2_ref</th>\n",
       "      <th>NO2_61FD</th>\n",
       "      <th>NO2_61F0</th>\n",
       "      <th>NO2_61EF</th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "      <th>tgrad</th>\n",
       "      <th>pressure</th>\n",
       "      <th>pluvio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>2017-09-28 14:00:00</td>\n",
       "      <td>16.2</td>\n",
       "      <td>-1.178505</td>\n",
       "      <td>-1.137844</td>\n",
       "      <td>-1.134624</td>\n",
       "      <td>-1.183081</td>\n",
       "      <td>-1.128074</td>\n",
       "      <td>-1.148204</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.986031</td>\n",
       "      <td>-1.114144</td>\n",
       "      <td>-0.922393</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>2017-09-28 14:15:00</td>\n",
       "      <td>9.6</td>\n",
       "      <td>-1.108262</td>\n",
       "      <td>-1.085060</td>\n",
       "      <td>-1.121956</td>\n",
       "      <td>-1.101652</td>\n",
       "      <td>-1.071229</td>\n",
       "      <td>-1.128278</td>\n",
       "      <td>9.9</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>2.057032</td>\n",
       "      <td>-1.123212</td>\n",
       "      <td>-0.977185</td>\n",
       "      <td>0.335134</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>2017-09-28 14:30:00</td>\n",
       "      <td>10.3</td>\n",
       "      <td>-1.178505</td>\n",
       "      <td>-1.169515</td>\n",
       "      <td>-1.257077</td>\n",
       "      <td>-1.176817</td>\n",
       "      <td>-1.167865</td>\n",
       "      <td>-1.252817</td>\n",
       "      <td>16.1</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>2.080699</td>\n",
       "      <td>-1.232038</td>\n",
       "      <td>-1.086769</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2017-09-28 14:45:00</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-1.137530</td>\n",
       "      <td>-1.000606</td>\n",
       "      <td>-1.206407</td>\n",
       "      <td>-1.139235</td>\n",
       "      <td>-1.008700</td>\n",
       "      <td>-1.222928</td>\n",
       "      <td>10.9</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>2.009698</td>\n",
       "      <td>-1.259245</td>\n",
       "      <td>-0.812809</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2017-09-28 15:00:00</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-1.166798</td>\n",
       "      <td>-1.164236</td>\n",
       "      <td>-1.138846</td>\n",
       "      <td>-1.164290</td>\n",
       "      <td>-1.167865</td>\n",
       "      <td>-1.148204</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.867697</td>\n",
       "      <td>-1.141350</td>\n",
       "      <td>-0.922393</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                 date  PM_ref   PM_6182   PM_6179   PM_617B  \\\n",
       "0     15  2017-09-28 14:00:00    16.2 -1.178505 -1.137844 -1.134624   \n",
       "1     16  2017-09-28 14:15:00     9.6 -1.108262 -1.085060 -1.121956   \n",
       "2     17  2017-09-28 14:30:00    10.3 -1.178505 -1.169515 -1.257077   \n",
       "3     18  2017-09-28 14:45:00     9.4 -1.137530 -1.000606 -1.206407   \n",
       "4     19  2017-09-28 15:00:00    10.7 -1.166798 -1.164236 -1.138846   \n",
       "\n",
       "   PM25_6182  PM25_6179  PM25_617B  NO2_ref  NO2_61FD  NO2_61F0  NO2_61EF  \\\n",
       "0  -1.183081  -1.128074  -1.148204     10.1 -0.392423 -0.621107 -0.419097   \n",
       "1  -1.101652  -1.071229  -1.128278      9.9 -0.392423 -0.621107 -0.419097   \n",
       "2  -1.176817  -1.167865  -1.252817     16.1 -0.392423 -0.621107 -0.419097   \n",
       "3  -1.139235  -1.008700  -1.222928     10.9 -0.392423 -0.621107 -0.419097   \n",
       "4  -1.164290  -1.167865  -1.148204     16.0 -0.392423 -0.621107 -0.419097   \n",
       "\n",
       "       temp        rh     tgrad  pressure    pluvio  \n",
       "0  1.986031 -1.114144 -0.922393  0.315942 -0.150524  \n",
       "1  2.057032 -1.123212 -0.977185  0.335134 -0.150524  \n",
       "2  2.080699 -1.232038 -1.086769  0.315942 -0.150524  \n",
       "3  2.009698 -1.259245 -0.812809  0.315942 -0.150524  \n",
       "4  1.867697 -1.141350 -0.922393  0.315942 -0.150524  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/micro_sud3_normalized.pkl')\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[['date', 'NO2_ref', 'NO2_61FD', 'NO2_61F0', \\\n",
    "        'NO2_61EF', 'temp', 'rh', 'tgrad', 'pressure', 'pluvio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premier mod√®le: simple DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def baseline_model(dense_size, input_dim, loss='mean_squared_error', optimizer='adagrad'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_size, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "def split_dataframe(dataframe, percent):\n",
    "    nb_rows = int(np.floor(percent * len(dataframe)))\n",
    "    return dataframe[:nb_rows], dataframe[nb_rows:]\n",
    "\n",
    "def dataframe_to_xy(df):\n",
    "    return (np.array(df[['NO2_61FD', 'NO2_61F0', 'NO2_61EF', 'temp', 'rh',\\\n",
    "                         'tgrad', 'pressure', 'pluvio']]),\\\n",
    "            np.array(df['NO2_ref']))\n",
    "\n",
    "df_train, df_test = split_dataframe(df, 0.5) \n",
    "df_valid, df_test = split_dataframe(df_test, 0.5)\n",
    "\n",
    "X_train, y_train = dataframe_to_xy(df_train)\n",
    "X_valid, y_valid = dataframe_to_xy(df_valid)\n",
    "X_test, y_test = dataframe_to_xy(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1P6OqwFkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109b95c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK4qiLBwVekVRlIWjQq8oirJw/j/tXz+r77au/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114e82a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKQjtB5b4mBgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114fa4f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_train, '+r')\n",
    "plt.show()\n",
    "plt.plot(y_valid, '+r')\n",
    "plt.show()\n",
    "plt.plot(y_test, '+r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 321\n",
      "Trainable params: 321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1126 samples, validate on 563 samples\n",
      "Epoch 1/5000\n",
      "1126/1126 [==============================] - 0s - loss: 2753.0036 - val_loss: 2594.1590\n",
      "Epoch 2/5000\n",
      "1126/1126 [==============================] - 0s - loss: 2608.6199 - val_loss: 2451.8798\n",
      "Epoch 3/5000\n",
      "1126/1126 [==============================] - 0s - loss: 2450.4007 - val_loss: 2300.3313\n",
      "Epoch 4/5000\n",
      "1126/1126 [==============================] - 0s - loss: 2291.1062 - val_loss: 2155.0957\n",
      "Epoch 5/5000\n",
      "1126/1126 [==============================] - 0s - loss: 2137.8825 - val_loss: 2018.1463\n",
      "Epoch 6/5000\n",
      "1126/1126 [==============================] - 0s - loss: 1994.4058 - val_loss: 1886.9588\n",
      "Epoch 7/5000\n",
      "1126/1126 [==============================] - 0s - loss: 1857.5324 - val_loss: 1763.8126\n",
      "Epoch 8/5000\n",
      "1126/1126 [==============================] - 0s - loss: 1729.0460 - val_loss: 1648.4319\n",
      "Epoch 9/5000\n",
      "1126/1126 [==============================] - 0s - loss: 1609.4884 - val_loss: 1541.5241\n",
      "Epoch 10/5000\n",
      "1126/1126 [==============================] - 0s - loss: 1498.5573 - val_loss: 1441.4947\n",
      "Epoch 11/5000\n",
      "1126/1126 [==============================] - 0s - loss: 1395.8125 - val_loss: 1346.3600\n",
      "Epoch 12/5000\n",
      "1126/1126 [==============================] - 0s - loss: 1297.9874 - val_loss: 1259.5043\n",
      "Epoch 13/5000\n",
      "1126/1126 [==============================] - 0s - loss: 1209.1966 - val_loss: 1177.1505\n",
      "Epoch 14/5000\n",
      "1126/1126 [==============================] - 0s - loss: 1125.5010 - val_loss: 1104.6726\n",
      "Epoch 15/5000\n",
      "1126/1126 [==============================] - 0s - loss: 1051.8605 - val_loss: 1037.4168\n",
      "Epoch 16/5000\n",
      "1126/1126 [==============================] - 0s - loss: 983.9999 - val_loss: 976.9353\n",
      "Epoch 17/5000\n",
      "1126/1126 [==============================] - 0s - loss: 923.3386 - val_loss: 920.9180\n",
      "Epoch 18/5000\n",
      "1126/1126 [==============================] - 0s - loss: 867.1370 - val_loss: 867.9209\n",
      "Epoch 19/5000\n",
      "1126/1126 [==============================] - 0s - loss: 814.4826 - val_loss: 821.2937\n",
      "Epoch 20/5000\n",
      "1126/1126 [==============================] - 0s - loss: 768.4499 - val_loss: 777.7790\n",
      "Epoch 21/5000\n",
      "1126/1126 [==============================] - 0s - loss: 725.5476 - val_loss: 738.9156\n",
      "Epoch 22/5000\n",
      "1126/1126 [==============================] - 0s - loss: 687.4990 - val_loss: 703.4658\n",
      "Epoch 23/5000\n",
      "1126/1126 [==============================] - 0s - loss: 652.9403 - val_loss: 670.2645\n",
      "Epoch 24/5000\n",
      "1126/1126 [==============================] - 0s - loss: 620.8378 - val_loss: 640.1517\n",
      "Epoch 25/5000\n",
      "1126/1126 [==============================] - 0s - loss: 591.8701 - val_loss: 612.5597\n",
      "Epoch 26/5000\n",
      "1126/1126 [==============================] - 0s - loss: 565.5307 - val_loss: 587.9239\n",
      "Epoch 27/5000\n",
      "1126/1126 [==============================] - 0s - loss: 542.1108 - val_loss: 565.9523\n",
      "Epoch 28/5000\n",
      "1126/1126 [==============================] - 0s - loss: 521.3184 - val_loss: 544.9555\n",
      "Epoch 29/5000\n",
      "1126/1126 [==============================] - 0s - loss: 501.6574 - val_loss: 526.7648\n",
      "Epoch 30/5000\n",
      "1126/1126 [==============================] - 0s - loss: 484.6001 - val_loss: 510.1815\n",
      "Epoch 31/5000\n",
      "1126/1126 [==============================] - 0s - loss: 469.1854 - val_loss: 495.2662\n",
      "Epoch 32/5000\n",
      "1126/1126 [==============================] - 0s - loss: 455.3382 - val_loss: 481.4959\n",
      "Epoch 33/5000\n",
      "1126/1126 [==============================] - 0s - loss: 442.6800 - val_loss: 468.9802\n",
      "Epoch 34/5000\n",
      "1126/1126 [==============================] - 0s - loss: 431.2545 - val_loss: 457.3656\n",
      "Epoch 35/5000\n",
      "1126/1126 [==============================] - 0s - loss: 420.6383 - val_loss: 447.0098\n",
      "Epoch 36/5000\n",
      "1126/1126 [==============================] - 0s - loss: 411.2385 - val_loss: 437.3508\n",
      "Epoch 37/5000\n",
      "1126/1126 [==============================] - 0s - loss: 402.5064 - val_loss: 428.4351\n",
      "Epoch 38/5000\n",
      "1126/1126 [==============================] - 0s - loss: 394.5576 - val_loss: 420.4844\n",
      "Epoch 39/5000\n",
      "1126/1126 [==============================] - 0s - loss: 387.4709 - val_loss: 413.6845\n",
      "Epoch 40/5000\n",
      "1126/1126 [==============================] - 0s - loss: 381.3187 - val_loss: 406.5709\n",
      "Epoch 41/5000\n",
      "1126/1126 [==============================] - 0s - loss: 374.9748 - val_loss: 400.1640\n",
      "Epoch 42/5000\n",
      "1126/1126 [==============================] - 0s - loss: 369.3011 - val_loss: 394.1454\n",
      "Epoch 43/5000\n",
      "1126/1126 [==============================] - 0s - loss: 363.9485 - val_loss: 388.3811\n",
      "Epoch 44/5000\n",
      "1126/1126 [==============================] - 0s - loss: 358.8567 - val_loss: 383.2177\n",
      "Epoch 45/5000\n",
      "1126/1126 [==============================] - 0s - loss: 354.2667 - val_loss: 378.2838\n",
      "Epoch 46/5000\n",
      "1126/1126 [==============================] - 0s - loss: 349.9300 - val_loss: 373.8972\n",
      "Epoch 47/5000\n",
      "1126/1126 [==============================] - 0s - loss: 346.0259 - val_loss: 369.3723\n",
      "Epoch 48/5000\n",
      "1126/1126 [==============================] - 0s - loss: 342.0725 - val_loss: 365.1952\n",
      "Epoch 49/5000\n",
      "1126/1126 [==============================] - 0s - loss: 338.4027 - val_loss: 361.3493\n",
      "Epoch 50/5000\n",
      "1126/1126 [==============================] - 0s - loss: 335.0194 - val_loss: 357.5851\n",
      "Epoch 51/5000\n",
      "1126/1126 [==============================] - 0s - loss: 331.6742 - val_loss: 354.0116\n",
      "Epoch 52/5000\n",
      "1126/1126 [==============================] - 0s - loss: 328.5146 - val_loss: 350.4025\n",
      "Epoch 53/5000\n",
      "1126/1126 [==============================] - 0s - loss: 325.3845 - val_loss: 347.0452\n",
      "Epoch 54/5000\n",
      "1126/1126 [==============================] - 0s - loss: 322.4082 - val_loss: 343.9026\n",
      "Epoch 55/5000\n",
      "1126/1126 [==============================] - 0s - loss: 319.6712 - val_loss: 340.8644\n",
      "Epoch 56/5000\n",
      "1126/1126 [==============================] - 0s - loss: 316.9462 - val_loss: 337.8790\n",
      "Epoch 57/5000\n",
      "1126/1126 [==============================] - 0s - loss: 314.3319 - val_loss: 335.0708\n",
      "Epoch 58/5000\n",
      "1126/1126 [==============================] - 0s - loss: 311.8017 - val_loss: 332.1902\n",
      "Epoch 59/5000\n",
      "1126/1126 [==============================] - 0s - loss: 309.2407 - val_loss: 329.5145\n",
      "Epoch 60/5000\n",
      "1126/1126 [==============================] - 0s - loss: 306.8127 - val_loss: 326.9437\n",
      "Epoch 61/5000\n",
      "1126/1126 [==============================] - 0s - loss: 304.5133 - val_loss: 324.3200\n",
      "Epoch 62/5000\n",
      "1126/1126 [==============================] - 0s - loss: 302.1875 - val_loss: 321.8066\n",
      "Epoch 63/5000\n",
      "1126/1126 [==============================] - 0s - loss: 299.8822 - val_loss: 319.3908\n",
      "Epoch 64/5000\n",
      "1126/1126 [==============================] - 0s - loss: 297.7289 - val_loss: 316.9497\n",
      "Epoch 65/5000\n",
      "1126/1126 [==============================] - 0s - loss: 295.5471 - val_loss: 314.5574\n",
      "Epoch 66/5000\n",
      "1126/1126 [==============================] - 0s - loss: 293.4240 - val_loss: 312.1746\n",
      "Epoch 67/5000\n",
      "1126/1126 [==============================] - 0s - loss: 291.2841 - val_loss: 309.7719\n",
      "Epoch 68/5000\n",
      "1126/1126 [==============================] - 0s - loss: 289.1314 - val_loss: 307.5622\n",
      "Epoch 69/5000\n",
      "1126/1126 [==============================] - 0s - loss: 287.1217 - val_loss: 305.3340\n",
      "Epoch 70/5000\n",
      "1126/1126 [==============================] - 0s - loss: 285.1292 - val_loss: 303.1647\n",
      "Epoch 71/5000\n",
      "1126/1126 [==============================] - 0s - loss: 283.1624 - val_loss: 301.0137\n",
      "Epoch 72/5000\n",
      "1126/1126 [==============================] - 0s - loss: 281.2078 - val_loss: 298.8680\n",
      "Epoch 73/5000\n",
      "1126/1126 [==============================] - 0s - loss: 279.2866 - val_loss: 296.6980\n",
      "Epoch 74/5000\n",
      "1126/1126 [==============================] - 0s - loss: 277.3257 - val_loss: 294.5996\n",
      "Epoch 75/5000\n",
      "1126/1126 [==============================] - 0s - loss: 275.3974 - val_loss: 292.3695\n",
      "Epoch 76/5000\n",
      "1126/1126 [==============================] - 0s - loss: 273.3734 - val_loss: 290.2978\n",
      "Epoch 77/5000\n",
      "1126/1126 [==============================] - 0s - loss: 271.4952 - val_loss: 288.2794\n",
      "Epoch 78/5000\n",
      "1126/1126 [==============================] - 0s - loss: 269.6928 - val_loss: 286.3443\n",
      "Epoch 79/5000\n",
      "1126/1126 [==============================] - 0s - loss: 267.9175 - val_loss: 284.4502\n",
      "Epoch 80/5000\n",
      "1126/1126 [==============================] - 0s - loss: 266.1596 - val_loss: 282.5192\n",
      "Epoch 81/5000\n",
      "1126/1126 [==============================] - 0s - loss: 264.4070 - val_loss: 280.6173\n",
      "Epoch 82/5000\n",
      "1126/1126 [==============================] - 0s - loss: 262.6643 - val_loss: 278.8554\n",
      "Epoch 83/5000\n",
      "1126/1126 [==============================] - 0s - loss: 260.9367 - val_loss: 277.0018\n",
      "Epoch 84/5000\n",
      "1126/1126 [==============================] - 0s - loss: 259.2378 - val_loss: 275.1340\n",
      "Epoch 85/5000\n",
      "1126/1126 [==============================] - 0s - loss: 257.5550 - val_loss: 273.2150\n",
      "Epoch 86/5000\n",
      "1126/1126 [==============================] - 0s - loss: 255.8436 - val_loss: 271.4148\n",
      "Epoch 87/5000\n",
      "1126/1126 [==============================] - 0s - loss: 254.2262 - val_loss: 269.5627\n",
      "Epoch 88/5000\n",
      "1126/1126 [==============================] - 0s - loss: 252.5731 - val_loss: 267.8616\n",
      "Epoch 89/5000\n",
      "1126/1126 [==============================] - 0s - loss: 250.8860 - val_loss: 266.1246\n",
      "Epoch 90/5000\n",
      "1126/1126 [==============================] - 0s - loss: 249.3048 - val_loss: 264.3559\n",
      "Epoch 91/5000\n",
      "1126/1126 [==============================] - 0s - loss: 247.7167 - val_loss: 262.6442\n",
      "Epoch 92/5000\n",
      "1126/1126 [==============================] - 0s - loss: 246.1517 - val_loss: 260.9156\n",
      "Epoch 93/5000\n",
      "1126/1126 [==============================] - 0s - loss: 244.6038 - val_loss: 259.2431\n",
      "Epoch 94/5000\n",
      "1126/1126 [==============================] - 0s - loss: 243.0920 - val_loss: 257.5901\n",
      "Epoch 95/5000\n",
      "1126/1126 [==============================] - 0s - loss: 241.5974 - val_loss: 255.9120\n",
      "Epoch 96/5000\n",
      "1126/1126 [==============================] - 0s - loss: 240.0624 - val_loss: 254.2598\n",
      "Epoch 97/5000\n",
      "1126/1126 [==============================] - 0s - loss: 238.5779 - val_loss: 252.7286\n",
      "Epoch 98/5000\n",
      "1126/1126 [==============================] - 0s - loss: 237.1030 - val_loss: 251.1220\n",
      "Epoch 99/5000\n",
      "1126/1126 [==============================] - 0s - loss: 235.6542 - val_loss: 249.5392\n",
      "Epoch 100/5000\n",
      "1126/1126 [==============================] - 0s - loss: 234.1867 - val_loss: 247.9370\n",
      "Epoch 101/5000\n",
      "1126/1126 [==============================] - 0s - loss: 232.7346 - val_loss: 246.3781\n",
      "Epoch 102/5000\n",
      "1126/1126 [==============================] - 0s - loss: 231.3209 - val_loss: 244.8623\n",
      "Epoch 103/5000\n",
      "1126/1126 [==============================] - 0s - loss: 229.9096 - val_loss: 243.2927\n",
      "Epoch 104/5000\n",
      "1126/1126 [==============================] - 0s - loss: 228.5173 - val_loss: 241.7599\n",
      "Epoch 105/5000\n",
      "1126/1126 [==============================] - 0s - loss: 227.1628 - val_loss: 240.2653\n",
      "Epoch 106/5000\n",
      "1126/1126 [==============================] - 0s - loss: 225.7755 - val_loss: 238.7922\n",
      "Epoch 107/5000\n",
      "1126/1126 [==============================] - 0s - loss: 224.4450 - val_loss: 237.3497\n",
      "Epoch 108/5000\n",
      "1126/1126 [==============================] - 0s - loss: 223.1301 - val_loss: 235.8705\n",
      "Epoch 109/5000\n",
      "1126/1126 [==============================] - 0s - loss: 221.7906 - val_loss: 234.4214\n",
      "Epoch 110/5000\n",
      "1126/1126 [==============================] - 0s - loss: 220.4790 - val_loss: 233.0208\n",
      "Epoch 111/5000\n",
      "1126/1126 [==============================] - 0s - loss: 219.2105 - val_loss: 231.5872\n",
      "Epoch 112/5000\n",
      "1126/1126 [==============================] - 0s - loss: 217.9235 - val_loss: 230.2369\n",
      "Epoch 113/5000\n",
      "1126/1126 [==============================] - 0s - loss: 216.7228 - val_loss: 228.8977\n",
      "Epoch 114/5000\n",
      "1126/1126 [==============================] - 0s - loss: 215.4936 - val_loss: 227.5527\n",
      "Epoch 115/5000\n",
      "1126/1126 [==============================] - 0s - loss: 214.2912 - val_loss: 226.2484\n",
      "Epoch 116/5000\n",
      "1126/1126 [==============================] - 0s - loss: 213.0926 - val_loss: 224.9584\n",
      "Epoch 117/5000\n",
      "1126/1126 [==============================] - 0s - loss: 211.9099 - val_loss: 223.6172\n",
      "Epoch 118/5000\n",
      "1126/1126 [==============================] - 0s - loss: 210.7103 - val_loss: 222.3196\n",
      "Epoch 119/5000\n",
      "1126/1126 [==============================] - 0s - loss: 209.4841 - val_loss: 221.0629\n",
      "Epoch 120/5000\n",
      "1126/1126 [==============================] - 0s - loss: 208.3277 - val_loss: 219.8182\n",
      "Epoch 121/5000\n",
      "1126/1126 [==============================] - 0s - loss: 207.1717 - val_loss: 218.4133\n",
      "Epoch 122/5000\n",
      "1126/1126 [==============================] - 0s - loss: 205.9294 - val_loss: 217.1770\n",
      "Epoch 123/5000\n",
      "1126/1126 [==============================] - 0s - loss: 204.8149 - val_loss: 215.9763\n",
      "Epoch 124/5000\n",
      "1126/1126 [==============================] - 0s - loss: 203.7248 - val_loss: 214.6504\n",
      "Epoch 125/5000\n",
      "1126/1126 [==============================] - 0s - loss: 202.5494 - val_loss: 213.5085\n",
      "Epoch 126/5000\n",
      "1126/1126 [==============================] - 0s - loss: 201.4954 - val_loss: 212.2378\n",
      "Epoch 127/5000\n",
      "1126/1126 [==============================] - 0s - loss: 200.3726 - val_loss: 211.0540\n",
      "Epoch 128/5000\n",
      "1126/1126 [==============================] - 0s - loss: 199.2944 - val_loss: 209.9258\n",
      "Epoch 129/5000\n",
      "1126/1126 [==============================] - 0s - loss: 198.2467 - val_loss: 208.7908\n",
      "Epoch 130/5000\n",
      "1126/1126 [==============================] - 0s - loss: 197.2063 - val_loss: 207.6999\n",
      "Epoch 131/5000\n",
      "1126/1126 [==============================] - 0s - loss: 196.1848 - val_loss: 206.5958\n",
      "Epoch 132/5000\n",
      "1126/1126 [==============================] - 0s - loss: 195.1572 - val_loss: 205.4845\n",
      "Epoch 133/5000\n",
      "1126/1126 [==============================] - 0s - loss: 194.1553 - val_loss: 204.4468\n",
      "Epoch 134/5000\n",
      "1126/1126 [==============================] - 0s - loss: 193.1323 - val_loss: 203.3804\n",
      "Epoch 135/5000\n",
      "1126/1126 [==============================] - 0s - loss: 192.1741 - val_loss: 202.3299\n",
      "Epoch 136/5000\n",
      "1126/1126 [==============================] - 0s - loss: 191.1678 - val_loss: 201.2970\n",
      "Epoch 137/5000\n",
      "1126/1126 [==============================] - 0s - loss: 190.2046 - val_loss: 200.2956\n",
      "Epoch 138/5000\n",
      "1126/1126 [==============================] - 0s - loss: 189.2839 - val_loss: 199.2837\n",
      "Epoch 139/5000\n",
      "1126/1126 [==============================] - 0s - loss: 188.3486 - val_loss: 198.3192\n",
      "Epoch 140/5000\n",
      "1126/1126 [==============================] - 0s - loss: 187.4417 - val_loss: 197.3759\n",
      "Epoch 141/5000\n",
      "1126/1126 [==============================] - 0s - loss: 186.5323 - val_loss: 196.4286\n",
      "Epoch 142/5000\n",
      "1126/1126 [==============================] - 0s - loss: 185.6577 - val_loss: 195.5392\n",
      "Epoch 143/5000\n",
      "1126/1126 [==============================] - 0s - loss: 184.7556 - val_loss: 194.5778\n",
      "Epoch 144/5000\n",
      "1126/1126 [==============================] - 0s - loss: 183.8898 - val_loss: 193.6594\n",
      "Epoch 145/5000\n",
      "1126/1126 [==============================] - 0s - loss: 183.0559 - val_loss: 192.7003\n",
      "Epoch 146/5000\n",
      "1126/1126 [==============================] - 0s - loss: 182.1656 - val_loss: 191.8045\n",
      "Epoch 147/5000\n",
      "1126/1126 [==============================] - 0s - loss: 181.3194 - val_loss: 190.9111\n",
      "Epoch 148/5000\n",
      "1126/1126 [==============================] - 0s - loss: 180.4775 - val_loss: 190.0303\n",
      "Epoch 149/5000\n",
      "1126/1126 [==============================] - 0s - loss: 179.6448 - val_loss: 189.1363\n",
      "Epoch 150/5000\n",
      "1126/1126 [==============================] - 0s - loss: 178.7742 - val_loss: 188.2564\n",
      "Epoch 151/5000\n",
      "1126/1126 [==============================] - 0s - loss: 177.9475 - val_loss: 187.3969\n",
      "Epoch 152/5000\n",
      "1126/1126 [==============================] - 0s - loss: 177.1283 - val_loss: 186.5548\n",
      "Epoch 153/5000\n",
      "1126/1126 [==============================] - 0s - loss: 176.2796 - val_loss: 185.7166\n",
      "Epoch 154/5000\n",
      "1126/1126 [==============================] - 0s - loss: 175.4840 - val_loss: 184.8880\n",
      "Epoch 155/5000\n",
      "1126/1126 [==============================] - 0s - loss: 174.6877 - val_loss: 184.0511\n",
      "Epoch 156/5000\n",
      "1126/1126 [==============================] - 0s - loss: 173.8941 - val_loss: 183.2735\n",
      "Epoch 157/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 173.1513 - val_loss: 182.4837\n",
      "Epoch 158/5000\n",
      "1126/1126 [==============================] - 0s - loss: 172.3854 - val_loss: 181.6891\n",
      "Epoch 159/5000\n",
      "1126/1126 [==============================] - 0s - loss: 171.6153 - val_loss: 180.8991\n",
      "Epoch 160/5000\n",
      "1126/1126 [==============================] - 0s - loss: 170.8697 - val_loss: 180.1159\n",
      "Epoch 161/5000\n",
      "1126/1126 [==============================] - 0s - loss: 170.1203 - val_loss: 179.3778\n",
      "Epoch 162/5000\n",
      "1126/1126 [==============================] - 0s - loss: 169.4060 - val_loss: 178.6325\n",
      "Epoch 163/5000\n",
      "1126/1126 [==============================] - 0s - loss: 168.6943 - val_loss: 177.8888\n",
      "Epoch 164/5000\n",
      "1126/1126 [==============================] - 0s - loss: 167.9817 - val_loss: 177.1666\n",
      "Epoch 165/5000\n",
      "1126/1126 [==============================] - 0s - loss: 167.2664 - val_loss: 176.4621\n",
      "Epoch 166/5000\n",
      "1126/1126 [==============================] - 0s - loss: 166.5824 - val_loss: 175.7717\n",
      "Epoch 167/5000\n",
      "1126/1126 [==============================] - 0s - loss: 165.8966 - val_loss: 175.0582\n",
      "Epoch 168/5000\n",
      "1126/1126 [==============================] - 0s - loss: 165.1988 - val_loss: 174.3789\n",
      "Epoch 169/5000\n",
      "1126/1126 [==============================] - 0s - loss: 164.5236 - val_loss: 173.7415\n",
      "Epoch 170/5000\n",
      "1126/1126 [==============================] - 0s - loss: 163.8535 - val_loss: 173.0752\n",
      "Epoch 171/5000\n",
      "1126/1126 [==============================] - 0s - loss: 163.1376 - val_loss: 172.3887\n",
      "Epoch 172/5000\n",
      "1126/1126 [==============================] - 0s - loss: 162.4310 - val_loss: 171.7160\n",
      "Epoch 173/5000\n",
      "1126/1126 [==============================] - 0s - loss: 161.7776 - val_loss: 171.0550\n",
      "Epoch 174/5000\n",
      "1126/1126 [==============================] - 0s - loss: 161.1340 - val_loss: 170.4197\n",
      "Epoch 175/5000\n",
      "1126/1126 [==============================] - 0s - loss: 160.5045 - val_loss: 169.7574\n",
      "Epoch 176/5000\n",
      "1126/1126 [==============================] - 0s - loss: 159.8596 - val_loss: 169.1554\n",
      "Epoch 177/5000\n",
      "1126/1126 [==============================] - 0s - loss: 159.2376 - val_loss: 168.5613\n",
      "Epoch 178/5000\n",
      "1126/1126 [==============================] - 0s - loss: 158.6274 - val_loss: 167.9465\n",
      "Epoch 179/5000\n",
      "1126/1126 [==============================] - 0s - loss: 158.0190 - val_loss: 167.3364\n",
      "Epoch 180/5000\n",
      "1126/1126 [==============================] - 0s - loss: 157.4256 - val_loss: 166.7777\n",
      "Epoch 181/5000\n",
      "1126/1126 [==============================] - 0s - loss: 156.7985 - val_loss: 166.1638\n",
      "Epoch 182/5000\n",
      "1126/1126 [==============================] - 0s - loss: 156.1890 - val_loss: 165.5698\n",
      "Epoch 183/5000\n",
      "1126/1126 [==============================] - 0s - loss: 155.6205 - val_loss: 164.9752\n",
      "Epoch 184/5000\n",
      "1126/1126 [==============================] - 0s - loss: 155.0244 - val_loss: 164.3805\n",
      "Epoch 185/5000\n",
      "1126/1126 [==============================] - 0s - loss: 154.4340 - val_loss: 163.7671\n",
      "Epoch 186/5000\n",
      "1126/1126 [==============================] - 0s - loss: 153.8342 - val_loss: 163.2158\n",
      "Epoch 187/5000\n",
      "1126/1126 [==============================] - 0s - loss: 153.2758 - val_loss: 162.6478\n",
      "Epoch 188/5000\n",
      "1126/1126 [==============================] - 0s - loss: 152.7082 - val_loss: 162.1127\n",
      "Epoch 189/5000\n",
      "1126/1126 [==============================] - 0s - loss: 152.1670 - val_loss: 161.5796\n",
      "Epoch 190/5000\n",
      "1126/1126 [==============================] - 0s - loss: 151.6141 - val_loss: 161.0773\n",
      "Epoch 191/5000\n",
      "1126/1126 [==============================] - 0s - loss: 151.0747 - val_loss: 160.5529\n",
      "Epoch 192/5000\n",
      "1126/1126 [==============================] - 0s - loss: 150.5386 - val_loss: 160.0358\n",
      "Epoch 193/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 150.704 - 0s - loss: 149.9978 - val_loss: 159.5341\n",
      "Epoch 194/5000\n",
      "1126/1126 [==============================] - 0s - loss: 149.4760 - val_loss: 159.0392\n",
      "Epoch 195/5000\n",
      "1126/1126 [==============================] - 0s - loss: 148.9593 - val_loss: 158.5611\n",
      "Epoch 196/5000\n",
      "1126/1126 [==============================] - 0s - loss: 148.4471 - val_loss: 158.0341\n",
      "Epoch 197/5000\n",
      "1126/1126 [==============================] - 0s - loss: 147.9200 - val_loss: 157.5450\n",
      "Epoch 198/5000\n",
      "1126/1126 [==============================] - 0s - loss: 147.4170 - val_loss: 157.0661\n",
      "Epoch 199/5000\n",
      "1126/1126 [==============================] - 0s - loss: 146.9106 - val_loss: 156.6315\n",
      "Epoch 200/5000\n",
      "1126/1126 [==============================] - 0s - loss: 146.4255 - val_loss: 156.1633\n",
      "Epoch 201/5000\n",
      "1126/1126 [==============================] - 0s - loss: 145.9424 - val_loss: 155.6791\n",
      "Epoch 202/5000\n",
      "1126/1126 [==============================] - 0s - loss: 145.4406 - val_loss: 155.2171\n",
      "Epoch 203/5000\n",
      "1126/1126 [==============================] - 0s - loss: 144.9675 - val_loss: 154.7646\n",
      "Epoch 204/5000\n",
      "1126/1126 [==============================] - 0s - loss: 144.4831 - val_loss: 154.3226\n",
      "Epoch 205/5000\n",
      "1126/1126 [==============================] - 0s - loss: 144.0205 - val_loss: 153.8882\n",
      "Epoch 206/5000\n",
      "1126/1126 [==============================] - 0s - loss: 143.5491 - val_loss: 153.4910\n",
      "Epoch 207/5000\n",
      "1126/1126 [==============================] - 0s - loss: 143.0796 - val_loss: 153.0764\n",
      "Epoch 208/5000\n",
      "1126/1126 [==============================] - 0s - loss: 142.6327 - val_loss: 152.6793\n",
      "Epoch 209/5000\n",
      "1126/1126 [==============================] - 0s - loss: 142.1553 - val_loss: 152.2392\n",
      "Epoch 210/5000\n",
      "1126/1126 [==============================] - 0s - loss: 141.7074 - val_loss: 151.8371\n",
      "Epoch 211/5000\n",
      "1126/1126 [==============================] - 0s - loss: 141.2776 - val_loss: 151.4308\n",
      "Epoch 212/5000\n",
      "1126/1126 [==============================] - 0s - loss: 140.8467 - val_loss: 151.0336\n",
      "Epoch 213/5000\n",
      "1126/1126 [==============================] - 0s - loss: 140.4159 - val_loss: 150.6560\n",
      "Epoch 214/5000\n",
      "1126/1126 [==============================] - 0s - loss: 140.0000 - val_loss: 150.2638\n",
      "Epoch 215/5000\n",
      "1126/1126 [==============================] - 0s - loss: 139.5755 - val_loss: 149.8754\n",
      "Epoch 216/5000\n",
      "1126/1126 [==============================] - 0s - loss: 139.1654 - val_loss: 149.5533\n",
      "Epoch 217/5000\n",
      "1126/1126 [==============================] - 0s - loss: 138.7612 - val_loss: 149.1952\n",
      "Epoch 218/5000\n",
      "1126/1126 [==============================] - 0s - loss: 138.3610 - val_loss: 148.8340\n",
      "Epoch 219/5000\n",
      "1126/1126 [==============================] - 0s - loss: 137.9622 - val_loss: 148.4814\n",
      "Epoch 220/5000\n",
      "1126/1126 [==============================] - 0s - loss: 137.5727 - val_loss: 148.1072\n",
      "Epoch 221/5000\n",
      "1126/1126 [==============================] - 0s - loss: 137.1708 - val_loss: 147.7540\n",
      "Epoch 222/5000\n",
      "1126/1126 [==============================] - 0s - loss: 136.7750 - val_loss: 147.4021\n",
      "Epoch 223/5000\n",
      "1126/1126 [==============================] - 0s - loss: 136.3867 - val_loss: 147.0214\n",
      "Epoch 224/5000\n",
      "1126/1126 [==============================] - 0s - loss: 135.9872 - val_loss: 146.6624\n",
      "Epoch 225/5000\n",
      "1126/1126 [==============================] - 0s - loss: 135.6021 - val_loss: 146.3553\n",
      "Epoch 226/5000\n",
      "1126/1126 [==============================] - 0s - loss: 135.2363 - val_loss: 146.0398\n",
      "Epoch 227/5000\n",
      "1126/1126 [==============================] - 0s - loss: 134.8768 - val_loss: 145.7529\n",
      "Epoch 228/5000\n",
      "1126/1126 [==============================] - 0s - loss: 134.5149 - val_loss: 145.4564\n",
      "Epoch 229/5000\n",
      "1126/1126 [==============================] - 0s - loss: 134.1758 - val_loss: 145.1296\n",
      "Epoch 230/5000\n",
      "1126/1126 [==============================] - 0s - loss: 133.8126 - val_loss: 144.8181\n",
      "Epoch 231/5000\n",
      "1126/1126 [==============================] - 0s - loss: 133.4626 - val_loss: 144.5080\n",
      "Epoch 232/5000\n",
      "1126/1126 [==============================] - 0s - loss: 133.0976 - val_loss: 144.2185\n",
      "Epoch 233/5000\n",
      "1126/1126 [==============================] - 0s - loss: 132.7526 - val_loss: 143.9278\n",
      "Epoch 234/5000\n",
      "1126/1126 [==============================] - 0s - loss: 132.3997 - val_loss: 143.6142\n",
      "Epoch 235/5000\n",
      "1126/1126 [==============================] - 0s - loss: 132.0615 - val_loss: 143.3403\n",
      "Epoch 236/5000\n",
      "1126/1126 [==============================] - 0s - loss: 131.7332 - val_loss: 143.0511\n",
      "Epoch 237/5000\n",
      "1126/1126 [==============================] - 0s - loss: 131.4024 - val_loss: 142.7926\n",
      "Epoch 238/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 131.0753 - val_loss: 142.5437\n",
      "Epoch 239/5000\n",
      "1126/1126 [==============================] - 0s - loss: 130.7626 - val_loss: 142.2908\n",
      "Epoch 240/5000\n",
      "1126/1126 [==============================] - 0s - loss: 130.4536 - val_loss: 142.0218\n",
      "Epoch 241/5000\n",
      "1126/1126 [==============================] - 0s - loss: 130.1450 - val_loss: 141.7893\n",
      "Epoch 242/5000\n",
      "1126/1126 [==============================] - 0s - loss: 129.8348 - val_loss: 141.5365\n",
      "Epoch 243/5000\n",
      "1126/1126 [==============================] - 0s - loss: 129.5291 - val_loss: 141.2837\n",
      "Epoch 244/5000\n",
      "1126/1126 [==============================] - 0s - loss: 129.2311 - val_loss: 141.0322\n",
      "Epoch 245/5000\n",
      "1126/1126 [==============================] - 0s - loss: 128.9279 - val_loss: 140.7593\n",
      "Epoch 246/5000\n",
      "1126/1126 [==============================] - 0s - loss: 128.6315 - val_loss: 140.5520\n",
      "Epoch 247/5000\n",
      "1126/1126 [==============================] - 0s - loss: 128.3398 - val_loss: 140.3052\n",
      "Epoch 248/5000\n",
      "1126/1126 [==============================] - 0s - loss: 128.0553 - val_loss: 140.0880\n",
      "Epoch 249/5000\n",
      "1126/1126 [==============================] - 0s - loss: 127.7653 - val_loss: 139.8689\n",
      "Epoch 250/5000\n",
      "1126/1126 [==============================] - 0s - loss: 127.4858 - val_loss: 139.6567\n",
      "Epoch 251/5000\n",
      "1126/1126 [==============================] - 0s - loss: 127.2143 - val_loss: 139.4208\n",
      "Epoch 252/5000\n",
      "1126/1126 [==============================] - 0s - loss: 126.9324 - val_loss: 139.1877\n",
      "Epoch 253/5000\n",
      "1126/1126 [==============================] - 0s - loss: 126.6659 - val_loss: 138.9747\n",
      "Epoch 254/5000\n",
      "1126/1126 [==============================] - 0s - loss: 126.4051 - val_loss: 138.7333\n",
      "Epoch 255/5000\n",
      "1126/1126 [==============================] - 0s - loss: 126.1320 - val_loss: 138.5035\n",
      "Epoch 256/5000\n",
      "1126/1126 [==============================] - 0s - loss: 125.8598 - val_loss: 138.3004\n",
      "Epoch 257/5000\n",
      "1126/1126 [==============================] - 0s - loss: 125.6060 - val_loss: 138.0930\n",
      "Epoch 258/5000\n",
      "1126/1126 [==============================] - 0s - loss: 125.3497 - val_loss: 137.9208\n",
      "Epoch 259/5000\n",
      "1126/1126 [==============================] - 0s - loss: 125.0923 - val_loss: 137.7050\n",
      "Epoch 260/5000\n",
      "1126/1126 [==============================] - 0s - loss: 124.8490 - val_loss: 137.4978\n",
      "Epoch 261/5000\n",
      "1126/1126 [==============================] - 0s - loss: 124.5982 - val_loss: 137.2965\n",
      "Epoch 262/5000\n",
      "1126/1126 [==============================] - 0s - loss: 124.3543 - val_loss: 137.1045\n",
      "Epoch 263/5000\n",
      "1126/1126 [==============================] - 0s - loss: 124.1151 - val_loss: 136.9185\n",
      "Epoch 264/5000\n",
      "1126/1126 [==============================] - 0s - loss: 123.8807 - val_loss: 136.7299\n",
      "Epoch 265/5000\n",
      "1126/1126 [==============================] - 0s - loss: 123.6456 - val_loss: 136.5451\n",
      "Epoch 266/5000\n",
      "1126/1126 [==============================] - 0s - loss: 123.4223 - val_loss: 136.3613\n",
      "Epoch 267/5000\n",
      "1126/1126 [==============================] - 0s - loss: 123.1925 - val_loss: 136.1857\n",
      "Epoch 268/5000\n",
      "1126/1126 [==============================] - 0s - loss: 122.9635 - val_loss: 136.0150\n",
      "Epoch 269/5000\n",
      "1126/1126 [==============================] - 0s - loss: 122.7453 - val_loss: 135.8610\n",
      "Epoch 270/5000\n",
      "1126/1126 [==============================] - 0s - loss: 122.5280 - val_loss: 135.6877\n",
      "Epoch 271/5000\n",
      "1126/1126 [==============================] - 0s - loss: 122.3157 - val_loss: 135.5292\n",
      "Epoch 272/5000\n",
      "1126/1126 [==============================] - 0s - loss: 122.1034 - val_loss: 135.3470\n",
      "Epoch 273/5000\n",
      "1126/1126 [==============================] - 0s - loss: 121.8969 - val_loss: 135.2003\n",
      "Epoch 274/5000\n",
      "1126/1126 [==============================] - 0s - loss: 121.6844 - val_loss: 135.0240\n",
      "Epoch 275/5000\n",
      "1126/1126 [==============================] - 0s - loss: 121.4697 - val_loss: 134.8494\n",
      "Epoch 276/5000\n",
      "1126/1126 [==============================] - 0s - loss: 121.2633 - val_loss: 134.6783\n",
      "Epoch 277/5000\n",
      "1126/1126 [==============================] - 0s - loss: 121.0550 - val_loss: 134.5146\n",
      "Epoch 278/5000\n",
      "1126/1126 [==============================] - 0s - loss: 120.8640 - val_loss: 134.3655\n",
      "Epoch 279/5000\n",
      "1126/1126 [==============================] - 0s - loss: 120.6641 - val_loss: 134.1901\n",
      "Epoch 280/5000\n",
      "1126/1126 [==============================] - 0s - loss: 120.4677 - val_loss: 134.0465\n",
      "Epoch 281/5000\n",
      "1126/1126 [==============================] - 0s - loss: 120.2757 - val_loss: 133.9080\n",
      "Epoch 282/5000\n",
      "1126/1126 [==============================] - 0s - loss: 120.0828 - val_loss: 133.8147\n",
      "Epoch 283/5000\n",
      "1126/1126 [==============================] - 0s - loss: 119.8967 - val_loss: 133.5795\n",
      "Epoch 284/5000\n",
      "1126/1126 [==============================] - 0s - loss: 119.7177 - val_loss: 133.4451\n",
      "Epoch 285/5000\n",
      "1126/1126 [==============================] - 0s - loss: 119.5306 - val_loss: 133.3162\n",
      "Epoch 286/5000\n",
      "1126/1126 [==============================] - 0s - loss: 119.3514 - val_loss: 133.1535\n",
      "Epoch 287/5000\n",
      "1126/1126 [==============================] - 0s - loss: 119.1607 - val_loss: 133.0081\n",
      "Epoch 288/5000\n",
      "1126/1126 [==============================] - 0s - loss: 118.9901 - val_loss: 132.8814\n",
      "Epoch 289/5000\n",
      "1126/1126 [==============================] - 0s - loss: 118.8134 - val_loss: 132.7434\n",
      "Epoch 290/5000\n",
      "1126/1126 [==============================] - 0s - loss: 118.6414 - val_loss: 132.6125\n",
      "Epoch 291/5000\n",
      "1126/1126 [==============================] - 0s - loss: 118.4743 - val_loss: 132.5007\n",
      "Epoch 292/5000\n",
      "1126/1126 [==============================] - 0s - loss: 118.2945 - val_loss: 132.3805\n",
      "Epoch 293/5000\n",
      "1126/1126 [==============================] - 0s - loss: 118.1371 - val_loss: 132.2546\n",
      "Epoch 294/5000\n",
      "1126/1126 [==============================] - 0s - loss: 117.9766 - val_loss: 132.1320\n",
      "Epoch 295/5000\n",
      "1126/1126 [==============================] - 0s - loss: 117.8166 - val_loss: 132.0097\n",
      "Epoch 296/5000\n",
      "1126/1126 [==============================] - 0s - loss: 117.6583 - val_loss: 131.8854\n",
      "Epoch 297/5000\n",
      "1126/1126 [==============================] - 0s - loss: 117.5040 - val_loss: 131.7566\n",
      "Epoch 298/5000\n",
      "1126/1126 [==============================] - 0s - loss: 117.3419 - val_loss: 131.6359\n",
      "Epoch 299/5000\n",
      "1126/1126 [==============================] - 0s - loss: 117.1801 - val_loss: 131.5280\n",
      "Epoch 300/5000\n",
      "1126/1126 [==============================] - 0s - loss: 117.0260 - val_loss: 131.4167\n",
      "Epoch 301/5000\n",
      "1126/1126 [==============================] - 0s - loss: 116.8740 - val_loss: 131.3494\n",
      "Epoch 302/5000\n",
      "1126/1126 [==============================] - 0s - loss: 116.7205 - val_loss: 131.2140\n",
      "Epoch 303/5000\n",
      "1126/1126 [==============================] - 0s - loss: 116.5730 - val_loss: 131.1261\n",
      "Epoch 304/5000\n",
      "1126/1126 [==============================] - 0s - loss: 116.4323 - val_loss: 131.0377\n",
      "Epoch 305/5000\n",
      "1126/1126 [==============================] - 0s - loss: 116.2885 - val_loss: 130.9286\n",
      "Epoch 306/5000\n",
      "1126/1126 [==============================] - 0s - loss: 116.1486 - val_loss: 130.8363\n",
      "Epoch 307/5000\n",
      "1126/1126 [==============================] - 0s - loss: 116.0021 - val_loss: 130.7363\n",
      "Epoch 308/5000\n",
      "1126/1126 [==============================] - 0s - loss: 115.8675 - val_loss: 130.6369\n",
      "Epoch 309/5000\n",
      "1126/1126 [==============================] - 0s - loss: 115.7251 - val_loss: 130.5666\n",
      "Epoch 310/5000\n",
      "1126/1126 [==============================] - 0s - loss: 115.5861 - val_loss: 130.4817\n",
      "Epoch 311/5000\n",
      "1126/1126 [==============================] - 0s - loss: 115.4511 - val_loss: 130.3908\n",
      "Epoch 312/5000\n",
      "1126/1126 [==============================] - 0s - loss: 115.3196 - val_loss: 130.3138\n",
      "Epoch 313/5000\n",
      "1126/1126 [==============================] - 0s - loss: 115.1889 - val_loss: 130.2013\n",
      "Epoch 314/5000\n",
      "1126/1126 [==============================] - 0s - loss: 115.0557 - val_loss: 130.0726\n",
      "Epoch 315/5000\n",
      "1126/1126 [==============================] - 0s - loss: 114.9192 - val_loss: 130.0176\n",
      "Epoch 316/5000\n",
      "1126/1126 [==============================] - 0s - loss: 114.7902 - val_loss: 129.9246\n",
      "Epoch 317/5000\n",
      "1126/1126 [==============================] - 0s - loss: 114.6645 - val_loss: 129.8289\n",
      "Epoch 318/5000\n",
      "1126/1126 [==============================] - 0s - loss: 114.5473 - val_loss: 129.7437\n",
      "Epoch 319/5000\n",
      "1126/1126 [==============================] - 0s - loss: 114.4144 - val_loss: 129.6666\n",
      "Epoch 320/5000\n",
      "1126/1126 [==============================] - 0s - loss: 114.2898 - val_loss: 129.5679\n",
      "Epoch 321/5000\n",
      "1126/1126 [==============================] - 0s - loss: 114.1785 - val_loss: 129.4614\n",
      "Epoch 322/5000\n",
      "1126/1126 [==============================] - 0s - loss: 114.0547 - val_loss: 129.3386\n",
      "Epoch 323/5000\n",
      "1126/1126 [==============================] - 0s - loss: 113.9440 - val_loss: 129.2547\n",
      "Epoch 324/5000\n",
      "1126/1126 [==============================] - 0s - loss: 113.8290 - val_loss: 129.1727\n",
      "Epoch 325/5000\n",
      "1126/1126 [==============================] - 0s - loss: 113.7176 - val_loss: 129.0856\n",
      "Epoch 326/5000\n",
      "1126/1126 [==============================] - 0s - loss: 113.6121 - val_loss: 128.9922\n",
      "Epoch 327/5000\n",
      "1126/1126 [==============================] - 0s - loss: 113.5047 - val_loss: 128.8829\n",
      "Epoch 328/5000\n",
      "1126/1126 [==============================] - 0s - loss: 113.3939 - val_loss: 128.7968\n",
      "Epoch 329/5000\n",
      "1126/1126 [==============================] - 0s - loss: 113.2946 - val_loss: 128.7063\n",
      "Epoch 330/5000\n",
      "1126/1126 [==============================] - 0s - loss: 113.1920 - val_loss: 128.6197\n",
      "Epoch 331/5000\n",
      "1126/1126 [==============================] - 0s - loss: 113.0814 - val_loss: 128.5384\n",
      "Epoch 332/5000\n",
      "1126/1126 [==============================] - 0s - loss: 112.9746 - val_loss: 128.4626\n",
      "Epoch 333/5000\n",
      "1126/1126 [==============================] - 0s - loss: 112.8726 - val_loss: 128.3965\n",
      "Epoch 334/5000\n",
      "1126/1126 [==============================] - 0s - loss: 112.7755 - val_loss: 128.3181\n",
      "Epoch 335/5000\n",
      "1126/1126 [==============================] - 0s - loss: 112.6733 - val_loss: 128.2409\n",
      "Epoch 336/5000\n",
      "1126/1126 [==============================] - 0s - loss: 112.5771 - val_loss: 128.1710\n",
      "Epoch 337/5000\n",
      "1126/1126 [==============================] - 0s - loss: 112.4734 - val_loss: 128.1060\n",
      "Epoch 338/5000\n",
      "1126/1126 [==============================] - 0s - loss: 112.3739 - val_loss: 128.0391\n",
      "Epoch 339/5000\n",
      "1126/1126 [==============================] - 0s - loss: 112.2821 - val_loss: 127.9550\n",
      "Epoch 340/5000\n",
      "1126/1126 [==============================] - 0s - loss: 112.1818 - val_loss: 127.8726\n",
      "Epoch 341/5000\n",
      "1126/1126 [==============================] - 0s - loss: 112.0722 - val_loss: 127.8163\n",
      "Epoch 342/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.9773 - val_loss: 127.7639\n",
      "Epoch 343/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.8823 - val_loss: 127.6667\n",
      "Epoch 344/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.7945 - val_loss: 127.5928\n",
      "Epoch 345/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.6971 - val_loss: 127.5052\n",
      "Epoch 346/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.6125 - val_loss: 127.4448\n",
      "Epoch 347/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.5161 - val_loss: 127.3575\n",
      "Epoch 348/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.4211 - val_loss: 127.3388\n",
      "Epoch 349/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.3332 - val_loss: 127.2674\n",
      "Epoch 350/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.2460 - val_loss: 127.1902\n",
      "Epoch 351/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.1610 - val_loss: 127.1130\n",
      "Epoch 352/5000\n",
      "1126/1126 [==============================] - 0s - loss: 111.0719 - val_loss: 127.0426\n",
      "Epoch 353/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.9911 - val_loss: 126.9517\n",
      "Epoch 354/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.9075 - val_loss: 126.8963\n",
      "Epoch 355/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.8255 - val_loss: 126.8253\n",
      "Epoch 356/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.7442 - val_loss: 126.7743\n",
      "Epoch 357/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.6625 - val_loss: 126.7010\n",
      "Epoch 358/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.5831 - val_loss: 126.6529\n",
      "Epoch 359/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.5038 - val_loss: 126.6009\n",
      "Epoch 360/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.4280 - val_loss: 126.5386\n",
      "Epoch 361/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.3492 - val_loss: 126.4508\n",
      "Epoch 362/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.2732 - val_loss: 126.4106\n",
      "Epoch 363/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.1939 - val_loss: 126.3644\n",
      "Epoch 364/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.1207 - val_loss: 126.3403\n",
      "Epoch 365/5000\n",
      "1126/1126 [==============================] - 0s - loss: 110.0440 - val_loss: 126.2831\n",
      "Epoch 366/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.9718 - val_loss: 126.2225\n",
      "Epoch 367/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.8934 - val_loss: 126.1314\n",
      "Epoch 368/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.8226 - val_loss: 126.0767\n",
      "Epoch 369/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.7492 - val_loss: 126.0129\n",
      "Epoch 370/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.6804 - val_loss: 125.9445\n",
      "Epoch 371/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.6051 - val_loss: 125.8867\n",
      "Epoch 372/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.5381 - val_loss: 125.8354\n",
      "Epoch 373/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.4685 - val_loss: 125.7962\n",
      "Epoch 374/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.3987 - val_loss: 125.7518\n",
      "Epoch 375/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.3381 - val_loss: 125.6957\n",
      "Epoch 376/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.2668 - val_loss: 125.6423\n",
      "Epoch 377/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.2075 - val_loss: 125.5729\n",
      "Epoch 378/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.1336 - val_loss: 125.5268\n",
      "Epoch 379/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.0724 - val_loss: 125.4740\n",
      "Epoch 380/5000\n",
      "1126/1126 [==============================] - 0s - loss: 109.0069 - val_loss: 125.4177\n",
      "Epoch 381/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.9392 - val_loss: 125.3806\n",
      "Epoch 382/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.8794 - val_loss: 125.3478\n",
      "Epoch 383/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.8156 - val_loss: 125.2789\n",
      "Epoch 384/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.7516 - val_loss: 125.2291\n",
      "Epoch 385/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.6942 - val_loss: 125.1638\n",
      "Epoch 386/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.6296 - val_loss: 125.1649\n",
      "Epoch 387/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.5694 - val_loss: 125.0995\n",
      "Epoch 388/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.5065 - val_loss: 125.0454\n",
      "Epoch 389/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.4488 - val_loss: 124.9943\n",
      "Epoch 390/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.3914 - val_loss: 124.9594\n",
      "Epoch 391/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.3324 - val_loss: 124.8965\n",
      "Epoch 392/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.2743 - val_loss: 124.8615\n",
      "Epoch 393/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.2186 - val_loss: 124.7972\n",
      "Epoch 394/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.1601 - val_loss: 124.7405\n",
      "Epoch 395/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.1032 - val_loss: 124.6809\n",
      "Epoch 396/5000\n",
      "1126/1126 [==============================] - 0s - loss: 108.0498 - val_loss: 124.6719\n",
      "Epoch 397/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.9967 - val_loss: 124.6379\n",
      "Epoch 398/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.9453 - val_loss: 124.5104\n",
      "Epoch 399/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.8910 - val_loss: 124.4402\n",
      "Epoch 400/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 107.8357 - val_loss: 124.4164\n",
      "Epoch 401/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.7801 - val_loss: 124.3708\n",
      "Epoch 402/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.7308 - val_loss: 124.3120\n",
      "Epoch 403/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.6732 - val_loss: 124.2746\n",
      "Epoch 404/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.6188 - val_loss: 124.2425\n",
      "Epoch 405/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.5719 - val_loss: 124.1972\n",
      "Epoch 406/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.5313 - val_loss: 124.1377\n",
      "Epoch 407/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.4757 - val_loss: 124.0751\n",
      "Epoch 408/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.4284 - val_loss: 123.9662\n",
      "Epoch 409/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.3821 - val_loss: 123.9109\n",
      "Epoch 410/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.3251 - val_loss: 123.8590\n",
      "Epoch 411/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.2787 - val_loss: 123.8017\n",
      "Epoch 412/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.2295 - val_loss: 123.7754\n",
      "Epoch 413/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.1860 - val_loss: 123.7372\n",
      "Epoch 414/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.1363 - val_loss: 123.5707\n",
      "Epoch 415/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.0880 - val_loss: 123.5585\n",
      "Epoch 416/5000\n",
      "1126/1126 [==============================] - 0s - loss: 107.0437 - val_loss: 123.5107\n",
      "Epoch 417/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.9929 - val_loss: 123.4624\n",
      "Epoch 418/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.9453 - val_loss: 123.4185\n",
      "Epoch 419/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.9048 - val_loss: 123.3687\n",
      "Epoch 420/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.8530 - val_loss: 123.2987\n",
      "Epoch 421/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.8063 - val_loss: 123.2455\n",
      "Epoch 422/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.7618 - val_loss: 123.2614\n",
      "Epoch 423/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.7193 - val_loss: 123.2085\n",
      "Epoch 424/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.6758 - val_loss: 123.1430\n",
      "Epoch 425/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.6330 - val_loss: 123.0922\n",
      "Epoch 426/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.5878 - val_loss: 123.0631\n",
      "Epoch 427/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.5431 - val_loss: 123.0577\n",
      "Epoch 428/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.5004 - val_loss: 123.0275\n",
      "Epoch 429/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.4583 - val_loss: 122.9993\n",
      "Epoch 430/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.4188 - val_loss: 122.9809\n",
      "Epoch 431/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.3754 - val_loss: 122.9743\n",
      "Epoch 432/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.3344 - val_loss: 122.9569\n",
      "Epoch 433/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.2881 - val_loss: 122.9034\n",
      "Epoch 434/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.2498 - val_loss: 122.8660\n",
      "Epoch 435/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.2138 - val_loss: 122.8831\n",
      "Epoch 436/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.1764 - val_loss: 122.8549\n",
      "Epoch 437/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.1427 - val_loss: 122.8418\n",
      "Epoch 438/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.1046 - val_loss: 122.8065\n",
      "Epoch 439/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.0655 - val_loss: 122.7608\n",
      "Epoch 440/5000\n",
      "1126/1126 [==============================] - 0s - loss: 106.0255 - val_loss: 122.7172\n",
      "Epoch 441/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.9870 - val_loss: 122.6879\n",
      "Epoch 442/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.9439 - val_loss: 122.6408\n",
      "Epoch 443/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.9067 - val_loss: 122.6068\n",
      "Epoch 444/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.8635 - val_loss: 122.5663\n",
      "Epoch 445/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 105.694 - 0s - loss: 105.8270 - val_loss: 122.5222\n",
      "Epoch 446/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.7946 - val_loss: 122.4224\n",
      "Epoch 447/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.7564 - val_loss: 122.3945\n",
      "Epoch 448/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.7144 - val_loss: 122.3399\n",
      "Epoch 449/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.6874 - val_loss: 122.3105\n",
      "Epoch 450/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.6464 - val_loss: 122.2630\n",
      "Epoch 451/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.6080 - val_loss: 122.2439\n",
      "Epoch 452/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.5735 - val_loss: 122.2050\n",
      "Epoch 453/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.5398 - val_loss: 122.1727\n",
      "Epoch 454/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.5014 - val_loss: 122.1290\n",
      "Epoch 455/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.4648 - val_loss: 122.0965\n",
      "Epoch 456/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.4338 - val_loss: 122.0552\n",
      "Epoch 457/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.3986 - val_loss: 122.0125\n",
      "Epoch 458/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.3646 - val_loss: 121.9686\n",
      "Epoch 459/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.3292 - val_loss: 121.9348\n",
      "Epoch 460/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.2989 - val_loss: 121.8854\n",
      "Epoch 461/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.2609 - val_loss: 121.8909\n",
      "Epoch 462/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.2275 - val_loss: 121.8633\n",
      "Epoch 463/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.1976 - val_loss: 121.8261\n",
      "Epoch 464/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.1609 - val_loss: 121.7905\n",
      "Epoch 465/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.1271 - val_loss: 121.7420\n",
      "Epoch 466/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.0978 - val_loss: 121.7221\n",
      "Epoch 467/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.0686 - val_loss: 121.7025\n",
      "Epoch 468/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.0375 - val_loss: 121.6773\n",
      "Epoch 469/5000\n",
      "1126/1126 [==============================] - 0s - loss: 105.0079 - val_loss: 121.6664\n",
      "Epoch 470/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.9740 - val_loss: 121.6126\n",
      "Epoch 471/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.9463 - val_loss: 121.5893\n",
      "Epoch 472/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.9138 - val_loss: 121.5964\n",
      "Epoch 473/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.8858 - val_loss: 121.5482\n",
      "Epoch 474/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.8536 - val_loss: 121.5323\n",
      "Epoch 475/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.8269 - val_loss: 121.5018\n",
      "Epoch 476/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7942 - val_loss: 121.4430\n",
      "Epoch 477/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7629 - val_loss: 121.4520\n",
      "Epoch 478/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7250 - val_loss: 121.4141\n",
      "Epoch 479/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7033 - val_loss: 121.3766\n",
      "Epoch 480/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.6743 - val_loss: 121.3310\n",
      "Epoch 481/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 104.6380 - val_loss: 121.2714\n",
      "Epoch 482/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.6084 - val_loss: 121.2207\n",
      "Epoch 483/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.5775 - val_loss: 121.1877\n",
      "Epoch 484/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.5489 - val_loss: 121.1320\n",
      "Epoch 485/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.5219 - val_loss: 121.1016\n",
      "Epoch 486/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4960 - val_loss: 121.0734\n",
      "Epoch 487/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4654 - val_loss: 121.0004\n",
      "Epoch 488/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4350 - val_loss: 120.9724\n",
      "Epoch 489/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3998 - val_loss: 120.9370\n",
      "Epoch 490/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3716 - val_loss: 120.9490\n",
      "Epoch 491/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3434 - val_loss: 120.9322\n",
      "Epoch 492/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3165 - val_loss: 120.8982\n",
      "Epoch 493/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2871 - val_loss: 120.8710\n",
      "Epoch 494/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2628 - val_loss: 120.8407\n",
      "Epoch 495/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2373 - val_loss: 120.8119\n",
      "Epoch 496/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2128 - val_loss: 120.7812\n",
      "Epoch 497/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1825 - val_loss: 120.7397\n",
      "Epoch 498/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1512 - val_loss: 120.7025\n",
      "Epoch 499/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1265 - val_loss: 120.7036\n",
      "Epoch 500/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0988 - val_loss: 120.6856\n",
      "Epoch 501/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0731 - val_loss: 120.6435\n",
      "Epoch 502/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0466 - val_loss: 120.6128\n",
      "Epoch 503/5000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0187 - val_loss: 120.5970\n",
      "Epoch 504/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9900 - val_loss: 120.5617\n",
      "Epoch 505/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9676 - val_loss: 120.5348\n",
      "Epoch 506/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9411 - val_loss: 120.5058\n",
      "Epoch 507/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9179 - val_loss: 120.4669\n",
      "Epoch 508/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8887 - val_loss: 120.4203\n",
      "Epoch 509/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8609 - val_loss: 120.4209\n",
      "Epoch 510/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8376 - val_loss: 120.4210\n",
      "Epoch 511/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8200 - val_loss: 120.3750\n",
      "Epoch 512/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7870 - val_loss: 120.3391\n",
      "Epoch 513/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7650 - val_loss: 120.3091\n",
      "Epoch 514/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7395 - val_loss: 120.2781\n",
      "Epoch 515/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7085 - val_loss: 120.2342\n",
      "Epoch 516/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6876 - val_loss: 120.1818\n",
      "Epoch 517/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6619 - val_loss: 120.1385\n",
      "Epoch 518/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6357 - val_loss: 120.1106\n",
      "Epoch 519/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6104 - val_loss: 120.0772\n",
      "Epoch 520/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5921 - val_loss: 120.0506\n",
      "Epoch 521/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5621 - val_loss: 120.0230\n",
      "Epoch 522/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5410 - val_loss: 119.9986\n",
      "Epoch 523/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5091 - val_loss: 119.9726\n",
      "Epoch 524/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4920 - val_loss: 119.9639\n",
      "Epoch 525/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4603 - val_loss: 119.8909\n",
      "Epoch 526/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4396 - val_loss: 119.8631\n",
      "Epoch 527/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4134 - val_loss: 119.8252\n",
      "Epoch 528/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3898 - val_loss: 119.7979\n",
      "Epoch 529/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3685 - val_loss: 119.7482\n",
      "Epoch 530/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3451 - val_loss: 119.6999\n",
      "Epoch 531/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3172 - val_loss: 119.6441\n",
      "Epoch 532/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2988 - val_loss: 119.6435\n",
      "Epoch 533/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2750 - val_loss: 119.6446\n",
      "Epoch 534/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2508 - val_loss: 119.6141\n",
      "Epoch 535/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2304 - val_loss: 119.5835\n",
      "Epoch 536/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2066 - val_loss: 119.5522\n",
      "Epoch 537/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1844 - val_loss: 119.5332\n",
      "Epoch 538/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1612 - val_loss: 119.5057\n",
      "Epoch 539/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1376 - val_loss: 119.4553\n",
      "Epoch 540/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1155 - val_loss: 119.3702\n",
      "Epoch 541/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0980 - val_loss: 119.3718\n",
      "Epoch 542/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0757 - val_loss: 119.3410\n",
      "Epoch 543/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0513 - val_loss: 119.3064\n",
      "Epoch 544/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0280 - val_loss: 119.2767\n",
      "Epoch 545/5000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0048 - val_loss: 119.2310\n",
      "Epoch 546/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9857 - val_loss: 119.2102\n",
      "Epoch 547/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9647 - val_loss: 119.1784\n",
      "Epoch 548/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9415 - val_loss: 119.1460\n",
      "Epoch 549/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9182 - val_loss: 119.1395\n",
      "Epoch 550/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8972 - val_loss: 119.1071\n",
      "Epoch 551/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8757 - val_loss: 119.0954\n",
      "Epoch 552/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8518 - val_loss: 119.0690\n",
      "Epoch 553/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8354 - val_loss: 119.0375\n",
      "Epoch 554/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8103 - val_loss: 119.0070\n",
      "Epoch 555/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7903 - val_loss: 118.9767\n",
      "Epoch 556/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7737 - val_loss: 118.9984\n",
      "Epoch 557/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7498 - val_loss: 118.9662\n",
      "Epoch 558/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7282 - val_loss: 118.9701\n",
      "Epoch 559/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7083 - val_loss: 118.9373\n",
      "Epoch 560/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6903 - val_loss: 118.9095\n",
      "Epoch 561/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6652 - val_loss: 118.9183\n",
      "Epoch 562/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6493 - val_loss: 118.8358\n",
      "Epoch 563/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6310 - val_loss: 118.8094\n",
      "Epoch 564/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6099 - val_loss: 118.8389\n",
      "Epoch 565/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5892 - val_loss: 118.8103\n",
      "Epoch 566/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5715 - val_loss: 118.7715\n",
      "Epoch 567/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5456 - val_loss: 118.7447\n",
      "Epoch 568/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5251 - val_loss: 118.7147\n",
      "Epoch 569/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5064 - val_loss: 118.6964\n",
      "Epoch 570/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4889 - val_loss: 118.6594\n",
      "Epoch 571/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4700 - val_loss: 118.5860\n",
      "Epoch 572/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4480 - val_loss: 118.5386\n",
      "Epoch 573/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4247 - val_loss: 118.4970\n",
      "Epoch 574/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4062 - val_loss: 118.4668\n",
      "Epoch 575/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3949 - val_loss: 118.4596\n",
      "Epoch 576/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3684 - val_loss: 118.3758\n",
      "Epoch 577/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3489 - val_loss: 118.3474\n",
      "Epoch 578/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3313 - val_loss: 118.3148\n",
      "Epoch 579/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3125 - val_loss: 118.2941\n",
      "Epoch 580/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2936 - val_loss: 118.3295\n",
      "Epoch 581/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2718 - val_loss: 118.3077\n",
      "Epoch 582/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2581 - val_loss: 118.2825\n",
      "Epoch 583/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2375 - val_loss: 118.2452\n",
      "Epoch 584/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2216 - val_loss: 118.1986\n",
      "Epoch 585/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2038 - val_loss: 118.1280\n",
      "Epoch 586/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1782 - val_loss: 118.0965\n",
      "Epoch 587/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1600 - val_loss: 118.0862\n",
      "Epoch 588/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1434 - val_loss: 118.0464\n",
      "Epoch 589/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1234 - val_loss: 118.0207\n",
      "Epoch 590/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1067 - val_loss: 117.9908\n",
      "Epoch 591/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.0843 - val_loss: 117.9903\n",
      "Epoch 592/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.0692 - val_loss: 117.9603\n",
      "Epoch 593/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.0481 - val_loss: 117.9045\n",
      "Epoch 594/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.0332 - val_loss: 117.8829\n",
      "Epoch 595/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.0178 - val_loss: 117.8546\n",
      "Epoch 596/5000\n",
      "1126/1126 [==============================] - 0s - loss: 102.0004 - val_loss: 117.8443\n",
      "Epoch 597/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.9840 - val_loss: 117.7555\n",
      "Epoch 598/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.9653 - val_loss: 117.7356\n",
      "Epoch 599/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.9501 - val_loss: 117.6884\n",
      "Epoch 600/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.9304 - val_loss: 117.6588\n",
      "Epoch 601/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.9106 - val_loss: 117.6529\n",
      "Epoch 602/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.8997 - val_loss: 117.6422\n",
      "Epoch 603/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.8793 - val_loss: 117.5050\n",
      "Epoch 604/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.8599 - val_loss: 117.4821\n",
      "Epoch 605/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.8447 - val_loss: 117.4418\n",
      "Epoch 606/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.8233 - val_loss: 117.4358\n",
      "Epoch 607/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.8031 - val_loss: 117.4152\n",
      "Epoch 608/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.7929 - val_loss: 117.3900\n",
      "Epoch 609/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.7714 - val_loss: 117.3926\n",
      "Epoch 610/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.7548 - val_loss: 117.3714\n",
      "Epoch 611/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.7390 - val_loss: 117.3463\n",
      "Epoch 612/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.7206 - val_loss: 117.3326\n",
      "Epoch 613/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.7042 - val_loss: 117.3413\n",
      "Epoch 614/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.6889 - val_loss: 117.3064\n",
      "Epoch 615/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.6706 - val_loss: 117.2969\n",
      "Epoch 616/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.6558 - val_loss: 117.2719\n",
      "Epoch 617/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.6355 - val_loss: 117.2533\n",
      "Epoch 618/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.6229 - val_loss: 117.2614\n",
      "Epoch 619/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.6053 - val_loss: 117.2372\n",
      "Epoch 620/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.5893 - val_loss: 117.2116\n",
      "Epoch 621/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.5704 - val_loss: 117.1707\n",
      "Epoch 622/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.5559 - val_loss: 117.0518\n",
      "Epoch 623/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.5379 - val_loss: 117.0157\n",
      "Epoch 624/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.5202 - val_loss: 116.9967\n",
      "Epoch 625/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.5051 - val_loss: 116.9852\n",
      "Epoch 626/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.4963 - val_loss: 116.9635\n",
      "Epoch 627/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.4780 - val_loss: 116.9404\n",
      "Epoch 628/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.4548 - val_loss: 116.9204\n",
      "Epoch 629/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.4461 - val_loss: 116.8823\n",
      "Epoch 630/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.4286 - val_loss: 116.8695\n",
      "Epoch 631/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.4162 - val_loss: 116.8398\n",
      "Epoch 632/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.3996 - val_loss: 116.8329\n",
      "Epoch 633/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.3829 - val_loss: 116.8085\n",
      "Epoch 634/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.3645 - val_loss: 116.7878\n",
      "Epoch 635/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.3494 - val_loss: 116.7697\n",
      "Epoch 636/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.3346 - val_loss: 116.7541\n",
      "Epoch 637/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.3204 - val_loss: 116.6850\n",
      "Epoch 638/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.3025 - val_loss: 116.6617\n",
      "Epoch 639/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.2875 - val_loss: 116.6304\n",
      "Epoch 640/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.2707 - val_loss: 116.6081\n",
      "Epoch 641/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.2583 - val_loss: 116.6015\n",
      "Epoch 642/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.2430 - val_loss: 116.5694\n",
      "Epoch 643/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 101.2247 - val_loss: 116.5438\n",
      "Epoch 644/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.2053 - val_loss: 116.5277\n",
      "Epoch 645/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.1945 - val_loss: 116.4965\n",
      "Epoch 646/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.1838 - val_loss: 116.4988\n",
      "Epoch 647/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.1622 - val_loss: 116.4968\n",
      "Epoch 648/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.1527 - val_loss: 116.4479\n",
      "Epoch 649/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.1364 - val_loss: 116.4227\n",
      "Epoch 650/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.1197 - val_loss: 116.4221\n",
      "Epoch 651/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.1055 - val_loss: 116.4107\n",
      "Epoch 652/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.0899 - val_loss: 116.3858\n",
      "Epoch 653/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.0734 - val_loss: 116.3489\n",
      "Epoch 654/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.0617 - val_loss: 116.3565\n",
      "Epoch 655/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.0428 - val_loss: 116.3210\n",
      "Epoch 656/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.0290 - val_loss: 116.2841\n",
      "Epoch 657/5000\n",
      "1126/1126 [==============================] - 0s - loss: 101.0163 - val_loss: 116.2600\n",
      "Epoch 658/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.9982 - val_loss: 116.2608\n",
      "Epoch 659/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.9849 - val_loss: 116.2306\n",
      "Epoch 660/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.9702 - val_loss: 116.2017\n",
      "Epoch 661/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.9552 - val_loss: 116.1748\n",
      "Epoch 662/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.9377 - val_loss: 116.1494\n",
      "Epoch 663/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.9264 - val_loss: 116.1200\n",
      "Epoch 664/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.9113 - val_loss: 116.0985\n",
      "Epoch 665/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.8979 - val_loss: 116.0851\n",
      "Epoch 666/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.8830 - val_loss: 116.0332\n",
      "Epoch 667/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.8685 - val_loss: 116.0427\n",
      "Epoch 668/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.8554 - val_loss: 116.0287\n",
      "Epoch 669/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.8408 - val_loss: 116.0078\n",
      "Epoch 670/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.8273 - val_loss: 116.0062\n",
      "Epoch 671/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.8133 - val_loss: 115.9755\n",
      "Epoch 672/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.7952 - val_loss: 115.9593\n",
      "Epoch 673/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.7821 - val_loss: 115.9055\n",
      "Epoch 674/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.7762 - val_loss: 115.8792\n",
      "Epoch 675/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.7592 - val_loss: 115.8546\n",
      "Epoch 676/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.7431 - val_loss: 115.8474\n",
      "Epoch 677/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.7309 - val_loss: 115.8226\n",
      "Epoch 678/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.7156 - val_loss: 115.7865\n",
      "Epoch 679/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.7048 - val_loss: 115.7565\n",
      "Epoch 680/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.6915 - val_loss: 115.7290\n",
      "Epoch 681/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.6732 - val_loss: 115.6866\n",
      "Epoch 682/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.6618 - val_loss: 115.6469\n",
      "Epoch 683/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.6480 - val_loss: 115.6558\n",
      "Epoch 684/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.6392 - val_loss: 115.6384\n",
      "Epoch 685/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.6228 - val_loss: 115.6289\n",
      "Epoch 686/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.6091 - val_loss: 115.6038\n",
      "Epoch 687/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.5915 - val_loss: 115.5929\n",
      "Epoch 688/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.5820 - val_loss: 115.5783\n",
      "Epoch 689/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.5693 - val_loss: 115.5253\n",
      "Epoch 690/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.5535 - val_loss: 115.4972\n",
      "Epoch 691/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.5389 - val_loss: 115.4764\n",
      "Epoch 692/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.5279 - val_loss: 115.4569\n",
      "Epoch 693/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.5147 - val_loss: 115.4459\n",
      "Epoch 694/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.4998 - val_loss: 115.4242\n",
      "Epoch 695/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.4900 - val_loss: 115.4069\n",
      "Epoch 696/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.4757 - val_loss: 115.3761\n",
      "Epoch 697/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.4601 - val_loss: 115.3436\n",
      "Epoch 698/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 103.763 - 0s - loss: 100.4514 - val_loss: 115.3416\n",
      "Epoch 699/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.4337 - val_loss: 115.3074\n",
      "Epoch 700/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.4196 - val_loss: 115.2764\n",
      "Epoch 701/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.4111 - val_loss: 115.2525\n",
      "Epoch 702/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.3957 - val_loss: 115.2228\n",
      "Epoch 703/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.3824 - val_loss: 115.2075\n",
      "Epoch 704/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.3695 - val_loss: 115.1894\n",
      "Epoch 705/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.3555 - val_loss: 115.1868\n",
      "Epoch 706/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.3395 - val_loss: 115.1743\n",
      "Epoch 707/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.3284 - val_loss: 115.1480\n",
      "Epoch 708/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.3173 - val_loss: 115.1228\n",
      "Epoch 709/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.3026 - val_loss: 115.0917\n",
      "Epoch 710/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 96.487 - 0s - loss: 100.2899 - val_loss: 115.0845\n",
      "Epoch 711/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.2750 - val_loss: 115.0527\n",
      "Epoch 712/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.2640 - val_loss: 115.0084\n",
      "Epoch 713/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.2567 - val_loss: 114.9864\n",
      "Epoch 714/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.2446 - val_loss: 114.9580\n",
      "Epoch 715/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.2291 - val_loss: 114.9231\n",
      "Epoch 716/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.2183 - val_loss: 114.8786\n",
      "Epoch 717/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.2039 - val_loss: 114.8543\n",
      "Epoch 718/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.1924 - val_loss: 114.8374\n",
      "Epoch 719/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.1796 - val_loss: 114.8198\n",
      "Epoch 720/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 97.27 - 0s - loss: 100.1682 - val_loss: 114.8278\n",
      "Epoch 721/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.1539 - val_loss: 114.8172\n",
      "Epoch 722/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.1422 - val_loss: 114.7948\n",
      "Epoch 723/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.1304 - val_loss: 114.8077\n",
      "Epoch 724/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.1200 - val_loss: 114.7908\n",
      "Epoch 725/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.1043 - val_loss: 114.7680\n",
      "Epoch 726/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.0928 - val_loss: 114.7505\n",
      "Epoch 727/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.0820 - val_loss: 114.7193\n",
      "Epoch 728/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.0729 - val_loss: 114.6922\n",
      "Epoch 729/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.0599 - val_loss: 114.7186\n",
      "Epoch 730/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.0438 - val_loss: 114.6951\n",
      "Epoch 731/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.0344 - val_loss: 114.6685\n",
      "Epoch 732/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.0192 - val_loss: 114.6450\n",
      "Epoch 733/5000\n",
      "1126/1126 [==============================] - 0s - loss: 100.0053 - val_loss: 114.6225\n",
      "Epoch 734/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.9963 - val_loss: 114.5953\n",
      "Epoch 735/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.9863 - val_loss: 114.6085\n",
      "Epoch 736/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.9707 - val_loss: 114.6043\n",
      "Epoch 737/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.9585 - val_loss: 114.5818\n",
      "Epoch 738/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.9503 - val_loss: 114.5425\n",
      "Epoch 739/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.9352 - val_loss: 114.5265\n",
      "Epoch 740/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.9235 - val_loss: 114.4930\n",
      "Epoch 741/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.9131 - val_loss: 114.4677\n",
      "Epoch 742/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.9008 - val_loss: 114.4477\n",
      "Epoch 743/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.8833 - val_loss: 114.4566\n",
      "Epoch 744/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.8738 - val_loss: 114.4315\n",
      "Epoch 745/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.8629 - val_loss: 114.3999\n",
      "Epoch 746/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.8485 - val_loss: 114.3922\n",
      "Epoch 747/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.8370 - val_loss: 114.3662\n",
      "Epoch 748/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.8236 - val_loss: 114.3448\n",
      "Epoch 749/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.8118 - val_loss: 114.3461\n",
      "Epoch 750/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.8018 - val_loss: 114.3026\n",
      "Epoch 751/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.7857 - val_loss: 114.2834\n",
      "Epoch 752/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.7782 - val_loss: 114.2671\n",
      "Epoch 753/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.7669 - val_loss: 114.2687\n",
      "Epoch 754/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.7531 - val_loss: 114.2472\n",
      "Epoch 755/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.7423 - val_loss: 114.2243\n",
      "Epoch 756/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.7326 - val_loss: 114.1767\n",
      "Epoch 757/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.7177 - val_loss: 114.1554\n",
      "Epoch 758/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.7062 - val_loss: 114.1162\n",
      "Epoch 759/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.6994 - val_loss: 114.1011\n",
      "Epoch 760/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.6880 - val_loss: 114.0689\n",
      "Epoch 761/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.6719 - val_loss: 114.0414\n",
      "Epoch 762/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.6639 - val_loss: 114.0164\n",
      "Epoch 763/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.6486 - val_loss: 114.0255\n",
      "Epoch 764/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.6398 - val_loss: 114.0058\n",
      "Epoch 765/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.6278 - val_loss: 113.9834\n",
      "Epoch 766/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.6207 - val_loss: 113.9583\n",
      "Epoch 767/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.6056 - val_loss: 113.9445\n",
      "Epoch 768/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.5919 - val_loss: 113.9314\n",
      "Epoch 769/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.5852 - val_loss: 113.9071\n",
      "Epoch 770/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.5725 - val_loss: 113.8901\n",
      "Epoch 771/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.5635 - val_loss: 113.8949\n",
      "Epoch 772/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.5505 - val_loss: 113.8333\n",
      "Epoch 773/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.5415 - val_loss: 113.8075\n",
      "Epoch 774/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.5323 - val_loss: 113.7859\n",
      "Epoch 775/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.5188 - val_loss: 113.7890\n",
      "Epoch 776/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.5064 - val_loss: 113.7879\n",
      "Epoch 777/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.4991 - val_loss: 113.7501\n",
      "Epoch 778/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.4849 - val_loss: 113.7270\n",
      "Epoch 779/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.4734 - val_loss: 113.7111\n",
      "Epoch 780/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.4607 - val_loss: 113.6831\n",
      "Epoch 781/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.4527 - val_loss: 113.6912\n",
      "Epoch 782/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.4430 - val_loss: 113.6807\n",
      "Epoch 783/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.4337 - val_loss: 113.6647\n",
      "Epoch 784/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.4223 - val_loss: 113.6158\n",
      "Epoch 785/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.4121 - val_loss: 113.6101\n",
      "Epoch 786/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.4009 - val_loss: 113.5732\n",
      "Epoch 787/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.3880 - val_loss: 113.5516\n",
      "Epoch 788/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.3785 - val_loss: 113.5401\n",
      "Epoch 789/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.3661 - val_loss: 113.5125\n",
      "Epoch 790/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.3587 - val_loss: 113.5008\n",
      "Epoch 791/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.3439 - val_loss: 113.4727\n",
      "Epoch 792/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.3348 - val_loss: 113.4779\n",
      "Epoch 793/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.3229 - val_loss: 113.4287\n",
      "Epoch 794/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.3133 - val_loss: 113.4207\n",
      "Epoch 795/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.3001 - val_loss: 113.4059\n",
      "Epoch 796/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.2901 - val_loss: 113.3847\n",
      "Epoch 797/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.2796 - val_loss: 113.3567\n",
      "Epoch 798/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.2702 - val_loss: 113.3330\n",
      "Epoch 799/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.2605 - val_loss: 113.3353\n",
      "Epoch 800/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.2470 - val_loss: 113.3174\n",
      "Epoch 801/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.2348 - val_loss: 113.3014\n",
      "Epoch 802/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.2312 - val_loss: 113.2546\n",
      "Epoch 803/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.2182 - val_loss: 113.2369\n",
      "Epoch 804/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 99.2067 - val_loss: 113.2271\n",
      "Epoch 805/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.1955 - val_loss: 113.2120\n",
      "Epoch 806/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.1870 - val_loss: 113.2038\n",
      "Epoch 807/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.1728 - val_loss: 113.1885\n",
      "Epoch 808/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.1667 - val_loss: 113.1898\n",
      "Epoch 809/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.1530 - val_loss: 113.1820\n",
      "Epoch 810/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.1464 - val_loss: 113.1617\n",
      "Epoch 811/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.1337 - val_loss: 113.1585\n",
      "Epoch 812/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.1203 - val_loss: 113.1779\n",
      "Epoch 813/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.1128 - val_loss: 113.1755\n",
      "Epoch 814/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.0986 - val_loss: 113.1308\n",
      "Epoch 815/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.0917 - val_loss: 113.1067\n",
      "Epoch 816/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.0843 - val_loss: 113.0883\n",
      "Epoch 817/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.0708 - val_loss: 113.0518\n",
      "Epoch 818/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.0590 - val_loss: 113.0379\n",
      "Epoch 819/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.0518 - val_loss: 112.9559\n",
      "Epoch 820/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.0384 - val_loss: 112.9971\n",
      "Epoch 821/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.0289 - val_loss: 112.9823\n",
      "Epoch 822/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.0218 - val_loss: 112.9798\n",
      "Epoch 823/5000\n",
      "1126/1126 [==============================] - 0s - loss: 99.0097 - val_loss: 112.9573\n",
      "Epoch 824/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9978 - val_loss: 112.9325\n",
      "Epoch 825/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9908 - val_loss: 112.9114\n",
      "Epoch 826/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9790 - val_loss: 112.8941\n",
      "Epoch 827/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9712 - val_loss: 112.8773\n",
      "Epoch 828/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9608 - val_loss: 112.8352\n",
      "Epoch 829/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9473 - val_loss: 112.8140\n",
      "Epoch 830/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9377 - val_loss: 112.7688\n",
      "Epoch 831/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9280 - val_loss: 112.7792\n",
      "Epoch 832/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9167 - val_loss: 112.7628\n",
      "Epoch 833/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9071 - val_loss: 112.7501\n",
      "Epoch 834/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8991 - val_loss: 112.7320\n",
      "Epoch 835/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8907 - val_loss: 112.7134\n",
      "Epoch 836/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8827 - val_loss: 112.7109\n",
      "Epoch 837/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8711 - val_loss: 112.6959\n",
      "Epoch 838/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8597 - val_loss: 112.7127\n",
      "Epoch 839/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8527 - val_loss: 112.6982\n",
      "Epoch 840/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8420 - val_loss: 112.6811\n",
      "Epoch 841/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8306 - val_loss: 112.6677\n",
      "Epoch 842/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8227 - val_loss: 112.6474\n",
      "Epoch 843/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8117 - val_loss: 112.6373\n",
      "Epoch 844/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8010 - val_loss: 112.6234\n",
      "Epoch 845/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.7928 - val_loss: 112.5869\n",
      "Epoch 846/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.7821 - val_loss: 112.5627\n",
      "Epoch 847/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.7750 - val_loss: 112.5454\n",
      "Epoch 848/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.7631 - val_loss: 112.5220\n",
      "Epoch 849/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.7557 - val_loss: 112.5173\n",
      "Epoch 850/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.7454 - val_loss: 112.4922\n",
      "Epoch 851/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.7340 - val_loss: 112.4679\n",
      "Epoch 852/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.7240 - val_loss: 112.4504\n",
      "Epoch 853/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.7149 - val_loss: 112.4270\n",
      "Epoch 854/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.7083 - val_loss: 112.4114\n",
      "Epoch 855/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.6938 - val_loss: 112.3948\n",
      "Epoch 856/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.6835 - val_loss: 112.3985\n",
      "Epoch 857/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.6735 - val_loss: 112.3797\n",
      "Epoch 858/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.6644 - val_loss: 112.3556\n",
      "Epoch 859/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.6560 - val_loss: 112.3412\n",
      "Epoch 860/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.6482 - val_loss: 112.3280\n",
      "Epoch 861/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.6367 - val_loss: 112.3121\n",
      "Epoch 862/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.6308 - val_loss: 112.2890\n",
      "Epoch 863/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.6167 - val_loss: 112.2786\n",
      "Epoch 864/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.6071 - val_loss: 112.2434\n",
      "Epoch 865/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5989 - val_loss: 112.2272\n",
      "Epoch 866/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5902 - val_loss: 112.2108\n",
      "Epoch 867/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5789 - val_loss: 112.2510\n",
      "Epoch 868/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5700 - val_loss: 112.2309\n",
      "Epoch 869/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5588 - val_loss: 112.2338\n",
      "Epoch 870/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5520 - val_loss: 112.2664\n",
      "Epoch 871/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5418 - val_loss: 112.2461\n",
      "Epoch 872/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5331 - val_loss: 112.2290\n",
      "Epoch 873/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5236 - val_loss: 112.2079\n",
      "Epoch 874/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5146 - val_loss: 112.1853\n",
      "Epoch 875/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5057 - val_loss: 112.1627\n",
      "Epoch 876/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.4940 - val_loss: 112.1517\n",
      "Epoch 877/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.4861 - val_loss: 112.1420\n",
      "Epoch 878/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.4777 - val_loss: 112.1386\n",
      "Epoch 879/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.4653 - val_loss: 112.1083\n",
      "Epoch 880/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.4590 - val_loss: 112.0834\n",
      "Epoch 881/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.4485 - val_loss: 112.0635\n",
      "Epoch 882/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.4401 - val_loss: 112.0469\n",
      "Epoch 883/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.4320 - val_loss: 112.0329\n",
      "Epoch 884/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.4204 - val_loss: 112.0361\n",
      "Epoch 885/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.4129 - val_loss: 112.0142\n",
      "Epoch 886/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 98.4055 - val_loss: 112.0050\n",
      "Epoch 887/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3943 - val_loss: 111.9797\n",
      "Epoch 888/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3835 - val_loss: 111.9870\n",
      "Epoch 889/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3738 - val_loss: 111.9720\n",
      "Epoch 890/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3721 - val_loss: 111.9555\n",
      "Epoch 891/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3579 - val_loss: 111.9361\n",
      "Epoch 892/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3524 - val_loss: 111.9259\n",
      "Epoch 893/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3400 - val_loss: 111.8435\n",
      "Epoch 894/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3348 - val_loss: 111.8278\n",
      "Epoch 895/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3254 - val_loss: 111.8071\n",
      "Epoch 896/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3156 - val_loss: 111.7436\n",
      "Epoch 897/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3059 - val_loss: 111.7254\n",
      "Epoch 898/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2971 - val_loss: 111.7171\n",
      "Epoch 899/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2876 - val_loss: 111.7085\n",
      "Epoch 900/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2784 - val_loss: 111.6925\n",
      "Epoch 901/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2734 - val_loss: 111.6862\n",
      "Epoch 902/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2600 - val_loss: 111.6875\n",
      "Epoch 903/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2516 - val_loss: 111.6818\n",
      "Epoch 904/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2444 - val_loss: 111.6754\n",
      "Epoch 905/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2339 - val_loss: 111.6692\n",
      "Epoch 906/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2290 - val_loss: 111.6751\n",
      "Epoch 907/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2165 - val_loss: 111.6624\n",
      "Epoch 908/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.2106 - val_loss: 111.6460\n",
      "Epoch 909/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1992 - val_loss: 111.6182\n",
      "Epoch 910/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1919 - val_loss: 111.6073\n",
      "Epoch 911/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1819 - val_loss: 111.6141\n",
      "Epoch 912/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1748 - val_loss: 111.5951\n",
      "Epoch 913/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1654 - val_loss: 111.5744\n",
      "Epoch 914/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1587 - val_loss: 111.5756\n",
      "Epoch 915/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1548 - val_loss: 111.5585\n",
      "Epoch 916/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1383 - val_loss: 111.5300\n",
      "Epoch 917/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1328 - val_loss: 111.5271\n",
      "Epoch 918/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1238 - val_loss: 111.5195\n",
      "Epoch 919/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1172 - val_loss: 111.4939\n",
      "Epoch 920/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1058 - val_loss: 111.5004\n",
      "Epoch 921/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0986 - val_loss: 111.4824\n",
      "Epoch 922/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0928 - val_loss: 111.4759\n",
      "Epoch 923/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0807 - val_loss: 111.4431\n",
      "Epoch 924/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0774 - val_loss: 111.4421\n",
      "Epoch 925/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0649 - val_loss: 111.4334\n",
      "Epoch 926/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0598 - val_loss: 111.4113\n",
      "Epoch 927/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0511 - val_loss: 111.3948s: 95.209\n",
      "Epoch 928/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0409 - val_loss: 111.3770\n",
      "Epoch 929/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0295 - val_loss: 111.3594\n",
      "Epoch 930/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0242 - val_loss: 111.3425\n",
      "Epoch 931/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0146 - val_loss: 111.3218\n",
      "Epoch 932/5000\n",
      "1126/1126 [==============================] - 0s - loss: 98.0054 - val_loss: 111.3052\n",
      "Epoch 933/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9988 - val_loss: 111.3090\n",
      "Epoch 934/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9902 - val_loss: 111.3153\n",
      "Epoch 935/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9817 - val_loss: 111.3089\n",
      "Epoch 936/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9761 - val_loss: 111.2955\n",
      "Epoch 937/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9657 - val_loss: 111.3096\n",
      "Epoch 938/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9574 - val_loss: 111.2943\n",
      "Epoch 939/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9514 - val_loss: 111.2826\n",
      "Epoch 940/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9424 - val_loss: 111.2778\n",
      "Epoch 941/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9312 - val_loss: 111.2530\n",
      "Epoch 942/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9256 - val_loss: 111.2382\n",
      "Epoch 943/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9157 - val_loss: 111.2442\n",
      "Epoch 944/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9103 - val_loss: 111.2167\n",
      "Epoch 945/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8985 - val_loss: 111.2006\n",
      "Epoch 946/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8911 - val_loss: 111.1881\n",
      "Epoch 947/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8859 - val_loss: 111.1751\n",
      "Epoch 948/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8753 - val_loss: 111.1606\n",
      "Epoch 949/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8694 - val_loss: 111.1411\n",
      "Epoch 950/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8581 - val_loss: 111.1300\n",
      "Epoch 951/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8529 - val_loss: 111.1047\n",
      "Epoch 952/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8464 - val_loss: 111.0941\n",
      "Epoch 953/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8352 - val_loss: 111.1396\n",
      "Epoch 954/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8303 - val_loss: 111.1548\n",
      "Epoch 955/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8234 - val_loss: 111.1235\n",
      "Epoch 956/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8134 - val_loss: 111.1212\n",
      "Epoch 957/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8042 - val_loss: 111.1057\n",
      "Epoch 958/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7959 - val_loss: 111.0913\n",
      "Epoch 959/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7863 - val_loss: 111.0737\n",
      "Epoch 960/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7785 - val_loss: 111.0674\n",
      "Epoch 961/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7727 - val_loss: 111.0767\n",
      "Epoch 962/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7696 - val_loss: 111.0524\n",
      "Epoch 963/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7619 - val_loss: 111.0309\n",
      "Epoch 964/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7505 - val_loss: 111.0124\n",
      "Epoch 965/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7444 - val_loss: 110.9490\n",
      "Epoch 966/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7305 - val_loss: 110.9271\n",
      "Epoch 967/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7224 - val_loss: 110.9182\n",
      "Epoch 968/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7130 - val_loss: 110.9012\n",
      "Epoch 969/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7074 - val_loss: 110.8871\n",
      "Epoch 970/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.7017 - val_loss: 110.8732\n",
      "Epoch 971/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6917 - val_loss: 110.8535\n",
      "Epoch 972/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6824 - val_loss: 110.8399\n",
      "Epoch 973/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6762 - val_loss: 110.8261\n",
      "Epoch 974/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6671 - val_loss: 110.8061\n",
      "Epoch 975/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6589 - val_loss: 110.7995\n",
      "Epoch 976/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6497 - val_loss: 110.7986\n",
      "Epoch 977/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6437 - val_loss: 110.8375\n",
      "Epoch 978/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6356 - val_loss: 110.7982\n",
      "Epoch 979/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6294 - val_loss: 110.7940\n",
      "Epoch 980/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6168 - val_loss: 110.7830\n",
      "Epoch 981/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6125 - val_loss: 110.7471\n",
      "Epoch 982/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.6034 - val_loss: 110.7647\n",
      "Epoch 983/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5939 - val_loss: 110.7489\n",
      "Epoch 984/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5884 - val_loss: 110.7578\n",
      "Epoch 985/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5802 - val_loss: 110.7561\n",
      "Epoch 986/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5735 - val_loss: 110.7389\n",
      "Epoch 987/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5639 - val_loss: 110.7120\n",
      "Epoch 988/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5567 - val_loss: 110.7139\n",
      "Epoch 989/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5463 - val_loss: 110.6937\n",
      "Epoch 990/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5403 - val_loss: 110.6823\n",
      "Epoch 991/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5326 - val_loss: 110.6651\n",
      "Epoch 992/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5209 - val_loss: 110.6579\n",
      "Epoch 993/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5142 - val_loss: 110.6526\n",
      "Epoch 994/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.5076 - val_loss: 110.6271\n",
      "Epoch 995/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4986 - val_loss: 110.6063\n",
      "Epoch 996/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4904 - val_loss: 110.5888\n",
      "Epoch 997/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4831 - val_loss: 110.5695\n",
      "Epoch 998/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4767 - val_loss: 110.5545\n",
      "Epoch 999/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4691 - val_loss: 110.5364\n",
      "Epoch 1000/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4577 - val_loss: 110.5272\n",
      "Epoch 1001/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4518 - val_loss: 110.5166\n",
      "Epoch 1002/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4441 - val_loss: 110.4908\n",
      "Epoch 1003/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4369 - val_loss: 110.4922\n",
      "Epoch 1004/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4302 - val_loss: 110.4754\n",
      "Epoch 1005/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4211 - val_loss: 110.4648\n",
      "Epoch 1006/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4155 - val_loss: 110.4870\n",
      "Epoch 1007/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4054 - val_loss: 110.4922\n",
      "Epoch 1008/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3990 - val_loss: 110.5130\n",
      "Epoch 1009/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3894 - val_loss: 110.4810\n",
      "Epoch 1010/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3860 - val_loss: 110.4706\n",
      "Epoch 1011/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3759 - val_loss: 110.4398\n",
      "Epoch 1012/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3689 - val_loss: 110.3692\n",
      "Epoch 1013/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3582 - val_loss: 110.3562\n",
      "Epoch 1014/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3518 - val_loss: 110.3505\n",
      "Epoch 1015/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3487 - val_loss: 110.3435\n",
      "Epoch 1016/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3379 - val_loss: 110.3191\n",
      "Epoch 1017/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3316 - val_loss: 110.2712\n",
      "Epoch 1018/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3256 - val_loss: 110.2753\n",
      "Epoch 1019/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3119 - val_loss: 110.2678\n",
      "Epoch 1020/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.3080 - val_loss: 110.2528\n",
      "Epoch 1021/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2990 - val_loss: 110.2481\n",
      "Epoch 1022/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2955 - val_loss: 110.2327\n",
      "Epoch 1023/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2836 - val_loss: 110.2133\n",
      "Epoch 1024/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2767 - val_loss: 110.2132\n",
      "Epoch 1025/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2713 - val_loss: 110.2290\n",
      "Epoch 1026/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2638 - val_loss: 110.2214\n",
      "Epoch 1027/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2545 - val_loss: 110.2218\n",
      "Epoch 1028/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2475 - val_loss: 110.2165\n",
      "Epoch 1029/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2421 - val_loss: 110.1141\n",
      "Epoch 1030/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2371 - val_loss: 110.0957\n",
      "Epoch 1031/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2248 - val_loss: 110.0952\n",
      "Epoch 1032/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2214 - val_loss: 110.0810\n",
      "Epoch 1033/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2131 - val_loss: 110.0744\n",
      "Epoch 1034/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.2046 - val_loss: 110.0528\n",
      "Epoch 1035/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1976 - val_loss: 110.0487\n",
      "Epoch 1036/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1913 - val_loss: 110.0329\n",
      "Epoch 1037/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1795 - val_loss: 110.0391\n",
      "Epoch 1038/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1729 - val_loss: 110.0350\n",
      "Epoch 1039/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1683 - val_loss: 110.0516\n",
      "Epoch 1040/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1581 - val_loss: 110.0374\n",
      "Epoch 1041/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1539 - val_loss: 110.0326\n",
      "Epoch 1042/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1456 - val_loss: 110.0503\n",
      "Epoch 1043/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1379 - val_loss: 110.0694\n",
      "Epoch 1044/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1335 - val_loss: 110.0694\n",
      "Epoch 1045/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1216 - val_loss: 110.0440\n",
      "Epoch 1046/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1164 - val_loss: 110.0457\n",
      "Epoch 1047/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.1079 - val_loss: 110.0408\n",
      "Epoch 1048/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 97.1047 - val_loss: 110.0216\n",
      "Epoch 1049/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0949 - val_loss: 110.0013\n",
      "Epoch 1050/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0923 - val_loss: 110.0018\n",
      "Epoch 1051/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0813 - val_loss: 109.9891\n",
      "Epoch 1052/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0685 - val_loss: 109.9639\n",
      "Epoch 1053/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0623 - val_loss: 109.9421\n",
      "Epoch 1054/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0548 - val_loss: 109.9476\n",
      "Epoch 1055/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0486 - val_loss: 109.9380\n",
      "Epoch 1056/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0452 - val_loss: 109.9125\n",
      "Epoch 1057/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0346 - val_loss: 109.8941\n",
      "Epoch 1058/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0255 - val_loss: 109.8658\n",
      "Epoch 1059/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0197 - val_loss: 109.8490\n",
      "Epoch 1060/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0116 - val_loss: 109.8341\n",
      "Epoch 1061/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0060 - val_loss: 109.7913\n",
      "Epoch 1062/5000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0003 - val_loss: 109.7868\n",
      "Epoch 1063/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9914 - val_loss: 109.7526\n",
      "Epoch 1064/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9859 - val_loss: 109.7392\n",
      "Epoch 1065/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9765 - val_loss: 109.7251\n",
      "Epoch 1066/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9685 - val_loss: 109.7210\n",
      "Epoch 1067/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9642 - val_loss: 109.7125\n",
      "Epoch 1068/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9563 - val_loss: 109.6480\n",
      "Epoch 1069/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9506 - val_loss: 109.6316\n",
      "Epoch 1070/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9401 - val_loss: 109.6234\n",
      "Epoch 1071/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9344 - val_loss: 109.6314s: 100.183\n",
      "Epoch 1072/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9280 - val_loss: 109.6201\n",
      "Epoch 1073/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9202 - val_loss: 109.6321\n",
      "Epoch 1074/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9116 - val_loss: 109.6231\n",
      "Epoch 1075/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.9062 - val_loss: 109.6139\n",
      "Epoch 1076/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8942 - val_loss: 109.5946\n",
      "Epoch 1077/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8890 - val_loss: 109.5843\n",
      "Epoch 1078/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8836 - val_loss: 109.5714\n",
      "Epoch 1079/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8766 - val_loss: 109.5678\n",
      "Epoch 1080/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8709 - val_loss: 109.5524\n",
      "Epoch 1081/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8605 - val_loss: 109.5451\n",
      "Epoch 1082/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8551 - val_loss: 109.5484\n",
      "Epoch 1083/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8454 - val_loss: 109.5352\n",
      "Epoch 1084/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8433 - val_loss: 109.5305\n",
      "Epoch 1085/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8355 - val_loss: 109.5146\n",
      "Epoch 1086/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8322 - val_loss: 109.5200\n",
      "Epoch 1087/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8243 - val_loss: 109.5107\n",
      "Epoch 1088/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8124 - val_loss: 109.4811\n",
      "Epoch 1089/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8069 - val_loss: 109.4784\n",
      "Epoch 1090/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.8019 - val_loss: 109.4732\n",
      "Epoch 1091/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7924 - val_loss: 109.4351\n",
      "Epoch 1092/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7867 - val_loss: 109.4731\n",
      "Epoch 1093/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7803 - val_loss: 109.4654\n",
      "Epoch 1094/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7738 - val_loss: 109.4537\n",
      "Epoch 1095/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7646 - val_loss: 109.4477\n",
      "Epoch 1096/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7577 - val_loss: 109.4234\n",
      "Epoch 1097/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7526 - val_loss: 109.4256\n",
      "Epoch 1098/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7453 - val_loss: 109.3895\n",
      "Epoch 1099/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7391 - val_loss: 109.3778\n",
      "Epoch 1100/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7338 - val_loss: 109.3712\n",
      "Epoch 1101/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7248 - val_loss: 109.3778\n",
      "Epoch 1102/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7198 - val_loss: 109.3520\n",
      "Epoch 1103/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7122 - val_loss: 109.3393\n",
      "Epoch 1104/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7052 - val_loss: 109.3232\n",
      "Epoch 1105/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7009 - val_loss: 109.3229\n",
      "Epoch 1106/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6946 - val_loss: 109.3045\n",
      "Epoch 1107/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6871 - val_loss: 109.2964\n",
      "Epoch 1108/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6779 - val_loss: 109.2766\n",
      "Epoch 1109/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6723 - val_loss: 109.2665\n",
      "Epoch 1110/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6668 - val_loss: 109.2461\n",
      "Epoch 1111/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6589 - val_loss: 109.2284\n",
      "Epoch 1112/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6572 - val_loss: 109.2223\n",
      "Epoch 1113/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6489 - val_loss: 109.2231\n",
      "Epoch 1114/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6390 - val_loss: 109.2131\n",
      "Epoch 1115/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6330 - val_loss: 109.2026\n",
      "Epoch 1116/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6267 - val_loss: 109.1623\n",
      "Epoch 1117/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6162 - val_loss: 109.1427\n",
      "Epoch 1118/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6084 - val_loss: 109.1431\n",
      "Epoch 1119/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.6045 - val_loss: 109.1402\n",
      "Epoch 1120/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5986 - val_loss: 109.1195\n",
      "Epoch 1121/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5891 - val_loss: 109.0819\n",
      "Epoch 1122/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5801 - val_loss: 109.0817\n",
      "Epoch 1123/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5756 - val_loss: 109.0745\n",
      "Epoch 1124/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5714 - val_loss: 109.0429\n",
      "Epoch 1125/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5640 - val_loss: 109.0390\n",
      "Epoch 1126/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5579 - val_loss: 109.0398\n",
      "Epoch 1127/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5514 - val_loss: 109.0385\n",
      "Epoch 1128/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5439 - val_loss: 109.0262\n",
      "Epoch 1129/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5389 - val_loss: 109.0125\n",
      "Epoch 1130/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5297 - val_loss: 109.0041\n",
      "Epoch 1131/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5249 - val_loss: 108.9828\n",
      "Epoch 1132/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5181 - val_loss: 108.9863\n",
      "Epoch 1133/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5074 - val_loss: 108.9693\n",
      "Epoch 1134/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5065 - val_loss: 108.9608\n",
      "Epoch 1135/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4997 - val_loss: 108.9763\n",
      "Epoch 1136/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4916 - val_loss: 108.9389\n",
      "Epoch 1137/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4873 - val_loss: 108.9274\n",
      "Epoch 1138/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4821 - val_loss: 108.9218\n",
      "Epoch 1139/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4721 - val_loss: 108.9221\n",
      "Epoch 1140/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4656 - val_loss: 108.9132\n",
      "Epoch 1141/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4598 - val_loss: 108.9075\n",
      "Epoch 1142/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4514 - val_loss: 108.8959\n",
      "Epoch 1143/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4491 - val_loss: 108.8840\n",
      "Epoch 1144/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4441 - val_loss: 108.8860\n",
      "Epoch 1145/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4347 - val_loss: 108.8628\n",
      "Epoch 1146/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4265 - val_loss: 108.8271\n",
      "Epoch 1147/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4221 - val_loss: 108.8237\n",
      "Epoch 1148/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4171 - val_loss: 108.7858\n",
      "Epoch 1149/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4095 - val_loss: 108.7921\n",
      "Epoch 1150/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.4019 - val_loss: 108.7837\n",
      "Epoch 1151/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3974 - val_loss: 108.7091\n",
      "Epoch 1152/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3898 - val_loss: 108.6910\n",
      "Epoch 1153/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3831 - val_loss: 108.6809\n",
      "Epoch 1154/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3792 - val_loss: 108.6718\n",
      "Epoch 1155/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3693 - val_loss: 108.6730\n",
      "Epoch 1156/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3643 - val_loss: 108.6724\n",
      "Epoch 1157/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3561 - val_loss: 108.6610\n",
      "Epoch 1158/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3491 - val_loss: 108.6571\n",
      "Epoch 1159/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3433 - val_loss: 108.6464\n",
      "Epoch 1160/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3380 - val_loss: 108.6288\n",
      "Epoch 1161/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3305 - val_loss: 108.6252\n",
      "Epoch 1162/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3272 - val_loss: 108.6162\n",
      "Epoch 1163/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3179 - val_loss: 108.6041\n",
      "Epoch 1164/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3107 - val_loss: 108.5952\n",
      "Epoch 1165/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3055 - val_loss: 108.5669\n",
      "Epoch 1166/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3001 - val_loss: 108.5620\n",
      "Epoch 1167/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2961 - val_loss: 108.5847\n",
      "Epoch 1168/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2927 - val_loss: 108.5762\n",
      "Epoch 1169/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2809 - val_loss: 108.5675\n",
      "Epoch 1170/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2724 - val_loss: 108.5595\n",
      "Epoch 1171/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2691 - val_loss: 108.5590\n",
      "Epoch 1172/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2617 - val_loss: 108.5249\n",
      "Epoch 1173/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2565 - val_loss: 108.5256\n",
      "Epoch 1174/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2491 - val_loss: 108.5162\n",
      "Epoch 1175/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2420 - val_loss: 108.5107\n",
      "Epoch 1176/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2399 - val_loss: 108.5034\n",
      "Epoch 1177/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2336 - val_loss: 108.4958\n",
      "Epoch 1178/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2236 - val_loss: 108.4745\n",
      "Epoch 1179/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 99.137 - 0s - loss: 96.2211 - val_loss: 108.4654\n",
      "Epoch 1180/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2164 - val_loss: 108.4266\n",
      "Epoch 1181/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2067 - val_loss: 108.4344\n",
      "Epoch 1182/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.2003 - val_loss: 108.4248\n",
      "Epoch 1183/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1994 - val_loss: 108.4337\n",
      "Epoch 1184/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1853 - val_loss: 108.4344\n",
      "Epoch 1185/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1806 - val_loss: 108.4195\n",
      "Epoch 1186/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1752 - val_loss: 108.4040\n",
      "Epoch 1187/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1661 - val_loss: 108.4185\n",
      "Epoch 1188/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1603 - val_loss: 108.4051\n",
      "Epoch 1189/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1543 - val_loss: 108.4092\n",
      "Epoch 1190/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1474 - val_loss: 108.4010\n",
      "Epoch 1191/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1461 - val_loss: 108.4030\n",
      "Epoch 1192/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1374 - val_loss: 108.3913\n",
      "Epoch 1193/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1328 - val_loss: 108.3857\n",
      "Epoch 1194/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1268 - val_loss: 108.3819\n",
      "Epoch 1195/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1204 - val_loss: 108.3825\n",
      "Epoch 1196/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1129 - val_loss: 108.4404\n",
      "Epoch 1197/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1064 - val_loss: 108.4498\n",
      "Epoch 1198/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1004 - val_loss: 108.4432\n",
      "Epoch 1199/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0951 - val_loss: 108.4268\n",
      "Epoch 1200/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0864 - val_loss: 108.4171\n",
      "Epoch 1201/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0831 - val_loss: 108.3786\n",
      "Epoch 1202/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0795 - val_loss: 108.3670\n",
      "Epoch 1203/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0693 - val_loss: 108.3486\n",
      "Epoch 1204/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0638 - val_loss: 108.3416\n",
      "Epoch 1205/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0582 - val_loss: 108.3018\n",
      "Epoch 1206/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0544 - val_loss: 108.2874\n",
      "Epoch 1207/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0471 - val_loss: 108.2602\n",
      "Epoch 1208/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0408 - val_loss: 108.2603\n",
      "Epoch 1209/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0340 - val_loss: 108.2480\n",
      "Epoch 1210/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 96.0281 - val_loss: 108.2354\n",
      "Epoch 1211/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0257 - val_loss: 108.2262\n",
      "Epoch 1212/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0150 - val_loss: 108.2549\n",
      "Epoch 1213/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0114 - val_loss: 108.2583\n",
      "Epoch 1214/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0042 - val_loss: 108.2460\n",
      "Epoch 1215/5000\n",
      "1126/1126 [==============================] - 0s - loss: 96.0003 - val_loss: 108.2333\n",
      "Epoch 1216/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9902 - val_loss: 108.2159\n",
      "Epoch 1217/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9865 - val_loss: 108.2033\n",
      "Epoch 1218/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9799 - val_loss: 108.1709\n",
      "Epoch 1219/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9705 - val_loss: 108.1492\n",
      "Epoch 1220/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9675 - val_loss: 108.1401\n",
      "Epoch 1221/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9612 - val_loss: 108.1259\n",
      "Epoch 1222/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9551 - val_loss: 108.1317\n",
      "Epoch 1223/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9496 - val_loss: 108.1498\n",
      "Epoch 1224/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9414 - val_loss: 108.1278\n",
      "Epoch 1225/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9375 - val_loss: 108.1130\n",
      "Epoch 1226/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9312 - val_loss: 108.0963\n",
      "Epoch 1227/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9256 - val_loss: 108.0847\n",
      "Epoch 1228/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9200 - val_loss: 108.0772\n",
      "Epoch 1229/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9131 - val_loss: 108.0635\n",
      "Epoch 1230/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9087 - val_loss: 108.0490\n",
      "Epoch 1231/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9004 - val_loss: 108.0477\n",
      "Epoch 1232/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8943 - val_loss: 108.0384\n",
      "Epoch 1233/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8875 - val_loss: 108.0202\n",
      "Epoch 1234/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8831 - val_loss: 108.0255\n",
      "Epoch 1235/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8750 - val_loss: 108.0028\n",
      "Epoch 1236/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8726 - val_loss: 107.9837\n",
      "Epoch 1237/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8637 - val_loss: 107.9610\n",
      "Epoch 1238/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8578 - val_loss: 107.9979\n",
      "Epoch 1239/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8541 - val_loss: 107.9829\n",
      "Epoch 1240/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8448 - val_loss: 107.9633\n",
      "Epoch 1241/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8381 - val_loss: 107.9568\n",
      "Epoch 1242/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8358 - val_loss: 107.9717\n",
      "Epoch 1243/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8299 - val_loss: 107.9404\n",
      "Epoch 1244/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8228 - val_loss: 107.9276\n",
      "Epoch 1245/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8145 - val_loss: 107.9291\n",
      "Epoch 1246/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8109 - val_loss: 107.9162\n",
      "Epoch 1247/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.8010 - val_loss: 107.9011\n",
      "Epoch 1248/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7975 - val_loss: 107.9049\n",
      "Epoch 1249/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7909 - val_loss: 107.8907\n",
      "Epoch 1250/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7829 - val_loss: 107.8828\n",
      "Epoch 1251/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7781 - val_loss: 107.8594\n",
      "Epoch 1252/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7737 - val_loss: 107.8494\n",
      "Epoch 1253/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7656 - val_loss: 107.8604\n",
      "Epoch 1254/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7580 - val_loss: 107.8231\n",
      "Epoch 1255/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7515 - val_loss: 107.8018\n",
      "Epoch 1256/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7472 - val_loss: 107.7909\n",
      "Epoch 1257/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7418 - val_loss: 107.8077\n",
      "Epoch 1258/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7314 - val_loss: 107.8157\n",
      "Epoch 1259/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7242 - val_loss: 107.7679\n",
      "Epoch 1260/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7185 - val_loss: 107.7743\n",
      "Epoch 1261/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7149 - val_loss: 107.7662\n",
      "Epoch 1262/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7059 - val_loss: 107.7551\n",
      "Epoch 1263/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6990 - val_loss: 107.7427\n",
      "Epoch 1264/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6912 - val_loss: 107.7252\n",
      "Epoch 1265/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6859 - val_loss: 107.7133\n",
      "Epoch 1266/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6798 - val_loss: 107.6894\n",
      "Epoch 1267/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6711 - val_loss: 107.6747\n",
      "Epoch 1268/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6645 - val_loss: 107.6718\n",
      "Epoch 1269/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6603 - val_loss: 107.7095\n",
      "Epoch 1270/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6519 - val_loss: 107.7308\n",
      "Epoch 1271/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6470 - val_loss: 107.7382\n",
      "Epoch 1272/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6375 - val_loss: 107.7202\n",
      "Epoch 1273/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6340 - val_loss: 107.7016\n",
      "Epoch 1274/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6296 - val_loss: 107.6885\n",
      "Epoch 1275/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6189 - val_loss: 107.6518\n",
      "Epoch 1276/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6157 - val_loss: 107.6454\n",
      "Epoch 1277/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6063 - val_loss: 107.6329\n",
      "Epoch 1278/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6026 - val_loss: 107.5934\n",
      "Epoch 1279/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5955 - val_loss: 107.5997\n",
      "Epoch 1280/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5884 - val_loss: 107.5930\n",
      "Epoch 1281/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5833 - val_loss: 107.5884\n",
      "Epoch 1282/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5752 - val_loss: 107.6011\n",
      "Epoch 1283/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5694 - val_loss: 107.5906\n",
      "Epoch 1284/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5647 - val_loss: 107.5855\n",
      "Epoch 1285/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5577 - val_loss: 107.5699\n",
      "Epoch 1286/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5507 - val_loss: 107.5766\n",
      "Epoch 1287/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5409 - val_loss: 107.5565\n",
      "Epoch 1288/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5420 - val_loss: 107.5532\n",
      "Epoch 1289/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5333 - val_loss: 107.5401\n",
      "Epoch 1290/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5266 - val_loss: 107.5307\n",
      "Epoch 1291/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5183 - val_loss: 107.5139\n",
      "Epoch 1292/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5151 - val_loss: 107.5014\n",
      "Epoch 1293/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5075 - val_loss: 107.4880\n",
      "Epoch 1294/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.5012 - val_loss: 107.4758\n",
      "Epoch 1295/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4912 - val_loss: 107.4724\n",
      "Epoch 1296/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4872 - val_loss: 107.4570\n",
      "Epoch 1297/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4802 - val_loss: 107.4251\n",
      "Epoch 1298/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4744 - val_loss: 107.4138\n",
      "Epoch 1299/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4650 - val_loss: 107.3854\n",
      "Epoch 1300/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4647 - val_loss: 107.3888\n",
      "Epoch 1301/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4558 - val_loss: 107.3937\n",
      "Epoch 1302/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4495 - val_loss: 107.4027\n",
      "Epoch 1303/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4451 - val_loss: 107.4069\n",
      "Epoch 1304/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4380 - val_loss: 107.3873\n",
      "Epoch 1305/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4307 - val_loss: 107.3685\n",
      "Epoch 1306/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4265 - val_loss: 107.3601\n",
      "Epoch 1307/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4190 - val_loss: 107.3339\n",
      "Epoch 1308/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4098 - val_loss: 107.3244\n",
      "Epoch 1309/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.4066 - val_loss: 107.3075\n",
      "Epoch 1310/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3983 - val_loss: 107.2956\n",
      "Epoch 1311/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3939 - val_loss: 107.3003\n",
      "Epoch 1312/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3870 - val_loss: 107.2910\n",
      "Epoch 1313/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3792 - val_loss: 107.2841\n",
      "Epoch 1314/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3777 - val_loss: 107.2718\n",
      "Epoch 1315/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3671 - val_loss: 107.2488\n",
      "Epoch 1316/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3640 - val_loss: 107.2424\n",
      "Epoch 1317/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3552 - val_loss: 107.2361\n",
      "Epoch 1318/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3495 - val_loss: 107.2223\n",
      "Epoch 1319/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3425 - val_loss: 107.2372\n",
      "Epoch 1320/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3361 - val_loss: 107.2221\n",
      "Epoch 1321/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3319 - val_loss: 107.1856\n",
      "Epoch 1322/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3231 - val_loss: 107.1985\n",
      "Epoch 1323/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3165 - val_loss: 107.1910\n",
      "Epoch 1324/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3108 - val_loss: 107.1647\n",
      "Epoch 1325/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3043 - val_loss: 107.1630\n",
      "Epoch 1326/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2961 - val_loss: 107.1456\n",
      "Epoch 1327/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2952 - val_loss: 107.1240\n",
      "Epoch 1328/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2860 - val_loss: 107.1307\n",
      "Epoch 1329/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2802 - val_loss: 107.1122\n",
      "Epoch 1330/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2742 - val_loss: 107.1314\n",
      "Epoch 1331/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2669 - val_loss: 107.0914\n",
      "Epoch 1332/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2629 - val_loss: 107.0861\n",
      "Epoch 1333/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2535 - val_loss: 107.0801\n",
      "Epoch 1334/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2494 - val_loss: 107.0713\n",
      "Epoch 1335/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2424 - val_loss: 107.0595\n",
      "Epoch 1336/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2377 - val_loss: 107.0614\n",
      "Epoch 1337/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2302 - val_loss: 107.0511\n",
      "Epoch 1338/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2239 - val_loss: 107.0292\n",
      "Epoch 1339/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2197 - val_loss: 106.9823\n",
      "Epoch 1340/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2113 - val_loss: 106.9728\n",
      "Epoch 1341/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2060 - val_loss: 106.9654\n",
      "Epoch 1342/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1984 - val_loss: 106.9609\n",
      "Epoch 1343/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1935 - val_loss: 106.9524\n",
      "Epoch 1344/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1882 - val_loss: 106.9443\n",
      "Epoch 1345/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1810 - val_loss: 106.9303\n",
      "Epoch 1346/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1733 - val_loss: 106.9128\n",
      "Epoch 1347/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1692 - val_loss: 106.8972\n",
      "Epoch 1348/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1621 - val_loss: 106.8892\n",
      "Epoch 1349/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1549 - val_loss: 106.8844\n",
      "Epoch 1350/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1490 - val_loss: 106.8623\n",
      "Epoch 1351/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1445 - val_loss: 106.8401\n",
      "Epoch 1352/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1378 - val_loss: 106.8232\n",
      "Epoch 1353/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1317 - val_loss: 106.8012\n",
      "Epoch 1354/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1249 - val_loss: 106.7987\n",
      "Epoch 1355/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1192 - val_loss: 106.7773\n",
      "Epoch 1356/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1123 - val_loss: 106.7735\n",
      "Epoch 1357/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1072 - val_loss: 106.7550\n",
      "Epoch 1358/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.1005 - val_loss: 106.7476\n",
      "Epoch 1359/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0962 - val_loss: 106.7394\n",
      "Epoch 1360/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0888 - val_loss: 106.7328\n",
      "Epoch 1361/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0800 - val_loss: 106.6856\n",
      "Epoch 1362/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0770 - val_loss: 106.6816\n",
      "Epoch 1363/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0701 - val_loss: 106.6814\n",
      "Epoch 1364/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0630 - val_loss: 106.6793\n",
      "Epoch 1365/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0581 - val_loss: 106.6718\n",
      "Epoch 1366/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0514 - val_loss: 106.6647\n",
      "Epoch 1367/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0463 - val_loss: 106.6507\n",
      "Epoch 1368/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0381 - val_loss: 106.6594\n",
      "Epoch 1369/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0361 - val_loss: 106.6336\n",
      "Epoch 1370/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0285 - val_loss: 106.6203\n",
      "Epoch 1371/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0229 - val_loss: 106.5990\n",
      "Epoch 1372/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 95.0160 - val_loss: 106.5935\n",
      "Epoch 1373/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0071 - val_loss: 106.5831\n",
      "Epoch 1374/5000\n",
      "1126/1126 [==============================] - 0s - loss: 95.0030 - val_loss: 106.5727\n",
      "Epoch 1375/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9993 - val_loss: 106.5474\n",
      "Epoch 1376/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9921 - val_loss: 106.5474\n",
      "Epoch 1377/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9865 - val_loss: 106.5510\n",
      "Epoch 1378/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9793 - val_loss: 106.5386\n",
      "Epoch 1379/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9760 - val_loss: 106.5250\n",
      "Epoch 1380/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9687 - val_loss: 106.5203\n",
      "Epoch 1381/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9620 - val_loss: 106.5043\n",
      "Epoch 1382/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9563 - val_loss: 106.4960\n",
      "Epoch 1383/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9501 - val_loss: 106.5151\n",
      "Epoch 1384/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9448 - val_loss: 106.5017\n",
      "Epoch 1385/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9341 - val_loss: 106.4905\n",
      "Epoch 1386/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9305 - val_loss: 106.4722\n",
      "Epoch 1387/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9228 - val_loss: 106.4849\n",
      "Epoch 1388/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9160 - val_loss: 106.4739\n",
      "Epoch 1389/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9117 - val_loss: 106.4331\n",
      "Epoch 1390/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9025 - val_loss: 106.4249\n",
      "Epoch 1391/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8974 - val_loss: 106.4350\n",
      "Epoch 1392/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8931 - val_loss: 106.4258\n",
      "Epoch 1393/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8851 - val_loss: 106.4469\n",
      "Epoch 1394/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8808 - val_loss: 106.4257\n",
      "Epoch 1395/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8752 - val_loss: 106.4081\n",
      "Epoch 1396/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8687 - val_loss: 106.3614\n",
      "Epoch 1397/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8611 - val_loss: 106.3649\n",
      "Epoch 1398/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8547 - val_loss: 106.3450\n",
      "Epoch 1399/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8504 - val_loss: 106.3474\n",
      "Epoch 1400/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8439 - val_loss: 106.3338\n",
      "Epoch 1401/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8374 - val_loss: 106.3171\n",
      "Epoch 1402/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8296 - val_loss: 106.3005\n",
      "Epoch 1403/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8244 - val_loss: 106.2783\n",
      "Epoch 1404/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8186 - val_loss: 106.2707\n",
      "Epoch 1405/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8120 - val_loss: 106.2358\n",
      "Epoch 1406/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8069 - val_loss: 106.2288\n",
      "Epoch 1407/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8000 - val_loss: 106.2177\n",
      "Epoch 1408/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7952 - val_loss: 106.2172\n",
      "Epoch 1409/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7880 - val_loss: 106.2416\n",
      "Epoch 1410/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7821 - val_loss: 106.2349\n",
      "Epoch 1411/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7768 - val_loss: 106.2229\n",
      "Epoch 1412/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7704 - val_loss: 106.2320\n",
      "Epoch 1413/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7668 - val_loss: 106.2100\n",
      "Epoch 1414/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7602 - val_loss: 106.2064\n",
      "Epoch 1415/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7523 - val_loss: 106.1919\n",
      "Epoch 1416/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7455 - val_loss: 106.1781\n",
      "Epoch 1417/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7414 - val_loss: 106.1750\n",
      "Epoch 1418/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7323 - val_loss: 106.1651\n",
      "Epoch 1419/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7301 - val_loss: 106.1759\n",
      "Epoch 1420/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7233 - val_loss: 106.1734\n",
      "Epoch 1421/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7175 - val_loss: 106.1609\n",
      "Epoch 1422/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7150 - val_loss: 106.1378\n",
      "Epoch 1423/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.7051 - val_loss: 106.1247\n",
      "Epoch 1424/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6987 - val_loss: 106.1000\n",
      "Epoch 1425/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6914 - val_loss: 106.1117\n",
      "Epoch 1426/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6920 - val_loss: 106.1004\n",
      "Epoch 1427/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6804 - val_loss: 106.0878\n",
      "Epoch 1428/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6787 - val_loss: 106.0874\n",
      "Epoch 1429/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6682 - val_loss: 106.0659\n",
      "Epoch 1430/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6617 - val_loss: 106.0580\n",
      "Epoch 1431/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6550 - val_loss: 106.0473\n",
      "Epoch 1432/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6505 - val_loss: 106.0410\n",
      "Epoch 1433/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6468 - val_loss: 106.0462\n",
      "Epoch 1434/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6424 - val_loss: 106.0360\n",
      "Epoch 1435/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6311 - val_loss: 106.0382\n",
      "Epoch 1436/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6312 - val_loss: 106.0259\n",
      "Epoch 1437/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6240 - val_loss: 106.0108\n",
      "Epoch 1438/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6131 - val_loss: 105.9862\n",
      "Epoch 1439/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6097 - val_loss: 105.9753\n",
      "Epoch 1440/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6037 - val_loss: 105.9646\n",
      "Epoch 1441/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.6003 - val_loss: 105.9585\n",
      "Epoch 1442/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5902 - val_loss: 105.9470\n",
      "Epoch 1443/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5844 - val_loss: 105.9435\n",
      "Epoch 1444/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5802 - val_loss: 105.9422\n",
      "Epoch 1445/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5762 - val_loss: 105.9037\n",
      "Epoch 1446/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5666 - val_loss: 105.8937\n",
      "Epoch 1447/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5646 - val_loss: 105.8704\n",
      "Epoch 1448/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5550 - val_loss: 105.8567\n",
      "Epoch 1449/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5508 - val_loss: 105.8374\n",
      "Epoch 1450/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5443 - val_loss: 105.8451\n",
      "Epoch 1451/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5387 - val_loss: 105.8325\n",
      "Epoch 1452/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5347 - val_loss: 105.8263\n",
      "Epoch 1453/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5273 - val_loss: 105.8213\n",
      "Epoch 1454/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5243 - val_loss: 105.7923\n",
      "Epoch 1455/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5167 - val_loss: 105.7856\n",
      "Epoch 1456/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5097 - val_loss: 105.7733\n",
      "Epoch 1457/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5057 - val_loss: 105.7187\n",
      "Epoch 1458/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4973 - val_loss: 105.7105\n",
      "Epoch 1459/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4942 - val_loss: 105.6892\n",
      "Epoch 1460/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4894 - val_loss: 105.7021\n",
      "Epoch 1461/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4840 - val_loss: 105.6937\n",
      "Epoch 1462/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4767 - val_loss: 105.6862\n",
      "Epoch 1463/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4699 - val_loss: 105.6779\n",
      "Epoch 1464/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4616 - val_loss: 105.6677\n",
      "Epoch 1465/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4582 - val_loss: 105.6507\n",
      "Epoch 1466/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4535 - val_loss: 105.6381\n",
      "Epoch 1467/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4462 - val_loss: 105.6294\n",
      "Epoch 1468/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4442 - val_loss: 105.6367\n",
      "Epoch 1469/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4388 - val_loss: 105.6415\n",
      "Epoch 1470/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4303 - val_loss: 105.6409\n",
      "Epoch 1471/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4222 - val_loss: 105.6329\n",
      "Epoch 1472/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4152 - val_loss: 105.6472\n",
      "Epoch 1473/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4109 - val_loss: 105.6408\n",
      "Epoch 1474/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4065 - val_loss: 105.6546\n",
      "Epoch 1475/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3998 - val_loss: 105.6321\n",
      "Epoch 1476/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3968 - val_loss: 105.6181\n",
      "Epoch 1477/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3877 - val_loss: 105.6088\n",
      "Epoch 1478/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3823 - val_loss: 105.6104\n",
      "Epoch 1479/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3773 - val_loss: 105.6015\n",
      "Epoch 1480/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3724 - val_loss: 105.5989\n",
      "Epoch 1481/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3699 - val_loss: 105.5950\n",
      "Epoch 1482/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3600 - val_loss: 105.5997\n",
      "Epoch 1483/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3533 - val_loss: 105.5997\n",
      "Epoch 1484/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3514 - val_loss: 105.5950\n",
      "Epoch 1485/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3418 - val_loss: 105.5869\n",
      "Epoch 1486/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3397 - val_loss: 105.5726\n",
      "Epoch 1487/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3305 - val_loss: 105.5564\n",
      "Epoch 1488/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3278 - val_loss: 105.5380\n",
      "Epoch 1489/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3200 - val_loss: 105.5381\n",
      "Epoch 1490/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3133 - val_loss: 105.5458\n",
      "Epoch 1491/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3112 - val_loss: 105.5327\n",
      "Epoch 1492/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.3019 - val_loss: 105.5236\n",
      "Epoch 1493/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2965 - val_loss: 105.5067\n",
      "Epoch 1494/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2946 - val_loss: 105.4984 94.31\n",
      "Epoch 1495/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2876 - val_loss: 105.4846\n",
      "Epoch 1496/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2809 - val_loss: 105.4882\n",
      "Epoch 1497/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2767 - val_loss: 105.4890\n",
      "Epoch 1498/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2742 - val_loss: 105.4960\n",
      "Epoch 1499/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2659 - val_loss: 105.4732\n",
      "Epoch 1500/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2609 - val_loss: 105.4474\n",
      "Epoch 1501/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2549 - val_loss: 105.4366\n",
      "Epoch 1502/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2488 - val_loss: 105.4438\n",
      "Epoch 1503/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2421 - val_loss: 105.4364\n",
      "Epoch 1504/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2360 - val_loss: 105.4337\n",
      "Epoch 1505/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2301 - val_loss: 105.4195\n",
      "Epoch 1506/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2260 - val_loss: 105.4162\n",
      "Epoch 1507/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2211 - val_loss: 105.4329\n",
      "Epoch 1508/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2149 - val_loss: 105.4254\n",
      "Epoch 1509/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2102 - val_loss: 105.4113\n",
      "Epoch 1510/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2057 - val_loss: 105.3879\n",
      "Epoch 1511/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1992 - val_loss: 105.3933\n",
      "Epoch 1512/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1949 - val_loss: 105.3914\n",
      "Epoch 1513/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1861 - val_loss: 105.3767\n",
      "Epoch 1514/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1824 - val_loss: 105.3891\n",
      "Epoch 1515/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1767 - val_loss: 105.3995\n",
      "Epoch 1516/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1721 - val_loss: 105.3828\n",
      "Epoch 1517/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1661 - val_loss: 105.3714\n",
      "Epoch 1518/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1611 - val_loss: 105.3604\n",
      "Epoch 1519/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1562 - val_loss: 105.3478\n",
      "Epoch 1520/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1499 - val_loss: 105.3350\n",
      "Epoch 1521/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1442 - val_loss: 105.3038\n",
      "Epoch 1522/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1380 - val_loss: 105.3072\n",
      "Epoch 1523/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1306 - val_loss: 105.3106\n",
      "Epoch 1524/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1297 - val_loss: 105.2951\n",
      "Epoch 1525/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1198 - val_loss: 105.2777\n",
      "Epoch 1526/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1171 - val_loss: 105.2661\n",
      "Epoch 1527/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1123 - val_loss: 105.2598\n",
      "Epoch 1528/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.1034 - val_loss: 105.2623\n",
      "Epoch 1529/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0986 - val_loss: 105.2634\n",
      "Epoch 1530/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0911 - val_loss: 105.2597\n",
      "Epoch 1531/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0875 - val_loss: 105.2549\n",
      "Epoch 1532/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0820 - val_loss: 105.2402\n",
      "Epoch 1533/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0767 - val_loss: 105.2352\n",
      "Epoch 1534/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 94.0724 - val_loss: 105.2496\n",
      "Epoch 1535/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0672 - val_loss: 105.2343\n",
      "Epoch 1536/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0611 - val_loss: 105.2207\n",
      "Epoch 1537/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0546 - val_loss: 105.2087\n",
      "Epoch 1538/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0518 - val_loss: 105.1935\n",
      "Epoch 1539/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0464 - val_loss: 105.1866\n",
      "Epoch 1540/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0398 - val_loss: 105.1721\n",
      "Epoch 1541/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0366 - val_loss: 105.1593\n",
      "Epoch 1542/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0281 - val_loss: 105.1395\n",
      "Epoch 1543/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0233 - val_loss: 105.1177\n",
      "Epoch 1544/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0150 - val_loss: 105.1151\n",
      "Epoch 1545/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0114 - val_loss: 105.1075\n",
      "Epoch 1546/5000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0077 - val_loss: 105.1034\n",
      "Epoch 1547/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9982 - val_loss: 105.0994\n",
      "Epoch 1548/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9939 - val_loss: 105.0846\n",
      "Epoch 1549/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9918 - val_loss: 105.0568\n",
      "Epoch 1550/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9853 - val_loss: 105.0362\n",
      "Epoch 1551/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9791 - val_loss: 105.0356\n",
      "Epoch 1552/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9739 - val_loss: 104.9987\n",
      "Epoch 1553/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9709 - val_loss: 104.9708\n",
      "Epoch 1554/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9634 - val_loss: 104.9002 94.52\n",
      "Epoch 1555/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9604 - val_loss: 104.9220\n",
      "Epoch 1556/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 93.97 - 0s - loss: 93.9524 - val_loss: 104.9383\n",
      "Epoch 1557/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9472 - val_loss: 104.9284\n",
      "Epoch 1558/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9439 - val_loss: 104.9253\n",
      "Epoch 1559/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9352 - val_loss: 104.9275\n",
      "Epoch 1560/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9331 - val_loss: 104.9163\n",
      "Epoch 1561/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9248 - val_loss: 104.9114\n",
      "Epoch 1562/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9214 - val_loss: 104.9186\n",
      "Epoch 1563/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9143 - val_loss: 104.8895\n",
      "Epoch 1564/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9151 - val_loss: 104.8789\n",
      "Epoch 1565/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9059 - val_loss: 104.8952\n",
      "Epoch 1566/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8999 - val_loss: 104.8810\n",
      "Epoch 1567/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8933 - val_loss: 104.8676\n",
      "Epoch 1568/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8840 - val_loss: 104.8625\n",
      "Epoch 1569/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8843 - val_loss: 104.8534\n",
      "Epoch 1570/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8791 - val_loss: 104.8583\n",
      "Epoch 1571/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8705 - val_loss: 104.8442\n",
      "Epoch 1572/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8651 - val_loss: 104.8265\n",
      "Epoch 1573/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8601 - val_loss: 104.8187\n",
      "Epoch 1574/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8553 - val_loss: 104.8045\n",
      "Epoch 1575/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8496 - val_loss: 104.8101\n",
      "Epoch 1576/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8483 - val_loss: 104.8048\n",
      "Epoch 1577/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8390 - val_loss: 104.7800\n",
      "Epoch 1578/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8313 - val_loss: 104.7584\n",
      "Epoch 1579/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8286 - val_loss: 104.7540\n",
      "Epoch 1580/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8203 - val_loss: 104.7542\n",
      "Epoch 1581/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8181 - val_loss: 104.7521\n",
      "Epoch 1582/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8113 - val_loss: 104.7383\n",
      "Epoch 1583/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8093 - val_loss: 104.7202\n",
      "Epoch 1584/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.8017 - val_loss: 104.7069\n",
      "Epoch 1585/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7956 - val_loss: 104.6979\n",
      "Epoch 1586/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7911 - val_loss: 104.6938\n",
      "Epoch 1587/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7873 - val_loss: 104.6918\n",
      "Epoch 1588/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7818 - val_loss: 104.6985\n",
      "Epoch 1589/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7761 - val_loss: 104.6884\n",
      "Epoch 1590/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7717 - val_loss: 104.6734\n",
      "Epoch 1591/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7646 - val_loss: 104.6637\n",
      "Epoch 1592/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7607 - val_loss: 104.6478\n",
      "Epoch 1593/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7514 - val_loss: 104.6475\n",
      "Epoch 1594/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7490 - val_loss: 104.6518\n",
      "Epoch 1595/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7452 - val_loss: 104.6723\n",
      "Epoch 1596/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7378 - val_loss: 104.6743\n",
      "Epoch 1597/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7313 - val_loss: 104.6652\n",
      "Epoch 1598/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7268 - val_loss: 104.6369\n",
      "Epoch 1599/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7200 - val_loss: 104.6323\n",
      "Epoch 1600/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7159 - val_loss: 104.6378\n",
      "Epoch 1601/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7139 - val_loss: 104.6093\n",
      "Epoch 1602/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7054 - val_loss: 104.5913\n",
      "Epoch 1603/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.7020 - val_loss: 104.5665\n",
      "Epoch 1604/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6973 - val_loss: 104.5600\n",
      "Epoch 1605/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6913 - val_loss: 104.5662\n",
      "Epoch 1606/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6856 - val_loss: 104.5552\n",
      "Epoch 1607/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6778 - val_loss: 104.5534\n",
      "Epoch 1608/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6774 - val_loss: 104.4972\n",
      "Epoch 1609/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6750 - val_loss: 104.4975\n",
      "Epoch 1610/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6676 - val_loss: 104.4959\n",
      "Epoch 1611/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6607 - val_loss: 104.4858\n",
      "Epoch 1612/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6547 - val_loss: 104.4629\n",
      "Epoch 1613/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6505 - val_loss: 104.4513\n",
      "Epoch 1614/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6446 - val_loss: 104.4584\n",
      "Epoch 1615/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6404 - val_loss: 104.4478\n",
      "Epoch 1616/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6353 - val_loss: 104.4256\n",
      "Epoch 1617/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6277 - val_loss: 104.4241\n",
      "Epoch 1618/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6232 - val_loss: 104.4228\n",
      "Epoch 1619/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6195 - val_loss: 104.4247\n",
      "Epoch 1620/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6129 - val_loss: 104.4096\n",
      "Epoch 1621/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6078 - val_loss: 104.3948\n",
      "Epoch 1622/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6029 - val_loss: 104.3928\n",
      "Epoch 1623/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5978 - val_loss: 104.3890\n",
      "Epoch 1624/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5894 - val_loss: 104.3897\n",
      "Epoch 1625/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5881 - val_loss: 104.3775\n",
      "Epoch 1626/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5846 - val_loss: 104.3399\n",
      "Epoch 1627/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5758 - val_loss: 104.3362\n",
      "Epoch 1628/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5701 - val_loss: 104.3261\n",
      "Epoch 1629/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5650 - val_loss: 104.3306\n",
      "Epoch 1630/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5594 - val_loss: 104.3391\n",
      "Epoch 1631/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5526 - val_loss: 104.3165\n",
      "Epoch 1632/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5509 - val_loss: 104.3198\n",
      "Epoch 1633/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5476 - val_loss: 104.3099\n",
      "Epoch 1634/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5384 - val_loss: 104.2973\n",
      "Epoch 1635/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5303 - val_loss: 104.2900\n",
      "Epoch 1636/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5294 - val_loss: 104.2744\n",
      "Epoch 1637/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5202 - val_loss: 104.2760 93.70\n",
      "Epoch 1638/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5189 - val_loss: 104.2807\n",
      "Epoch 1639/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5153 - val_loss: 104.2758\n",
      "Epoch 1640/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5080 - val_loss: 104.2558\n",
      "Epoch 1641/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5059 - val_loss: 104.2508\n",
      "Epoch 1642/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4966 - val_loss: 104.2461\n",
      "Epoch 1643/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4899 - val_loss: 104.2280\n",
      "Epoch 1644/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4864 - val_loss: 104.2228\n",
      "Epoch 1645/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4827 - val_loss: 104.2094\n",
      "Epoch 1646/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4780 - val_loss: 104.2060\n",
      "Epoch 1647/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4706 - val_loss: 104.2022\n",
      "Epoch 1648/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4654 - val_loss: 104.1966\n",
      "Epoch 1649/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4627 - val_loss: 104.1942\n",
      "Epoch 1650/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4572 - val_loss: 104.1867\n",
      "Epoch 1651/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4529 - val_loss: 104.1827\n",
      "Epoch 1652/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4498 - val_loss: 104.1620\n",
      "Epoch 1653/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4421 - val_loss: 104.1435\n",
      "Epoch 1654/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4348 - val_loss: 104.1288\n",
      "Epoch 1655/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4324 - val_loss: 104.1211\n",
      "Epoch 1656/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4274 - val_loss: 104.1146\n",
      "Epoch 1657/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4213 - val_loss: 104.1140\n",
      "Epoch 1658/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4158 - val_loss: 104.1080\n",
      "Epoch 1659/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4123 - val_loss: 104.0983\n",
      "Epoch 1660/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4029 - val_loss: 104.1073\n",
      "Epoch 1661/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.4022 - val_loss: 104.0969\n",
      "Epoch 1662/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3940 - val_loss: 104.0913\n",
      "Epoch 1663/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3937 - val_loss: 104.1034\n",
      "Epoch 1664/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3862 - val_loss: 104.1154\n",
      "Epoch 1665/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3788 - val_loss: 104.1069\n",
      "Epoch 1666/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3752 - val_loss: 104.1085\n",
      "Epoch 1667/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3699 - val_loss: 104.1271\n",
      "Epoch 1668/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3658 - val_loss: 104.1224\n",
      "Epoch 1669/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3602 - val_loss: 104.1237\n",
      "Epoch 1670/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3569 - val_loss: 104.1153\n",
      "Epoch 1671/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3516 - val_loss: 104.1087\n",
      "Epoch 1672/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3441 - val_loss: 104.1019\n",
      "Epoch 1673/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3393 - val_loss: 104.0896\n",
      "Epoch 1674/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3353 - val_loss: 104.0799\n",
      "Epoch 1675/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3286 - val_loss: 104.0692\n",
      "Epoch 1676/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3232 - val_loss: 104.0539\n",
      "Epoch 1677/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3189 - val_loss: 104.0418\n",
      "Epoch 1678/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3146 - val_loss: 104.0472\n",
      "Epoch 1679/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3066 - val_loss: 104.0363\n",
      "Epoch 1680/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.3032 - val_loss: 104.0290\n",
      "Epoch 1681/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2966 - val_loss: 104.0211\n",
      "Epoch 1682/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2928 - val_loss: 104.0114\n",
      "Epoch 1683/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2890 - val_loss: 104.0074\n",
      "Epoch 1684/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2850 - val_loss: 104.0489\n",
      "Epoch 1685/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2783 - val_loss: 104.0311\n",
      "Epoch 1686/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2749 - val_loss: 104.0071\n",
      "Epoch 1687/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2695 - val_loss: 103.9795\n",
      "Epoch 1688/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2642 - val_loss: 103.9685\n",
      "Epoch 1689/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2592 - val_loss: 103.9625\n",
      "Epoch 1690/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2538 - val_loss: 103.9498\n",
      "Epoch 1691/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2494 - val_loss: 103.9548\n",
      "Epoch 1692/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2446 - val_loss: 103.9495\n",
      "Epoch 1693/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2393 - val_loss: 103.9293\n",
      "Epoch 1694/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2334 - val_loss: 103.9362\n",
      "Epoch 1695/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 93.2294 - val_loss: 103.9203\n",
      "Epoch 1696/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2247 - val_loss: 103.9069\n",
      "Epoch 1697/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2158 - val_loss: 103.9059\n",
      "Epoch 1698/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2123 - val_loss: 103.9041\n",
      "Epoch 1699/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2093 - val_loss: 103.8797\n",
      "Epoch 1700/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2034 - val_loss: 103.8684\n",
      "Epoch 1701/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1977 - val_loss: 103.8689\n",
      "Epoch 1702/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1949 - val_loss: 103.8714\n",
      "Epoch 1703/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1869 - val_loss: 103.8588\n",
      "Epoch 1704/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1815 - val_loss: 103.8639\n",
      "Epoch 1705/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1766 - val_loss: 103.8608\n",
      "Epoch 1706/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1740 - val_loss: 103.8504\n",
      "Epoch 1707/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1688 - val_loss: 103.8345\n",
      "Epoch 1708/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1612 - val_loss: 103.8258\n",
      "Epoch 1709/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1549 - val_loss: 103.8157\n",
      "Epoch 1710/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1527 - val_loss: 103.8064\n",
      "Epoch 1711/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1457 - val_loss: 103.7933\n",
      "Epoch 1712/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1388 - val_loss: 103.7868\n",
      "Epoch 1713/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1352 - val_loss: 103.7778\n",
      "Epoch 1714/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1327 - val_loss: 103.7762\n",
      "Epoch 1715/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1260 - val_loss: 103.7656\n",
      "Epoch 1716/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1228 - val_loss: 103.7784\n",
      "Epoch 1717/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1177 - val_loss: 103.7529\n",
      "Epoch 1718/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1115 - val_loss: 103.7588\n",
      "Epoch 1719/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1076 - val_loss: 103.7565\n",
      "Epoch 1720/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.1017 - val_loss: 103.7616\n",
      "Epoch 1721/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0952 - val_loss: 103.7671\n",
      "Epoch 1722/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0924 - val_loss: 103.7804\n",
      "Epoch 1723/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0865 - val_loss: 103.7748\n",
      "Epoch 1724/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0854 - val_loss: 103.7573\n",
      "Epoch 1725/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0790 - val_loss: 103.7515\n",
      "Epoch 1726/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0715 - val_loss: 103.7477\n",
      "Epoch 1727/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0650 - val_loss: 103.7425\n",
      "Epoch 1728/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0604 - val_loss: 103.7542\n",
      "Epoch 1729/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0568 - val_loss: 103.7357\n",
      "Epoch 1730/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0534 - val_loss: 103.7279\n",
      "Epoch 1731/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0462 - val_loss: 103.7299\n",
      "Epoch 1732/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0424 - val_loss: 103.7050\n",
      "Epoch 1733/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0354 - val_loss: 103.7080\n",
      "Epoch 1734/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0333 - val_loss: 103.6990\n",
      "Epoch 1735/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0274 - val_loss: 103.6960\n",
      "Epoch 1736/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0239 - val_loss: 103.6902\n",
      "Epoch 1737/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0192 - val_loss: 103.6768\n",
      "Epoch 1738/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0125 - val_loss: 103.6785\n",
      "Epoch 1739/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0063 - val_loss: 103.6917\n",
      "Epoch 1740/5000\n",
      "1126/1126 [==============================] - 0s - loss: 93.0027 - val_loss: 103.6943\n",
      "Epoch 1741/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9967 - val_loss: 103.6945\n",
      "Epoch 1742/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9907 - val_loss: 103.7037\n",
      "Epoch 1743/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9882 - val_loss: 103.7054\n",
      "Epoch 1744/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9849 - val_loss: 103.6801\n",
      "Epoch 1745/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9794 - val_loss: 103.6721\n",
      "Epoch 1746/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9744 - val_loss: 103.6620\n",
      "Epoch 1747/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9684 - val_loss: 103.6478\n",
      "Epoch 1748/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9651 - val_loss: 103.6267\n",
      "Epoch 1749/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9590 - val_loss: 103.6108\n",
      "Epoch 1750/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9554 - val_loss: 103.6141\n",
      "Epoch 1751/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9492 - val_loss: 103.6160\n",
      "Epoch 1752/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9490 - val_loss: 103.6116\n",
      "Epoch 1753/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9417 - val_loss: 103.5972\n",
      "Epoch 1754/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9380 - val_loss: 103.5756\n",
      "Epoch 1755/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9315 - val_loss: 103.5686\n",
      "Epoch 1756/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9232 - val_loss: 103.5445\n",
      "Epoch 1757/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9218 - val_loss: 103.5316\n",
      "Epoch 1758/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9171 - val_loss: 103.5217\n",
      "Epoch 1759/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9122 - val_loss: 103.5061\n",
      "Epoch 1760/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9041 - val_loss: 103.4548\n",
      "Epoch 1761/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9001 - val_loss: 103.4338\n",
      "Epoch 1762/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8945 - val_loss: 103.4256\n",
      "Epoch 1763/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8913 - val_loss: 103.4192\n",
      "Epoch 1764/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8864 - val_loss: 103.4195\n",
      "Epoch 1765/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8838 - val_loss: 103.4134\n",
      "Epoch 1766/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8771 - val_loss: 103.3993\n",
      "Epoch 1767/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8731 - val_loss: 103.3906\n",
      "Epoch 1768/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8657 - val_loss: 103.3763\n",
      "Epoch 1769/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8601 - val_loss: 103.3698\n",
      "Epoch 1770/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8577 - val_loss: 103.3660\n",
      "Epoch 1771/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8529 - val_loss: 103.3629\n",
      "Epoch 1772/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8467 - val_loss: 103.3603\n",
      "Epoch 1773/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8443 - val_loss: 103.3531\n",
      "Epoch 1774/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8365 - val_loss: 103.3525\n",
      "Epoch 1775/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8323 - val_loss: 103.3373\n",
      "Epoch 1776/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8275 - val_loss: 103.3490\n",
      "Epoch 1777/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8260 - val_loss: 103.3281\n",
      "Epoch 1778/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8180 - val_loss: 103.3099\n",
      "Epoch 1779/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8129 - val_loss: 103.2964\n",
      "Epoch 1780/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8093 - val_loss: 103.2767\n",
      "Epoch 1781/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8053 - val_loss: 103.2453\n",
      "Epoch 1782/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7982 - val_loss: 103.2436\n",
      "Epoch 1783/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7935 - val_loss: 103.2459\n",
      "Epoch 1784/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7905 - val_loss: 103.2425\n",
      "Epoch 1785/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7838 - val_loss: 103.2330\n",
      "Epoch 1786/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7816 - val_loss: 103.2239\n",
      "Epoch 1787/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7757 - val_loss: 103.2218\n",
      "Epoch 1788/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7681 - val_loss: 103.1871\n",
      "Epoch 1789/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7656 - val_loss: 103.1641\n",
      "Epoch 1790/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7611 - val_loss: 103.1594\n",
      "Epoch 1791/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7572 - val_loss: 103.1616\n",
      "Epoch 1792/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7528 - val_loss: 103.1518\n",
      "Epoch 1793/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7477 - val_loss: 103.1523\n",
      "Epoch 1794/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7399 - val_loss: 103.1411\n",
      "Epoch 1795/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7378 - val_loss: 103.1340\n",
      "Epoch 1796/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7322 - val_loss: 103.1048\n",
      "Epoch 1797/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7286 - val_loss: 103.0885\n",
      "Epoch 1798/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7218 - val_loss: 103.0837\n",
      "Epoch 1799/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7165 - val_loss: 103.0778\n",
      "Epoch 1800/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7093 - val_loss: 103.0887\n",
      "Epoch 1801/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7059 - val_loss: 103.0814\n",
      "Epoch 1802/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.7057 - val_loss: 103.0792\n",
      "Epoch 1803/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6964 - val_loss: 103.0682\n",
      "Epoch 1804/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6925 - val_loss: 103.0846\n",
      "Epoch 1805/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6870 - val_loss: 103.0871\n",
      "Epoch 1806/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6845 - val_loss: 103.0732\n",
      "Epoch 1807/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6793 - val_loss: 103.0547\n",
      "Epoch 1808/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6764 - val_loss: 103.0682\n",
      "Epoch 1809/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6703 - val_loss: 103.0621\n",
      "Epoch 1810/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6655 - val_loss: 103.0602\n",
      "Epoch 1811/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6612 - val_loss: 103.0426\n",
      "Epoch 1812/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6536 - val_loss: 103.0379\n",
      "Epoch 1813/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6495 - val_loss: 103.0091\n",
      "Epoch 1814/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6459 - val_loss: 102.9915\n",
      "Epoch 1815/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6403 - val_loss: 103.0106\n",
      "Epoch 1816/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6333 - val_loss: 103.0055\n",
      "Epoch 1817/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6304 - val_loss: 102.9939\n",
      "Epoch 1818/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6269 - val_loss: 102.9934\n",
      "Epoch 1819/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6224 - val_loss: 102.9753\n",
      "Epoch 1820/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6157 - val_loss: 102.9733\n",
      "Epoch 1821/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6121 - val_loss: 102.9549\n",
      "Epoch 1822/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6073 - val_loss: 102.9500\n",
      "Epoch 1823/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.6033 - val_loss: 102.9277\n",
      "Epoch 1824/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5984 - val_loss: 102.8970\n",
      "Epoch 1825/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5961 - val_loss: 102.8916\n",
      "Epoch 1826/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5913 - val_loss: 102.8692\n",
      "Epoch 1827/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5834 - val_loss: 102.8521\n",
      "Epoch 1828/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5828 - val_loss: 102.8426\n",
      "Epoch 1829/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5743 - val_loss: 102.8409\n",
      "Epoch 1830/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5736 - val_loss: 102.8368\n",
      "Epoch 1831/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 92.78 - 0s - loss: 92.5639 - val_loss: 102.8425\n",
      "Epoch 1832/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5598 - val_loss: 102.8514\n",
      "Epoch 1833/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5559 - val_loss: 102.8458\n",
      "Epoch 1834/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5527 - val_loss: 102.8581\n",
      "Epoch 1835/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5445 - val_loss: 102.8456\n",
      "Epoch 1836/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5433 - val_loss: 102.8494\n",
      "Epoch 1837/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5392 - val_loss: 102.8397\n",
      "Epoch 1838/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5302 - val_loss: 102.8551\n",
      "Epoch 1839/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5294 - val_loss: 102.8512\n",
      "Epoch 1840/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5251 - val_loss: 102.8430\n",
      "Epoch 1841/5000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5184 - val_loss: 102.8429\n",
      "Epoch 01840: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model(32, X_train.shape[1], 'mean_squared_error', 'adagrad')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto', patience=10)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=5000, validation_data=(X_valid, y_valid), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naVEKABGRFvX/AQXD33HsGouNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115416908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1154ecb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10148514851\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "plt.plot(history.history['loss'], 'r-')\n",
    "plt.plot(history.history['val_loss'], 'b-')\n",
    "plt.show()\n",
    "\n",
    "plt.title('y_pred, y_test')\n",
    "\n",
    "plt.plot(y_pred[:], y_test[:], '+')\n",
    "plt.show()\n",
    "percent_high_detected = np.sum(y_pred.reshape((len(y_pred), )) > 20) / np.sum(y_test.reshape((len(y_test), )) > 20)\n",
    "print(percent_high_detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-f3e4a7f862bb>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-f3e4a7f862bb>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    model.add(Dense(1, kernel_initializer='normal'))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "df = pd.read_pickle('data/micro_sud3_normalized.pkl')\n",
    "df = df[['date', 'NO2_ref', 'NO2_61FD', 'NO2_61F0', \\\n",
    "        'NO2_61EF', 'temp', 'rh', 'tgrad', 'pressure', 'pluvio']]\n",
    "df = df.reset_index()\n",
    "df_train, df_test = split_dataframe(df, 0.5) \n",
    "df_valid, df_test = split_dataframe(df_test, 0.5)\n",
    "\n",
    "X_train, y_train = dataframe_to_xy(df_train)\n",
    "X_valid, y_valid = dataframe_to_xy(df_valid)\n",
    "X_test, y_test = dataframe_to_xy(df_test)\n",
    "\n",
    "def simple_rnn_model(nb_units, input_dim, loss='mean_squared_error', optimizer='adagrad'):\n",
    "    print(input_dim)\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(nb_units, input_shape=(24, 1, 8))#input_dim=input_dim[1], input_length=input_dim[0], return_sequences=True))\n",
    "    #model.add(Dense(nb_units))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = simple_rnn_model(16, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1, 8)\n",
      "(24, 1, 8)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have 2 dimensions, but got array with shape (24, 1, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-29ac19a07c21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1126\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1379\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have 2 dimensions, but got array with shape (24, 1, 8)"
     ]
    }
   ],
   "source": [
    "#X_train = np.reshape(X_train, (1, X_train.shape[0], X_train.shape[1]))\n",
    "print(X_train.shape)\n",
    "X_train = np.reshape(X_train[:24], (24, 1, 8))\n",
    "print(X_train.shape)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto', patience=10)\n",
    "history = model.fit(X_train, y_train, batch_size=1126, epochs=5000, validation_data=(X_valid, y_valid), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "plt.plot(history.history['loss'], 'r-')\n",
    "plt.plot(history.history['val_loss'], 'b-')\n",
    "plt.show()\n",
    "\n",
    "plt.title('y_pred, y_test')\n",
    "\n",
    "plt.plot(y_pred[:], y_test[:], '+')\n",
    "plt.show()\n",
    "percent_high_detected = np.sum(y_pred.reshape((len(y_pred), )) > 20) / np.sum(y_test.reshape((len(y_test), )) > 20)\n",
    "print(percent_high_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

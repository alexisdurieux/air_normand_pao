{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/micro_sud3_normalized.pkl')\n",
    "df = df.reset_index()\n",
    "\n",
    "\n",
    "def split_dataframe(dataframe, percent):\n",
    "    nb_rows = int(np.floor(percent * len(dataframe)))\n",
    "    return dataframe[:nb_rows], dataframe[nb_rows:]\n",
    "\n",
    "def dataframe_to_xy(df):\n",
    "    return (np.array(df[['NO2_61FD', 'NO2_61F0', 'NO2_61EF', 'temp', 'rh',\\\n",
    "                         'tgrad', 'pressure', 'pluvio']]),\\\n",
    "            np.array(df['NO2_ref']))\n",
    "\n",
    "        \n",
    "df_train, df_test = split_dataframe(df, 0.5) \n",
    "df_valid, df_test = split_dataframe(df_test, 0.5)\n",
    "\n",
    "X_train, y_train = dataframe_to_xy(df_train)\n",
    "X_valid, y_valid = dataframe_to_xy(df_valid)\n",
    "X_test, y_test = dataframe_to_xy(df_test)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_valid= X_valid.reshape((X_valid.shape[0], 1,  X_valid.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "def dataframe_to_xy_sequences(df, sequence_size):\n",
    "    out_X = np.zeros((len(df)//sequence_size, sequence_size, 8))\n",
    "    out_y = np.zeros((len(df)//sequence_size, sequence_size))\n",
    "    i = 0\n",
    "    while i + sequence_size < len(df):\n",
    "        sequence = df.iloc[i:i+sequence_size]\n",
    "        out_X[i//sequence_size] =  np.array(sequence[['NO2_61FD', 'NO2_61F0', 'NO2_61EF', 'temp', 'rh',\\\n",
    "                                 'tgrad', 'pressure', 'pluvio']])\n",
    "        out_y[i//sequence_size] = np.array(sequence['NO2_ref'])\n",
    "        i += sequence_size\n",
    "        \n",
    "    return out_X, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN, Dense, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def simple_rnn_model(nb_units, input_dim, loss='mean_squared_error', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(nb_units, input_shape=input_dim, activation='relu'))#input_dim=input_dim[1], input_length=input_dim[0], return_sequences=True))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def lstm_model(nb_units, input_dim, loss='mean_squared_error', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nb_units, input_shape=input_dim, activation='relu'))#input_dim=input_dim[1], input_length=input_dim[0], return_sequences=True))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def gru_model(nb_units, input_dim, loss='mean_squared_error', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(nb_units, input_shape=input_dim, activation='relu'))#input_dim=input_dim[1], input_length=input_dim[0], return_sequences=True))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1126, 1, 8)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "model = simple_rnn_model(32, X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1126 samples, validate on 563 samples\n",
      "Epoch 1/10000\n",
      "1126/1126 [==============================] - 1s - loss: 3338.7269 - val_loss: 2988.5734\n",
      "Epoch 2/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3310.0022 - val_loss: 2955.9246\n",
      "Epoch 3/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3272.7424 - val_loss: 2911.4492\n",
      "Epoch 4/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3217.8316 - val_loss: 2849.0086\n",
      "Epoch 5/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3139.9851 - val_loss: 2764.9304\n",
      "Epoch 6/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3036.9269 - val_loss: 2659.1266\n",
      "Epoch 7/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2908.6243 - val_loss: 2534.0007\n",
      "Epoch 8/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2757.1496 - val_loss: 2392.8800\n",
      "Epoch 9/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2587.1464 - val_loss: 2240.3704\n",
      "Epoch 10/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2404.2927 - val_loss: 2081.1851\n",
      "Epoch 11/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2213.7324 - val_loss: 1919.5444\n",
      "Epoch 12/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2020.2884 - val_loss: 1759.2198\n",
      "Epoch 13/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1828.3978 - val_loss: 1603.5828\n",
      "Epoch 14/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1642.3318 - val_loss: 1455.6131\n",
      "Epoch 15/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1466.0322 - val_loss: 1318.1350\n",
      "Epoch 16/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1302.8967 - val_loss: 1192.9915\n",
      "Epoch 17/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1155.1739 - val_loss: 1081.2124\n",
      "Epoch 18/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1024.2352 - val_loss: 982.9213\n",
      "Epoch 19/10000\n",
      "1126/1126 [==============================] - 0s - loss: 910.2528 - val_loss: 897.4584\n",
      "Epoch 20/10000\n",
      "1126/1126 [==============================] - 0s - loss: 812.5095 - val_loss: 823.6200\n",
      "Epoch 21/10000\n",
      "1126/1126 [==============================] - 0s - loss: 729.6169 - val_loss: 759.8610\n",
      "Epoch 22/10000\n",
      "1126/1126 [==============================] - 0s - loss: 659.7370 - val_loss: 704.4669\n",
      "Epoch 23/10000\n",
      "1126/1126 [==============================] - 0s - loss: 600.8309 - val_loss: 655.8502\n",
      "Epoch 24/10000\n",
      "1126/1126 [==============================] - 0s - loss: 550.8948 - val_loss: 612.6439\n",
      "Epoch 25/10000\n",
      "1126/1126 [==============================] - 0s - loss: 508.1436 - val_loss: 573.7994\n",
      "Epoch 26/10000\n",
      "1126/1126 [==============================] - 0s - loss: 471.0646 - val_loss: 538.4501\n",
      "Epoch 27/10000\n",
      "1126/1126 [==============================] - 0s - loss: 438.4842 - val_loss: 506.1854\n",
      "Epoch 28/10000\n",
      "1126/1126 [==============================] - 0s - loss: 409.6356 - val_loss: 476.6656\n",
      "Epoch 29/10000\n",
      "1126/1126 [==============================] - 0s - loss: 383.9594 - val_loss: 449.6578\n",
      "Epoch 30/10000\n",
      "1126/1126 [==============================] - 0s - loss: 361.1134 - val_loss: 425.1230\n",
      "Epoch 31/10000\n",
      "1126/1126 [==============================] - 0s - loss: 340.8267 - val_loss: 402.9271\n",
      "Epoch 32/10000\n",
      "1126/1126 [==============================] - 0s - loss: 322.8427 - val_loss: 382.9541\n",
      "Epoch 33/10000\n",
      "1126/1126 [==============================] - 0s - loss: 306.9537 - val_loss: 365.0314\n",
      "Epoch 34/10000\n",
      "1126/1126 [==============================] - 0s - loss: 292.9369 - val_loss: 349.0196\n",
      "Epoch 35/10000\n",
      "1126/1126 [==============================] - 0s - loss: 280.5997 - val_loss: 334.7450\n",
      "Epoch 36/10000\n",
      "1126/1126 [==============================] - 0s - loss: 269.7558 - val_loss: 322.0683\n",
      "Epoch 37/10000\n",
      "1126/1126 [==============================] - 0s - loss: 260.2248 - val_loss: 310.8112\n",
      "Epoch 38/10000\n",
      "1126/1126 [==============================] - 0s - loss: 251.8213 - val_loss: 300.8067\n",
      "Epoch 39/10000\n",
      "1126/1126 [==============================] - 0s - loss: 244.3841 - val_loss: 291.9053\n",
      "Epoch 40/10000\n",
      "1126/1126 [==============================] - 0s - loss: 237.7792 - val_loss: 283.9909\n",
      "Epoch 41/10000\n",
      "1126/1126 [==============================] - 0s - loss: 231.8997 - val_loss: 276.9216\n",
      "Epoch 42/10000\n",
      "1126/1126 [==============================] - 0s - loss: 226.6166 - val_loss: 270.5901\n",
      "Epoch 43/10000\n",
      "1126/1126 [==============================] - 0s - loss: 221.8377 - val_loss: 264.8866\n",
      "Epoch 44/10000\n",
      "1126/1126 [==============================] - 0s - loss: 217.4835 - val_loss: 259.7356\n",
      "Epoch 45/10000\n",
      "1126/1126 [==============================] - 0s - loss: 213.4930 - val_loss: 255.0556\n",
      "Epoch 46/10000\n",
      "1126/1126 [==============================] - 0s - loss: 209.7977 - val_loss: 250.7662\n",
      "Epoch 47/10000\n",
      "1126/1126 [==============================] - 0s - loss: 206.3443 - val_loss: 246.8075\n",
      "Epoch 48/10000\n",
      "1126/1126 [==============================] - 0s - loss: 203.0998 - val_loss: 243.1311\n",
      "Epoch 49/10000\n",
      "1126/1126 [==============================] - 0s - loss: 200.0253 - val_loss: 239.6982\n",
      "Epoch 50/10000\n",
      "1126/1126 [==============================] - 0s - loss: 197.1114 - val_loss: 236.4663\n",
      "Epoch 51/10000\n",
      "1126/1126 [==============================] - 0s - loss: 194.3201 - val_loss: 233.4172\n",
      "Epoch 52/10000\n",
      "1126/1126 [==============================] - 0s - loss: 191.6470 - val_loss: 230.5249\n",
      "Epoch 53/10000\n",
      "1126/1126 [==============================] - 0s - loss: 189.0816 - val_loss: 227.7665\n",
      "Epoch 54/10000\n",
      "1126/1126 [==============================] - 0s - loss: 186.6183 - val_loss: 225.1261\n",
      "Epoch 55/10000\n",
      "1126/1126 [==============================] - 0s - loss: 184.2480 - val_loss: 222.6029\n",
      "Epoch 56/10000\n",
      "1126/1126 [==============================] - 0s - loss: 181.9649 - val_loss: 220.1811\n",
      "Epoch 57/10000\n",
      "1126/1126 [==============================] - 0s - loss: 179.7634 - val_loss: 217.8468\n",
      "Epoch 58/10000\n",
      "1126/1126 [==============================] - 0s - loss: 177.6371 - val_loss: 215.5871\n",
      "Epoch 59/10000\n",
      "1126/1126 [==============================] - 0s - loss: 175.5792 - val_loss: 213.3815\n",
      "Epoch 60/10000\n",
      "1126/1126 [==============================] - 0s - loss: 173.5901 - val_loss: 211.2494\n",
      "Epoch 61/10000\n",
      "1126/1126 [==============================] - 0s - loss: 171.6698 - val_loss: 209.1667\n",
      "Epoch 62/10000\n",
      "1126/1126 [==============================] - 0s - loss: 169.8116 - val_loss: 207.1132\n",
      "Epoch 63/10000\n",
      "1126/1126 [==============================] - 0s - loss: 168.0101 - val_loss: 205.0952\n",
      "Epoch 64/10000\n",
      "1126/1126 [==============================] - 0s - loss: 166.2541 - val_loss: 203.1033\n",
      "Epoch 65/10000\n",
      "1126/1126 [==============================] - 0s - loss: 164.5333 - val_loss: 201.1478\n",
      "Epoch 66/10000\n",
      "1126/1126 [==============================] - 0s - loss: 162.8568 - val_loss: 199.2239\n",
      "Epoch 67/10000\n",
      "1126/1126 [==============================] - 0s - loss: 161.2244 - val_loss: 197.3281\n",
      "Epoch 68/10000\n",
      "1126/1126 [==============================] - 0s - loss: 159.6383 - val_loss: 195.4598\n",
      "Epoch 69/10000\n",
      "1126/1126 [==============================] - 0s - loss: 158.0984 - val_loss: 193.6226\n",
      "Epoch 70/10000\n",
      "1126/1126 [==============================] - 0s - loss: 156.6052 - val_loss: 191.8279\n",
      "Epoch 71/10000\n",
      "1126/1126 [==============================] - 0s - loss: 155.1565 - val_loss: 190.0574\n",
      "Epoch 72/10000\n",
      "1126/1126 [==============================] - 0s - loss: 153.7456 - val_loss: 188.3112\n",
      "Epoch 73/10000\n",
      "1126/1126 [==============================] - 0s - loss: 152.3738 - val_loss: 186.6042\n",
      "Epoch 74/10000\n",
      "1126/1126 [==============================] - 0s - loss: 151.0398 - val_loss: 184.9201\n",
      "Epoch 75/10000\n",
      "1126/1126 [==============================] - 0s - loss: 149.7439 - val_loss: 183.2693\n",
      "Epoch 76/10000\n",
      "1126/1126 [==============================] - 0s - loss: 148.4839 - val_loss: 181.6684\n",
      "Epoch 77/10000\n",
      "1126/1126 [==============================] - 0s - loss: 147.2477 - val_loss: 180.0858\n",
      "Epoch 78/10000\n",
      "1126/1126 [==============================] - 0s - loss: 146.0411 - val_loss: 178.5397\n",
      "Epoch 79/10000\n",
      "1126/1126 [==============================] - 0s - loss: 144.8668 - val_loss: 177.0104\n",
      "Epoch 80/10000\n",
      "1126/1126 [==============================] - 0s - loss: 143.7198 - val_loss: 175.5169\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 142.6025 - val_loss: 174.0599\n",
      "Epoch 82/10000\n",
      "1126/1126 [==============================] - 0s - loss: 141.5129 - val_loss: 172.6280\n",
      "Epoch 83/10000\n",
      "1126/1126 [==============================] - 0s - loss: 140.4536 - val_loss: 171.2344\n",
      "Epoch 84/10000\n",
      "1126/1126 [==============================] - 0s - loss: 139.4184 - val_loss: 169.8720\n",
      "Epoch 85/10000\n",
      "1126/1126 [==============================] - 0s - loss: 138.4112 - val_loss: 168.5366\n",
      "Epoch 86/10000\n",
      "1126/1126 [==============================] - 0s - loss: 137.4324 - val_loss: 167.2163\n",
      "Epoch 87/10000\n",
      "1126/1126 [==============================] - 0s - loss: 136.4818 - val_loss: 165.9365\n",
      "Epoch 88/10000\n",
      "1126/1126 [==============================] - 0s - loss: 135.5573 - val_loss: 164.6943\n",
      "Epoch 89/10000\n",
      "1126/1126 [==============================] - 0s - loss: 134.6596 - val_loss: 163.4781\n",
      "Epoch 90/10000\n",
      "1126/1126 [==============================] - 0s - loss: 133.7876 - val_loss: 162.2969\n",
      "Epoch 91/10000\n",
      "1126/1126 [==============================] - 0s - loss: 132.9462 - val_loss: 161.1483\n",
      "Epoch 92/10000\n",
      "1126/1126 [==============================] - 0s - loss: 132.1349 - val_loss: 160.0414\n",
      "Epoch 93/10000\n",
      "1126/1126 [==============================] - 0s - loss: 131.3481 - val_loss: 158.9614\n",
      "Epoch 94/10000\n",
      "1126/1126 [==============================] - 0s - loss: 130.5824 - val_loss: 157.9098\n",
      "Epoch 95/10000\n",
      "1126/1126 [==============================] - 0s - loss: 129.8450 - val_loss: 156.8878\n",
      "Epoch 96/10000\n",
      "1126/1126 [==============================] - 0s - loss: 129.1321 - val_loss: 155.9020\n",
      "Epoch 97/10000\n",
      "1126/1126 [==============================] - 0s - loss: 128.4391 - val_loss: 154.9565\n",
      "Epoch 98/10000\n",
      "1126/1126 [==============================] - 0s - loss: 127.7677 - val_loss: 154.0446\n",
      "Epoch 99/10000\n",
      "1126/1126 [==============================] - 0s - loss: 127.1177 - val_loss: 153.1579\n",
      "Epoch 100/10000\n",
      "1126/1126 [==============================] - 0s - loss: 126.4892 - val_loss: 152.3010\n",
      "Epoch 101/10000\n",
      "1126/1126 [==============================] - 0s - loss: 125.8808 - val_loss: 151.4760\n",
      "Epoch 102/10000\n",
      "1126/1126 [==============================] - 0s - loss: 125.2921 - val_loss: 150.6788\n",
      "Epoch 103/10000\n",
      "1126/1126 [==============================] - 0s - loss: 124.7232 - val_loss: 149.9085\n",
      "Epoch 104/10000\n",
      "1126/1126 [==============================] - 0s - loss: 124.1775 - val_loss: 149.1729\n",
      "Epoch 105/10000\n",
      "1126/1126 [==============================] - 0s - loss: 123.6537 - val_loss: 148.4525\n",
      "Epoch 106/10000\n",
      "1126/1126 [==============================] - 0s - loss: 123.1505 - val_loss: 147.7489\n",
      "Epoch 107/10000\n",
      "1126/1126 [==============================] - 0s - loss: 122.6650 - val_loss: 147.0683\n",
      "Epoch 108/10000\n",
      "1126/1126 [==============================] - 0s - loss: 122.1948 - val_loss: 146.4336\n",
      "Epoch 109/10000\n",
      "1126/1126 [==============================] - 0s - loss: 121.7434 - val_loss: 145.8222\n",
      "Epoch 110/10000\n",
      "1126/1126 [==============================] - 0s - loss: 121.3091 - val_loss: 145.2431\n",
      "Epoch 111/10000\n",
      "1126/1126 [==============================] - 0s - loss: 120.8901 - val_loss: 144.6882\n",
      "Epoch 112/10000\n",
      "1126/1126 [==============================] - 0s - loss: 120.4843 - val_loss: 144.1546\n",
      "Epoch 113/10000\n",
      "1126/1126 [==============================] - 0s - loss: 120.0939 - val_loss: 143.6457\n",
      "Epoch 114/10000\n",
      "1126/1126 [==============================] - 0s - loss: 119.7158 - val_loss: 143.1561\n",
      "Epoch 115/10000\n",
      "1126/1126 [==============================] - 0s - loss: 119.3541 - val_loss: 142.6961\n",
      "Epoch 116/10000\n",
      "1126/1126 [==============================] - 0s - loss: 119.0042 - val_loss: 142.2583\n",
      "Epoch 117/10000\n",
      "1126/1126 [==============================] - 0s - loss: 118.6690 - val_loss: 141.8431\n",
      "Epoch 118/10000\n",
      "1126/1126 [==============================] - 0s - loss: 118.3493 - val_loss: 141.4578\n",
      "Epoch 119/10000\n",
      "1126/1126 [==============================] - 0s - loss: 118.0416 - val_loss: 141.1041\n",
      "Epoch 120/10000\n",
      "1126/1126 [==============================] - 0s - loss: 117.7469 - val_loss: 140.7619\n",
      "Epoch 121/10000\n",
      "1126/1126 [==============================] - 0s - loss: 117.4640 - val_loss: 140.4342\n",
      "Epoch 122/10000\n",
      "1126/1126 [==============================] - 0s - loss: 117.1903 - val_loss: 140.1124\n",
      "Epoch 123/10000\n",
      "1126/1126 [==============================] - 0s - loss: 116.9267 - val_loss: 139.8054\n",
      "Epoch 124/10000\n",
      "1126/1126 [==============================] - 0s - loss: 116.6686 - val_loss: 139.5078\n",
      "Epoch 125/10000\n",
      "1126/1126 [==============================] - 0s - loss: 116.4138 - val_loss: 139.2006\n",
      "Epoch 126/10000\n",
      "1126/1126 [==============================] - 0s - loss: 116.1736 - val_loss: 138.9108\n",
      "Epoch 127/10000\n",
      "1126/1126 [==============================] - 0s - loss: 115.9428 - val_loss: 138.6340\n",
      "Epoch 128/10000\n",
      "1126/1126 [==============================] - 0s - loss: 115.7217 - val_loss: 138.3601\n",
      "Epoch 129/10000\n",
      "1126/1126 [==============================] - 0s - loss: 115.5122 - val_loss: 138.1051\n",
      "Epoch 130/10000\n",
      "1126/1126 [==============================] - 0s - loss: 115.3104 - val_loss: 137.8636\n",
      "Epoch 131/10000\n",
      "1126/1126 [==============================] - 0s - loss: 115.1165 - val_loss: 137.6405\n",
      "Epoch 132/10000\n",
      "1126/1126 [==============================] - 0s - loss: 114.9309 - val_loss: 137.4177\n",
      "Epoch 133/10000\n",
      "1126/1126 [==============================] - 0s - loss: 114.7533 - val_loss: 137.1978\n",
      "Epoch 134/10000\n",
      "1126/1126 [==============================] - 0s - loss: 114.5811 - val_loss: 136.9973\n",
      "Epoch 135/10000\n",
      "1126/1126 [==============================] - 0s - loss: 114.4139 - val_loss: 136.8046\n",
      "Epoch 136/10000\n",
      "1126/1126 [==============================] - 0s - loss: 114.2537 - val_loss: 136.6090\n",
      "Epoch 137/10000\n",
      "1126/1126 [==============================] - 0s - loss: 114.0992 - val_loss: 136.4273\n",
      "Epoch 138/10000\n",
      "1126/1126 [==============================] - 0s - loss: 113.9476 - val_loss: 136.2580\n",
      "Epoch 139/10000\n",
      "1126/1126 [==============================] - 0s - loss: 113.8015 - val_loss: 136.0895\n",
      "Epoch 140/10000\n",
      "1126/1126 [==============================] - 0s - loss: 113.6617 - val_loss: 135.9314\n",
      "Epoch 141/10000\n",
      "1126/1126 [==============================] - 0s - loss: 113.5289 - val_loss: 135.7839\n",
      "Epoch 142/10000\n",
      "1126/1126 [==============================] - 0s - loss: 113.4006 - val_loss: 135.6405\n",
      "Epoch 143/10000\n",
      "1126/1126 [==============================] - 0s - loss: 113.2762 - val_loss: 135.5047\n",
      "Epoch 144/10000\n",
      "1126/1126 [==============================] - 0s - loss: 113.1574 - val_loss: 135.3792\n",
      "Epoch 145/10000\n",
      "1126/1126 [==============================] - 0s - loss: 113.0449 - val_loss: 135.2581\n",
      "Epoch 146/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.9374 - val_loss: 135.1445\n",
      "Epoch 147/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.8331 - val_loss: 135.0319\n",
      "Epoch 148/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.7321 - val_loss: 134.9202\n",
      "Epoch 149/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.6343 - val_loss: 134.8063\n",
      "Epoch 150/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.5378 - val_loss: 134.6920\n",
      "Epoch 151/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.4445 - val_loss: 134.5820\n",
      "Epoch 152/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.3547 - val_loss: 134.4750\n",
      "Epoch 153/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.2672 - val_loss: 134.3664\n",
      "Epoch 154/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.1838 - val_loss: 134.2597\n",
      "Epoch 155/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.1042 - val_loss: 134.1521\n",
      "Epoch 156/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.0255 - val_loss: 134.0452\n",
      "Epoch 157/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.9491 - val_loss: 133.9410\n",
      "Epoch 158/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.8747 - val_loss: 133.8463\n",
      "Epoch 159/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.8014 - val_loss: 133.7521\n",
      "Epoch 160/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.7302 - val_loss: 133.6614\n",
      "Epoch 161/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 111.6595 - val_loss: 133.5667\n",
      "Epoch 162/10000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 112.214 - 0s - loss: 111.5911 - val_loss: 133.4696\n",
      "Epoch 163/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.5242 - val_loss: 133.3764\n",
      "Epoch 164/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.4561 - val_loss: 133.2826\n",
      "Epoch 165/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.3899 - val_loss: 133.1848\n",
      "Epoch 166/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.3249 - val_loss: 133.0836\n",
      "Epoch 167/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.2614 - val_loss: 132.9928\n",
      "Epoch 168/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.1987 - val_loss: 132.9035\n",
      "Epoch 169/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.1384 - val_loss: 132.8074\n",
      "Epoch 170/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.0807 - val_loss: 132.7126\n",
      "Epoch 171/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.0238 - val_loss: 132.6198\n",
      "Epoch 172/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.9687 - val_loss: 132.5263\n",
      "Epoch 173/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.9117 - val_loss: 132.4299\n",
      "Epoch 174/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.8583 - val_loss: 132.3370\n",
      "Epoch 175/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.8047 - val_loss: 132.2401\n",
      "Epoch 176/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.7520 - val_loss: 132.1369\n",
      "Epoch 177/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.7002 - val_loss: 132.0305\n",
      "Epoch 178/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.6500 - val_loss: 131.9214\n",
      "Epoch 179/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.6002 - val_loss: 131.8154\n",
      "Epoch 180/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.5510 - val_loss: 131.7079\n",
      "Epoch 181/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.5023 - val_loss: 131.6000\n",
      "Epoch 182/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.4555 - val_loss: 131.4926\n",
      "Epoch 183/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.4086 - val_loss: 131.3834\n",
      "Epoch 184/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.3622 - val_loss: 131.2722\n",
      "Epoch 185/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.3174 - val_loss: 131.1583\n",
      "Epoch 186/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.2726 - val_loss: 131.0448\n",
      "Epoch 187/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.2277 - val_loss: 130.9266\n",
      "Epoch 188/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.1833 - val_loss: 130.8134\n",
      "Epoch 189/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.1406 - val_loss: 130.6951\n",
      "Epoch 190/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.0982 - val_loss: 130.5755\n",
      "Epoch 191/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.0563 - val_loss: 130.4617\n",
      "Epoch 192/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.0151 - val_loss: 130.3457\n",
      "Epoch 193/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.9766 - val_loss: 130.2363\n",
      "Epoch 194/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.9376 - val_loss: 130.1224\n",
      "Epoch 195/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.9029 - val_loss: 130.0169\n",
      "Epoch 196/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.8667 - val_loss: 129.9127\n",
      "Epoch 197/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.8328 - val_loss: 129.8016\n",
      "Epoch 198/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.7996 - val_loss: 129.6971\n",
      "Epoch 199/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.7662 - val_loss: 129.5890\n",
      "Epoch 200/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.7342 - val_loss: 129.4783\n",
      "Epoch 201/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.7005 - val_loss: 129.3686\n",
      "Epoch 202/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.6671 - val_loss: 129.2588\n",
      "Epoch 203/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.6352 - val_loss: 129.1489\n",
      "Epoch 204/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.6022 - val_loss: 129.0403\n",
      "Epoch 205/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.5706 - val_loss: 128.9281\n",
      "Epoch 206/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.5397 - val_loss: 128.8219\n",
      "Epoch 207/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.5087 - val_loss: 128.7148\n",
      "Epoch 208/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.4765 - val_loss: 128.6045\n",
      "Epoch 209/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.4465 - val_loss: 128.4987\n",
      "Epoch 210/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.4138 - val_loss: 128.3957\n",
      "Epoch 211/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.3830 - val_loss: 128.2912\n",
      "Epoch 212/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.3497 - val_loss: 128.1854\n",
      "Epoch 213/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.3167 - val_loss: 128.0849\n",
      "Epoch 214/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.2827 - val_loss: 127.9811\n",
      "Epoch 215/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.2491 - val_loss: 127.8758\n",
      "Epoch 216/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.2150 - val_loss: 127.7732\n",
      "Epoch 217/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.1807 - val_loss: 127.6749\n",
      "Epoch 218/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.1456 - val_loss: 127.5748\n",
      "Epoch 219/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.1091 - val_loss: 127.4725\n",
      "Epoch 220/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.0728 - val_loss: 127.3679\n",
      "Epoch 221/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.0365 - val_loss: 127.2635\n",
      "Epoch 222/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.9980 - val_loss: 127.1567\n",
      "Epoch 223/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.9636 - val_loss: 127.0525\n",
      "Epoch 224/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.9242 - val_loss: 126.9434\n",
      "Epoch 225/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.8854 - val_loss: 126.8360\n",
      "Epoch 226/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.8456 - val_loss: 126.7295\n",
      "Epoch 227/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.8022 - val_loss: 126.6268\n",
      "Epoch 228/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.7607 - val_loss: 126.5275\n",
      "Epoch 229/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.7220 - val_loss: 126.4298\n",
      "Epoch 230/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.6813 - val_loss: 126.3327\n",
      "Epoch 231/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.6424 - val_loss: 126.2399\n",
      "Epoch 232/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.6023 - val_loss: 126.1466\n",
      "Epoch 233/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.5647 - val_loss: 126.0514\n",
      "Epoch 234/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.5265 - val_loss: 125.9656\n",
      "Epoch 235/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.4897 - val_loss: 125.8848\n",
      "Epoch 236/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.4532 - val_loss: 125.7969\n",
      "Epoch 237/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.4162 - val_loss: 125.7094\n",
      "Epoch 238/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.3795 - val_loss: 125.6110\n",
      "Epoch 239/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.3433 - val_loss: 125.5211\n",
      "Epoch 240/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.3124 - val_loss: 125.4454\n",
      "Epoch 241/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 108.2803 - val_loss: 125.3725\n",
      "Epoch 242/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.2501 - val_loss: 125.3047\n",
      "Epoch 243/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.2206 - val_loss: 125.2383\n",
      "Epoch 244/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.1928 - val_loss: 125.1667\n",
      "Epoch 245/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.1642 - val_loss: 125.0960\n",
      "Epoch 246/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.1359 - val_loss: 125.0268\n",
      "Epoch 247/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.1080 - val_loss: 124.9586\n",
      "Epoch 248/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.0796 - val_loss: 124.8953\n",
      "Epoch 249/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.0491 - val_loss: 124.8214\n",
      "Epoch 250/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.0209 - val_loss: 124.7536\n",
      "Epoch 251/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.9913 - val_loss: 124.6893\n",
      "Epoch 252/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.9632 - val_loss: 124.6236\n",
      "Epoch 253/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.9339 - val_loss: 124.5621\n",
      "Epoch 254/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.9053 - val_loss: 124.4942\n",
      "Epoch 255/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.8787 - val_loss: 124.4321\n",
      "Epoch 256/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.8506 - val_loss: 124.3635\n",
      "Epoch 257/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.8245 - val_loss: 124.2987\n",
      "Epoch 258/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.7974 - val_loss: 124.2316\n",
      "Epoch 259/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.7707 - val_loss: 124.1701\n",
      "Epoch 260/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.7441 - val_loss: 124.1041\n",
      "Epoch 261/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.7180 - val_loss: 124.0393\n",
      "Epoch 262/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.6907 - val_loss: 123.9758\n",
      "Epoch 263/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.6656 - val_loss: 123.9106\n",
      "Epoch 264/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.6388 - val_loss: 123.8474\n",
      "Epoch 265/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.6116 - val_loss: 123.7831\n",
      "Epoch 266/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.5852 - val_loss: 123.7216\n",
      "Epoch 267/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.5595 - val_loss: 123.6674\n",
      "Epoch 268/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.5330 - val_loss: 123.6083\n",
      "Epoch 269/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.5059 - val_loss: 123.5482\n",
      "Epoch 270/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.4782 - val_loss: 123.4896\n",
      "Epoch 271/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.4507 - val_loss: 123.4311\n",
      "Epoch 272/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.4229 - val_loss: 123.3699\n",
      "Epoch 273/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.3960 - val_loss: 123.3167\n",
      "Epoch 274/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.3683 - val_loss: 123.2605\n",
      "Epoch 275/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.3411 - val_loss: 123.2076\n",
      "Epoch 276/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.3143 - val_loss: 123.1526\n",
      "Epoch 277/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.2880 - val_loss: 123.0946\n",
      "Epoch 278/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.2617 - val_loss: 123.0364\n",
      "Epoch 279/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.2337 - val_loss: 122.9740\n",
      "Epoch 280/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.2066 - val_loss: 122.9183\n",
      "Epoch 281/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.1787 - val_loss: 122.8593\n",
      "Epoch 282/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.1529 - val_loss: 122.8081\n",
      "Epoch 283/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.1251 - val_loss: 122.7538\n",
      "Epoch 284/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.0974 - val_loss: 122.6966\n",
      "Epoch 285/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.0714 - val_loss: 122.6393\n",
      "Epoch 286/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.0430 - val_loss: 122.5792\n",
      "Epoch 287/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.0138 - val_loss: 122.5214\n",
      "Epoch 288/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.9871 - val_loss: 122.4665\n",
      "Epoch 289/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.9583 - val_loss: 122.4131\n",
      "Epoch 290/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.9310 - val_loss: 122.3576\n",
      "Epoch 291/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.9032 - val_loss: 122.2997\n",
      "Epoch 292/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.8757 - val_loss: 122.2437\n",
      "Epoch 293/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.8484 - val_loss: 122.1910\n",
      "Epoch 294/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.8191 - val_loss: 122.1346\n",
      "Epoch 295/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.7927 - val_loss: 122.0828\n",
      "Epoch 296/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.7643 - val_loss: 122.0333\n",
      "Epoch 297/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.7367 - val_loss: 121.9840\n",
      "Epoch 298/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.7091 - val_loss: 121.9346\n",
      "Epoch 299/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.6828 - val_loss: 121.8892\n",
      "Epoch 300/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.6557 - val_loss: 121.8425\n",
      "Epoch 301/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.6282 - val_loss: 121.7983\n",
      "Epoch 302/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.6026 - val_loss: 121.7525\n",
      "Epoch 303/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.5761 - val_loss: 121.7066\n",
      "Epoch 304/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.5502 - val_loss: 121.6676\n",
      "Epoch 305/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.5223 - val_loss: 121.6209\n",
      "Epoch 306/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.4975 - val_loss: 121.5773\n",
      "Epoch 307/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.4688 - val_loss: 121.5331\n",
      "Epoch 308/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.4415 - val_loss: 121.4911\n",
      "Epoch 309/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.4137 - val_loss: 121.4474\n",
      "Epoch 310/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.3859 - val_loss: 121.4046\n",
      "Epoch 311/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.3579 - val_loss: 121.3627\n",
      "Epoch 312/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.3293 - val_loss: 121.3209\n",
      "Epoch 313/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.3012 - val_loss: 121.2791\n",
      "Epoch 314/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.2745 - val_loss: 121.2378\n",
      "Epoch 315/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.2469 - val_loss: 121.1976\n",
      "Epoch 316/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.2204 - val_loss: 121.1545\n",
      "Epoch 317/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.1938 - val_loss: 121.1128\n",
      "Epoch 318/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.1672 - val_loss: 121.0731\n",
      "Epoch 319/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.1410 - val_loss: 121.0311\n",
      "Epoch 320/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.1160 - val_loss: 120.9894\n",
      "Epoch 321/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 106.0903 - val_loss: 120.9500\n",
      "Epoch 322/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.0648 - val_loss: 120.9084\n",
      "Epoch 323/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.0390 - val_loss: 120.8681\n",
      "Epoch 324/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.0142 - val_loss: 120.8260\n",
      "Epoch 325/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.9885 - val_loss: 120.7844\n",
      "Epoch 326/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.9634 - val_loss: 120.7393\n",
      "Epoch 327/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.9381 - val_loss: 120.6944\n",
      "Epoch 328/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.9143 - val_loss: 120.6498\n",
      "Epoch 329/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.8885 - val_loss: 120.6069\n",
      "Epoch 330/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.8632 - val_loss: 120.5646\n",
      "Epoch 331/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.8381 - val_loss: 120.5244\n",
      "Epoch 332/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.8129 - val_loss: 120.4798\n",
      "Epoch 333/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.7886 - val_loss: 120.4333\n",
      "Epoch 334/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.7638 - val_loss: 120.3882\n",
      "Epoch 335/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.7401 - val_loss: 120.3449\n",
      "Epoch 336/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.7158 - val_loss: 120.3018\n",
      "Epoch 337/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.6919 - val_loss: 120.2576\n",
      "Epoch 338/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.6681 - val_loss: 120.2156\n",
      "Epoch 339/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.6442 - val_loss: 120.1676\n",
      "Epoch 340/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.6200 - val_loss: 120.1185\n",
      "Epoch 341/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.5975 - val_loss: 120.0733\n",
      "Epoch 342/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.5757 - val_loss: 120.0283\n",
      "Epoch 343/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.5523 - val_loss: 119.9796\n",
      "Epoch 344/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.5300 - val_loss: 119.9376\n",
      "Epoch 345/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.5087 - val_loss: 119.8937\n",
      "Epoch 346/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.4879 - val_loss: 119.8500\n",
      "Epoch 347/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.4669 - val_loss: 119.8098\n",
      "Epoch 348/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.4462 - val_loss: 119.7694\n",
      "Epoch 349/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.4262 - val_loss: 119.7297\n",
      "Epoch 350/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.4069 - val_loss: 119.6915\n",
      "Epoch 351/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.3878 - val_loss: 119.6567\n",
      "Epoch 352/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.3665 - val_loss: 119.6224\n",
      "Epoch 353/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.3463 - val_loss: 119.5865\n",
      "Epoch 354/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.3274 - val_loss: 119.5560\n",
      "Epoch 355/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.3084 - val_loss: 119.5306\n",
      "Epoch 356/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.2887 - val_loss: 119.4979\n",
      "Epoch 357/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.2685 - val_loss: 119.4667\n",
      "Epoch 358/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.2507 - val_loss: 119.4350\n",
      "Epoch 359/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.2321 - val_loss: 119.4051\n",
      "Epoch 360/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.2135 - val_loss: 119.3725\n",
      "Epoch 361/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.1950 - val_loss: 119.3408\n",
      "Epoch 362/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.1785 - val_loss: 119.3162\n",
      "Epoch 363/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.1612 - val_loss: 119.2867\n",
      "Epoch 364/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.1440 - val_loss: 119.2610\n",
      "Epoch 365/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.1264 - val_loss: 119.2377\n",
      "Epoch 366/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.1107 - val_loss: 119.2070\n",
      "Epoch 367/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.0934 - val_loss: 119.1780\n",
      "Epoch 368/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.0768 - val_loss: 119.1546\n",
      "Epoch 369/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.0607 - val_loss: 119.1313\n",
      "Epoch 370/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.0438 - val_loss: 119.1117\n",
      "Epoch 371/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.0282 - val_loss: 119.0905\n",
      "Epoch 372/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.0120 - val_loss: 119.0740\n",
      "Epoch 373/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.9979 - val_loss: 119.0578\n",
      "Epoch 374/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.9824 - val_loss: 119.0436\n",
      "Epoch 375/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.9663 - val_loss: 119.0247\n",
      "Epoch 376/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.9502 - val_loss: 119.0142\n",
      "Epoch 377/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.9352 - val_loss: 118.9997\n",
      "Epoch 378/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.9194 - val_loss: 118.9909\n",
      "Epoch 379/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.9058 - val_loss: 118.9763\n",
      "Epoch 380/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.8906 - val_loss: 118.9667\n",
      "Epoch 381/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.8753 - val_loss: 118.9610\n",
      "Epoch 382/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.8608 - val_loss: 118.9493\n",
      "Epoch 383/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.8476 - val_loss: 118.9417\n",
      "Epoch 384/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.8313 - val_loss: 118.9316\n",
      "Epoch 385/10000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 105.820 - 0s - loss: 104.8178 - val_loss: 118.9240\n",
      "Epoch 386/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.8049 - val_loss: 118.9127\n",
      "Epoch 387/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7898 - val_loss: 118.9060\n",
      "Epoch 388/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7761 - val_loss: 118.8950\n",
      "Epoch 389/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7624 - val_loss: 118.8879\n",
      "Epoch 390/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7470 - val_loss: 118.8750\n",
      "Epoch 391/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7321 - val_loss: 118.8644\n",
      "Epoch 392/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7197 - val_loss: 118.8538\n",
      "Epoch 393/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7048 - val_loss: 118.8472\n",
      "Epoch 394/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.6916 - val_loss: 118.8380\n",
      "Epoch 395/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.6789 - val_loss: 118.8305\n",
      "Epoch 396/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.6646 - val_loss: 118.8228\n",
      "Epoch 397/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.6514 - val_loss: 118.8167\n",
      "Epoch 398/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.6383 - val_loss: 118.8091\n",
      "Epoch 399/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.6247 - val_loss: 118.8072\n",
      "Epoch 400/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.6118 - val_loss: 118.8058\n",
      "Epoch 401/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 104.5980 - val_loss: 118.7986\n",
      "Epoch 402/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.5842 - val_loss: 118.7912\n",
      "Epoch 403/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.5706 - val_loss: 118.7893\n",
      "Epoch 404/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.5567 - val_loss: 118.7824\n",
      "Epoch 405/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.5431 - val_loss: 118.7786\n",
      "Epoch 406/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.5310 - val_loss: 118.7725\n",
      "Epoch 407/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.5170 - val_loss: 118.7682\n",
      "Epoch 408/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.5034 - val_loss: 118.7653\n",
      "Epoch 409/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4907 - val_loss: 118.7595\n",
      "Epoch 410/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4779 - val_loss: 118.7599\n",
      "Epoch 411/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4646 - val_loss: 118.7588\n",
      "Epoch 412/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4524 - val_loss: 118.7568\n",
      "Epoch 413/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4394 - val_loss: 118.7526\n",
      "Epoch 414/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4270 - val_loss: 118.7500\n",
      "Epoch 415/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4152 - val_loss: 118.7465\n",
      "Epoch 416/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.4017 - val_loss: 118.7395\n",
      "Epoch 417/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3902 - val_loss: 118.7345\n",
      "Epoch 418/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3773 - val_loss: 118.7336\n",
      "Epoch 419/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3654 - val_loss: 118.7291\n",
      "Epoch 420/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3526 - val_loss: 118.7262\n",
      "Epoch 421/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3397 - val_loss: 118.7248\n",
      "Epoch 422/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3281 - val_loss: 118.7222\n",
      "Epoch 423/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3164 - val_loss: 118.7190\n",
      "Epoch 424/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.3037 - val_loss: 118.7169\n",
      "Epoch 425/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2910 - val_loss: 118.7142\n",
      "Epoch 426/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2798 - val_loss: 118.7106\n",
      "Epoch 427/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2669 - val_loss: 118.7031\n",
      "Epoch 428/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2551 - val_loss: 118.7020\n",
      "Epoch 429/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2423 - val_loss: 118.6951\n",
      "Epoch 430/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2301 - val_loss: 118.6938\n",
      "Epoch 431/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2187 - val_loss: 118.6884\n",
      "Epoch 432/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2068 - val_loss: 118.6817\n",
      "Epoch 433/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1947 - val_loss: 118.6770\n",
      "Epoch 434/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1834 - val_loss: 118.6703\n",
      "Epoch 435/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1707 - val_loss: 118.6625\n",
      "Epoch 436/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1598 - val_loss: 118.6559\n",
      "Epoch 437/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1489 - val_loss: 118.6491\n",
      "Epoch 438/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1373 - val_loss: 118.6458\n",
      "Epoch 439/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1274 - val_loss: 118.6417\n",
      "Epoch 440/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1165 - val_loss: 118.6374\n",
      "Epoch 441/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.1060 - val_loss: 118.6320\n",
      "Epoch 442/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0950 - val_loss: 118.6270\n",
      "Epoch 443/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0846 - val_loss: 118.6182\n",
      "Epoch 444/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0743 - val_loss: 118.6093\n",
      "Epoch 445/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0635 - val_loss: 118.6073\n",
      "Epoch 446/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0540 - val_loss: 118.5986\n",
      "Epoch 447/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0429 - val_loss: 118.5914\n",
      "Epoch 448/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0307 - val_loss: 118.5846\n",
      "Epoch 449/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0214 - val_loss: 118.5802\n",
      "Epoch 450/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0109 - val_loss: 118.5749\n",
      "Epoch 451/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.0006 - val_loss: 118.5678\n",
      "Epoch 452/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9898 - val_loss: 118.5617\n",
      "Epoch 453/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9792 - val_loss: 118.5557\n",
      "Epoch 454/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9685 - val_loss: 118.5514\n",
      "Epoch 455/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9581 - val_loss: 118.5451\n",
      "Epoch 456/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9478 - val_loss: 118.5355\n",
      "Epoch 457/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9379 - val_loss: 118.5255\n",
      "Epoch 458/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9259 - val_loss: 118.5259\n",
      "Epoch 459/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9164 - val_loss: 118.5168\n",
      "Epoch 460/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.9056 - val_loss: 118.5034\n",
      "Epoch 461/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8959 - val_loss: 118.4981\n",
      "Epoch 462/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8861 - val_loss: 118.4885\n",
      "Epoch 463/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8756 - val_loss: 118.4810\n",
      "Epoch 464/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8663 - val_loss: 118.4764\n",
      "Epoch 465/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8571 - val_loss: 118.4663\n",
      "Epoch 466/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8469 - val_loss: 118.4584\n",
      "Epoch 467/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8380 - val_loss: 118.4503\n",
      "Epoch 468/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8282 - val_loss: 118.4481\n",
      "Epoch 469/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8192 - val_loss: 118.4390\n",
      "Epoch 470/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8092 - val_loss: 118.4316\n",
      "Epoch 471/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8007 - val_loss: 118.4274\n",
      "Epoch 472/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7910 - val_loss: 118.4181\n",
      "Epoch 473/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7821 - val_loss: 118.4117\n",
      "Epoch 474/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7725 - val_loss: 118.4105\n",
      "Epoch 475/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7640 - val_loss: 118.3989\n",
      "Epoch 476/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7550 - val_loss: 118.3941\n",
      "Epoch 477/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7471 - val_loss: 118.3893\n",
      "Epoch 478/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7368 - val_loss: 118.3792\n",
      "Epoch 479/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7277 - val_loss: 118.3764\n",
      "Epoch 480/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7200 - val_loss: 118.3652\n",
      "Epoch 481/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 103.7113 - val_loss: 118.3576\n",
      "Epoch 482/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.7035 - val_loss: 118.3537\n",
      "Epoch 483/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6949 - val_loss: 118.3494\n",
      "Epoch 484/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6866 - val_loss: 118.3422\n",
      "Epoch 485/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6773 - val_loss: 118.3383\n",
      "Epoch 486/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6703 - val_loss: 118.3339\n",
      "Epoch 487/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6615 - val_loss: 118.3280\n",
      "Epoch 488/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6522 - val_loss: 118.3223\n",
      "Epoch 489/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6450 - val_loss: 118.3190\n",
      "Epoch 490/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6363 - val_loss: 118.3129\n",
      "Epoch 491/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6292 - val_loss: 118.3112\n",
      "Epoch 492/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6212 - val_loss: 118.3086\n",
      "Epoch 493/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6131 - val_loss: 118.3053\n",
      "Epoch 494/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6058 - val_loss: 118.3005\n",
      "Epoch 495/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5972 - val_loss: 118.2953\n",
      "Epoch 496/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5898 - val_loss: 118.2932111.92\n",
      "Epoch 497/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5828 - val_loss: 118.2911\n",
      "Epoch 498/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5741 - val_loss: 118.2894\n",
      "Epoch 499/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5670 - val_loss: 118.2857\n",
      "Epoch 500/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5598 - val_loss: 118.2830\n",
      "Epoch 501/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5526 - val_loss: 118.2802\n",
      "Epoch 502/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5455 - val_loss: 118.2802\n",
      "Epoch 503/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5386 - val_loss: 118.2755\n",
      "Epoch 504/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5310 - val_loss: 118.2741\n",
      "Epoch 505/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5241 - val_loss: 118.2674\n",
      "Epoch 506/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5175 - val_loss: 118.2648\n",
      "Epoch 507/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5097 - val_loss: 118.2638\n",
      "Epoch 508/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.5036 - val_loss: 118.2626\n",
      "Epoch 509/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4965 - val_loss: 118.2601\n",
      "Epoch 510/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4889 - val_loss: 118.2576\n",
      "Epoch 511/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4826 - val_loss: 118.2501\n",
      "Epoch 512/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4761 - val_loss: 118.2505\n",
      "Epoch 513/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4694 - val_loss: 118.2482\n",
      "Epoch 514/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4626 - val_loss: 118.2461\n",
      "Epoch 515/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4540 - val_loss: 118.2438\n",
      "Epoch 516/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4483 - val_loss: 118.2437\n",
      "Epoch 517/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4415 - val_loss: 118.2416\n",
      "Epoch 518/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4336 - val_loss: 118.2423\n",
      "Epoch 519/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4265 - val_loss: 118.2345\n",
      "Epoch 520/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4194 - val_loss: 118.2336\n",
      "Epoch 521/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4126 - val_loss: 118.2328\n",
      "Epoch 522/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4056 - val_loss: 118.2290\n",
      "Epoch 523/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3984 - val_loss: 118.2219\n",
      "Epoch 524/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3909 - val_loss: 118.2181\n",
      "Epoch 525/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3842 - val_loss: 118.2183\n",
      "Epoch 526/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3780 - val_loss: 118.2183\n",
      "Epoch 527/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3705 - val_loss: 118.2147\n",
      "Epoch 528/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3638 - val_loss: 118.2088\n",
      "Epoch 529/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3577 - val_loss: 118.2079\n",
      "Epoch 530/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3497 - val_loss: 118.2078\n",
      "Epoch 531/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3446 - val_loss: 118.2043\n",
      "Epoch 532/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3363 - val_loss: 118.2008\n",
      "Epoch 533/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3308 - val_loss: 118.2014\n",
      "Epoch 534/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3231 - val_loss: 118.2001\n",
      "Epoch 535/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3176 - val_loss: 118.1984\n",
      "Epoch 536/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3115 - val_loss: 118.1989\n",
      "Epoch 537/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.3041 - val_loss: 118.1980\n",
      "Epoch 538/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2986 - val_loss: 118.1954\n",
      "Epoch 539/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2917 - val_loss: 118.1975\n",
      "Epoch 540/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2834 - val_loss: 118.1923\n",
      "Epoch 541/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2790 - val_loss: 118.1890\n",
      "Epoch 542/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2721 - val_loss: 118.1895\n",
      "Epoch 543/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2651 - val_loss: 118.1920\n",
      "Epoch 544/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2587 - val_loss: 118.1885\n",
      "Epoch 545/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2528 - val_loss: 118.1859\n",
      "Epoch 546/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2454 - val_loss: 118.1861\n",
      "Epoch 547/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2398 - val_loss: 118.1816\n",
      "Epoch 548/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2323 - val_loss: 118.1799\n",
      "Epoch 549/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2256 - val_loss: 118.1762\n",
      "Epoch 550/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2201 - val_loss: 118.1721\n",
      "Epoch 551/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2131 - val_loss: 118.1683\n",
      "Epoch 552/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2065 - val_loss: 118.1741\n",
      "Epoch 553/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.2007 - val_loss: 118.1656\n",
      "Epoch 554/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1932 - val_loss: 118.1640\n",
      "Epoch 555/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1873 - val_loss: 118.1589\n",
      "Epoch 556/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1801 - val_loss: 118.1542\n",
      "Epoch 557/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1757 - val_loss: 118.1489\n",
      "Epoch 558/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1673 - val_loss: 118.1490\n",
      "Epoch 559/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1620 - val_loss: 118.1459\n",
      "Epoch 560/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1561 - val_loss: 118.1448\n",
      "Epoch 561/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 103.1492 - val_loss: 118.1355\n",
      "Epoch 562/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1426 - val_loss: 118.1322\n",
      "Epoch 563/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1376 - val_loss: 118.1275\n",
      "Epoch 564/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1301 - val_loss: 118.1243\n",
      "Epoch 565/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1252 - val_loss: 118.1198\n",
      "Epoch 566/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1191 - val_loss: 118.1169\n",
      "Epoch 567/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1130 - val_loss: 118.1118\n",
      "Epoch 568/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1067 - val_loss: 118.1086\n",
      "Epoch 569/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1005 - val_loss: 118.1075\n",
      "Epoch 570/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0930 - val_loss: 118.1061\n",
      "Epoch 571/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0880 - val_loss: 118.1041\n",
      "Epoch 572/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0797 - val_loss: 118.1020\n",
      "Epoch 573/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0731 - val_loss: 118.1002\n",
      "Epoch 574/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0659 - val_loss: 118.1001\n",
      "Epoch 575/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0588 - val_loss: 118.0944\n",
      "Epoch 576/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0531 - val_loss: 118.0917\n",
      "Epoch 577/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0457 - val_loss: 118.0929\n",
      "Epoch 578/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0394 - val_loss: 118.0883\n",
      "Epoch 579/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0319 - val_loss: 118.0886\n",
      "Epoch 580/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0258 - val_loss: 118.0848\n",
      "Epoch 581/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0195 - val_loss: 118.0814\n",
      "Epoch 582/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0122 - val_loss: 118.0806\n",
      "Epoch 583/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.0060 - val_loss: 118.0797\n",
      "Epoch 584/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9994 - val_loss: 118.0783\n",
      "Epoch 585/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9922 - val_loss: 118.0736\n",
      "Epoch 586/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9855 - val_loss: 118.0666\n",
      "Epoch 587/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9788 - val_loss: 118.0686\n",
      "Epoch 588/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9733 - val_loss: 118.0678\n",
      "Epoch 589/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9665 - val_loss: 118.0647\n",
      "Epoch 590/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9602 - val_loss: 118.0571\n",
      "Epoch 591/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9516 - val_loss: 118.0553\n",
      "Epoch 592/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9469 - val_loss: 118.0530\n",
      "Epoch 593/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9400 - val_loss: 118.0504\n",
      "Epoch 594/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9343 - val_loss: 118.0488\n",
      "Epoch 595/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9274 - val_loss: 118.0415\n",
      "Epoch 596/10000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 108.467 - 0s - loss: 102.9205 - val_loss: 118.0421\n",
      "Epoch 597/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9144 - val_loss: 118.0425\n",
      "Epoch 598/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9084 - val_loss: 118.0390\n",
      "Epoch 599/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9020 - val_loss: 118.0351\n",
      "Epoch 600/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8946 - val_loss: 118.0331\n",
      "Epoch 601/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8884 - val_loss: 118.0288\n",
      "Epoch 602/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8830 - val_loss: 118.0251\n",
      "Epoch 603/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8757 - val_loss: 118.0229\n",
      "Epoch 604/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8695 - val_loss: 118.0172\n",
      "Epoch 605/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8633 - val_loss: 118.0122\n",
      "Epoch 606/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8579 - val_loss: 118.0051\n",
      "Epoch 607/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8520 - val_loss: 117.9974\n",
      "Epoch 608/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8457 - val_loss: 117.9887\n",
      "Epoch 609/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8381 - val_loss: 117.9880\n",
      "Epoch 610/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8331 - val_loss: 117.9835\n",
      "Epoch 611/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8257 - val_loss: 117.9784\n",
      "Epoch 612/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8184 - val_loss: 117.9720\n",
      "Epoch 613/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8110 - val_loss: 117.9704\n",
      "Epoch 614/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.8050 - val_loss: 117.9685\n",
      "Epoch 615/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7984 - val_loss: 117.9693\n",
      "Epoch 616/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7909 - val_loss: 117.9650\n",
      "Epoch 617/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7842 - val_loss: 117.9637\n",
      "Epoch 618/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7768 - val_loss: 117.9628\n",
      "Epoch 619/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7712 - val_loss: 117.9596\n",
      "Epoch 620/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7645 - val_loss: 117.9629\n",
      "Epoch 621/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7586 - val_loss: 117.9620\n",
      "Epoch 622/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7514 - val_loss: 117.9585\n",
      "Epoch 623/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7436 - val_loss: 117.9563\n",
      "Epoch 624/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7374 - val_loss: 117.9555\n",
      "Epoch 625/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7313 - val_loss: 117.9534\n",
      "Epoch 626/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7235 - val_loss: 117.9447\n",
      "Epoch 627/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7162 - val_loss: 117.9456\n",
      "Epoch 628/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7086 - val_loss: 117.9396\n",
      "Epoch 629/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.7024 - val_loss: 117.9413\n",
      "Epoch 630/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6948 - val_loss: 117.9372\n",
      "Epoch 631/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6871 - val_loss: 117.9339\n",
      "Epoch 632/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6803 - val_loss: 117.9340\n",
      "Epoch 633/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6742 - val_loss: 117.9270\n",
      "Epoch 634/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6682 - val_loss: 117.9288\n",
      "Epoch 635/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6615 - val_loss: 117.9227\n",
      "Epoch 636/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6531 - val_loss: 117.9183\n",
      "Epoch 637/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6463 - val_loss: 117.9111\n",
      "Epoch 638/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6394 - val_loss: 117.9094\n",
      "Epoch 639/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6310 - val_loss: 117.9047\n",
      "Epoch 640/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6252 - val_loss: 117.8990\n",
      "Epoch 641/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 102.6162 - val_loss: 117.8953\n",
      "Epoch 642/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6095 - val_loss: 117.8940\n",
      "Epoch 643/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6027 - val_loss: 117.8909\n",
      "Epoch 644/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5958 - val_loss: 117.8900\n",
      "Epoch 645/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5867 - val_loss: 117.8839\n",
      "Epoch 646/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5792 - val_loss: 117.8766\n",
      "Epoch 647/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5713 - val_loss: 117.8733\n",
      "Epoch 648/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5627 - val_loss: 117.8648\n",
      "Epoch 649/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5547 - val_loss: 117.8581\n",
      "Epoch 650/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5458 - val_loss: 117.8558\n",
      "Epoch 651/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5384 - val_loss: 117.8510: 110.06\n",
      "Epoch 652/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5323 - val_loss: 117.8467\n",
      "Epoch 653/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5237 - val_loss: 117.8397\n",
      "Epoch 654/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5165 - val_loss: 117.8355\n",
      "Epoch 655/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5076 - val_loss: 117.8297\n",
      "Epoch 656/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5007 - val_loss: 117.8235\n",
      "Epoch 657/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4927 - val_loss: 117.8180\n",
      "Epoch 658/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4867 - val_loss: 117.8164\n",
      "Epoch 659/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4814 - val_loss: 117.8104\n",
      "Epoch 660/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4739 - val_loss: 117.8073\n",
      "Epoch 661/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4676 - val_loss: 117.8032\n",
      "Epoch 662/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4614 - val_loss: 117.8032\n",
      "Epoch 663/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4546 - val_loss: 117.8015\n",
      "Epoch 664/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4496 - val_loss: 117.7978\n",
      "Epoch 665/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4423 - val_loss: 117.7984\n",
      "Epoch 666/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4363 - val_loss: 117.7995\n",
      "Epoch 667/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4307 - val_loss: 117.7940\n",
      "Epoch 668/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4253 - val_loss: 117.7982\n",
      "Epoch 669/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4170 - val_loss: 117.7980\n",
      "Epoch 670/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4125 - val_loss: 117.7985\n",
      "Epoch 671/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4085 - val_loss: 117.7988\n",
      "Epoch 672/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.4001 - val_loss: 117.7969\n",
      "Epoch 673/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3948 - val_loss: 117.7953\n",
      "Epoch 674/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3887 - val_loss: 117.7975\n",
      "Epoch 675/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3813 - val_loss: 117.7939\n",
      "Epoch 676/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3749 - val_loss: 117.7958\n",
      "Epoch 677/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3695 - val_loss: 117.7923\n",
      "Epoch 678/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3642 - val_loss: 117.7898\n",
      "Epoch 679/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3579 - val_loss: 117.7886\n",
      "Epoch 680/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3524 - val_loss: 117.7865\n",
      "Epoch 681/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3452 - val_loss: 117.7864\n",
      "Epoch 682/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3420 - val_loss: 117.7859\n",
      "Epoch 683/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3340 - val_loss: 117.7845\n",
      "Epoch 684/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3291 - val_loss: 117.7865\n",
      "Epoch 685/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3234 - val_loss: 117.7853\n",
      "Epoch 686/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3171 - val_loss: 117.7847\n",
      "Epoch 687/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3112 - val_loss: 117.7833\n",
      "Epoch 688/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3051 - val_loss: 117.7858\n",
      "Epoch 689/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.3003 - val_loss: 117.7907\n",
      "Epoch 690/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2934 - val_loss: 117.7912\n",
      "Epoch 691/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2890 - val_loss: 117.7952\n",
      "Epoch 692/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2822 - val_loss: 117.7920\n",
      "Epoch 693/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2760 - val_loss: 117.7885\n",
      "Epoch 694/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2706 - val_loss: 117.7844\n",
      "Epoch 695/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2650 - val_loss: 117.7795\n",
      "Epoch 696/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2585 - val_loss: 117.7778\n",
      "Epoch 697/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2515 - val_loss: 117.7739\n",
      "Epoch 698/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2467 - val_loss: 117.7722\n",
      "Epoch 699/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2402 - val_loss: 117.7660\n",
      "Epoch 700/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2347 - val_loss: 117.7663\n",
      "Epoch 701/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2299 - val_loss: 117.7667\n",
      "Epoch 702/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2237 - val_loss: 117.7623\n",
      "Epoch 703/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2183 - val_loss: 117.7579\n",
      "Epoch 704/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2127 - val_loss: 117.7585\n",
      "Epoch 705/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2072 - val_loss: 117.7545\n",
      "Epoch 706/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.2012 - val_loss: 117.7521\n",
      "Epoch 707/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1968 - val_loss: 117.7517\n",
      "Epoch 708/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1903 - val_loss: 117.7541\n",
      "Epoch 709/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1850 - val_loss: 117.7563\n",
      "Epoch 710/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1786 - val_loss: 117.7581\n",
      "Epoch 711/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1750 - val_loss: 117.7600\n",
      "Epoch 712/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1687 - val_loss: 117.7603\n",
      "Epoch 713/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1638 - val_loss: 117.7573\n",
      "Epoch 714/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1571 - val_loss: 117.7558\n",
      "Epoch 715/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1533 - val_loss: 117.7560\n",
      "Epoch 716/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1470 - val_loss: 117.7572\n",
      "Epoch 717/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1434 - val_loss: 117.7584\n",
      "Epoch 718/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1374 - val_loss: 117.7594\n",
      "Epoch 00717: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto', patience=10)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10000, validation_data=(X_valid, y_valid), callbacks=[early_stopping], verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1163f8940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1165259b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "plt.title('Cot et cot de validation')\n",
    "line1,=plt.plot(history.history['loss'], label=\"Loss\", linestyle='-', color='r')\n",
    "line2,=plt.plot(history.history['val_loss'], label=\"Val loss\", linestyle='-', color='b')\n",
    "first_legend = plt.legend(handles=[line1, line2], loc=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.title('y_pred en fonction de y_test')\n",
    "\n",
    "plt.plot(y_pred[:], y_test[:], '+')\n",
    "plt.ylabel('Test')\n",
    "plt.xlabel('Prdiction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                5248      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,281\n",
      "Trainable params: 5,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model(32, X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1126 samples, validate on 563 samples\n",
      "Epoch 1/10000\n",
      "1126/1126 [==============================] - 1s - loss: 3347.1395 - val_loss: 3007.1302\n",
      "Epoch 2/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3336.0125 - val_loss: 2995.4703\n",
      "Epoch 3/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3318.5164 - val_loss: 2975.9344\n",
      "Epoch 4/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3288.8466 - val_loss: 2943.0173\n",
      "Epoch 5/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3240.5420 - val_loss: 2890.9079\n",
      "Epoch 6/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3167.3329 - val_loss: 2815.3084\n",
      "Epoch 7/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3065.5109 - val_loss: 2715.3289\n",
      "Epoch 8/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2935.7506 - val_loss: 2593.7298\n",
      "Epoch 9/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2781.0850 - val_loss: 2450.8504\n",
      "Epoch 10/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2603.3512 - val_loss: 2288.4919\n",
      "Epoch 11/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2406.1767 - val_loss: 2112.1413\n",
      "Epoch 12/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2195.8774 - val_loss: 1931.0691\n",
      "Epoch 13/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1983.1268 - val_loss: 1752.9514\n",
      "Epoch 14/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1776.3963 - val_loss: 1582.1943\n",
      "Epoch 15/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1580.0043 - val_loss: 1421.5076\n",
      "Epoch 16/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1397.9879 - val_loss: 1273.4430\n",
      "Epoch 17/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1233.0835 - val_loss: 1140.1219\n",
      "Epoch 18/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1087.1283 - val_loss: 1022.7465\n",
      "Epoch 19/10000\n",
      "1126/1126 [==============================] - 0s - loss: 961.1037 - val_loss: 921.8259\n",
      "Epoch 20/10000\n",
      "1126/1126 [==============================] - 0s - loss: 854.6994 - val_loss: 836.6810\n",
      "Epoch 21/10000\n",
      "1126/1126 [==============================] - 0s - loss: 766.5553 - val_loss: 765.9729\n",
      "Epoch 22/10000\n",
      "1126/1126 [==============================] - 0s - loss: 694.7151 - val_loss: 708.0285\n",
      "Epoch 23/10000\n",
      "1126/1126 [==============================] - 0s - loss: 636.9327 - val_loss: 660.9688\n",
      "Epoch 24/10000\n",
      "1126/1126 [==============================] - 0s - loss: 590.7931 - val_loss: 622.6977\n",
      "Epoch 25/10000\n",
      "1126/1126 [==============================] - 0s - loss: 553.8276 - val_loss: 591.3190\n",
      "Epoch 26/10000\n",
      "1126/1126 [==============================] - 0s - loss: 523.9111 - val_loss: 565.3296\n",
      "Epoch 27/10000\n",
      "1126/1126 [==============================] - 0s - loss: 499.2725 - val_loss: 543.3421\n",
      "Epoch 28/10000\n",
      "1126/1126 [==============================] - 0s - loss: 478.4588 - val_loss: 524.3671\n",
      "Epoch 29/10000\n",
      "1126/1126 [==============================] - 0s - loss: 460.4113 - val_loss: 507.5777\n",
      "Epoch 30/10000\n",
      "1126/1126 [==============================] - 0s - loss: 444.2697 - val_loss: 492.4093\n",
      "Epoch 31/10000\n",
      "1126/1126 [==============================] - 0s - loss: 429.5255 - val_loss: 478.5058\n",
      "Epoch 32/10000\n",
      "1126/1126 [==============================] - 0s - loss: 415.7838 - val_loss: 465.5785\n",
      "Epoch 33/10000\n",
      "1126/1126 [==============================] - 0s - loss: 402.7698 - val_loss: 453.4094\n",
      "Epoch 34/10000\n",
      "1126/1126 [==============================] - 0s - loss: 390.3452 - val_loss: 441.9005\n",
      "Epoch 35/10000\n",
      "1126/1126 [==============================] - 0s - loss: 378.4159 - val_loss: 430.9963\n",
      "Epoch 36/10000\n",
      "1126/1126 [==============================] - 0s - loss: 366.9527 - val_loss: 420.6512\n",
      "Epoch 37/10000\n",
      "1126/1126 [==============================] - 0s - loss: 355.9295 - val_loss: 410.8191\n",
      "Epoch 38/10000\n",
      "1126/1126 [==============================] - 0s - loss: 345.2958 - val_loss: 401.4551\n",
      "Epoch 39/10000\n",
      "1126/1126 [==============================] - 0s - loss: 335.0653 - val_loss: 392.5680\n",
      "Epoch 40/10000\n",
      "1126/1126 [==============================] - 0s - loss: 325.2237 - val_loss: 384.1440\n",
      "Epoch 41/10000\n",
      "1126/1126 [==============================] - 0s - loss: 315.7718 - val_loss: 376.1654\n",
      "Epoch 42/10000\n",
      "1126/1126 [==============================] - 0s - loss: 306.7244 - val_loss: 368.6125\n",
      "Epoch 43/10000\n",
      "1126/1126 [==============================] - 0s - loss: 298.0636 - val_loss: 361.4878\n",
      "Epoch 44/10000\n",
      "1126/1126 [==============================] - 0s - loss: 289.7980 - val_loss: 354.7359\n",
      "Epoch 45/10000\n",
      "1126/1126 [==============================] - 0s - loss: 281.9065 - val_loss: 348.3364\n",
      "Epoch 46/10000\n",
      "1126/1126 [==============================] - 0s - loss: 274.3635 - val_loss: 342.2638\n",
      "Epoch 47/10000\n",
      "1126/1126 [==============================] - 0s - loss: 267.1181 - val_loss: 336.4608\n",
      "Epoch 48/10000\n",
      "1126/1126 [==============================] - 0s - loss: 260.1402 - val_loss: 330.9073\n",
      "Epoch 49/10000\n",
      "1126/1126 [==============================] - 0s - loss: 253.4225 - val_loss: 325.5921\n",
      "Epoch 50/10000\n",
      "1126/1126 [==============================] - 0s - loss: 246.9421 - val_loss: 320.4851\n",
      "Epoch 51/10000\n",
      "1126/1126 [==============================] - 0s - loss: 240.6372 - val_loss: 315.5925\n",
      "Epoch 52/10000\n",
      "1126/1126 [==============================] - 0s - loss: 234.5489 - val_loss: 310.8906\n",
      "Epoch 53/10000\n",
      "1126/1126 [==============================] - 0s - loss: 228.6825 - val_loss: 306.3503\n",
      "Epoch 54/10000\n",
      "1126/1126 [==============================] - 0s - loss: 223.0293 - val_loss: 301.9649243\n",
      "Epoch 55/10000\n",
      "1126/1126 [==============================] - 0s - loss: 217.5951 - val_loss: 297.7035\n",
      "Epoch 56/10000\n",
      "1126/1126 [==============================] - 0s - loss: 212.3889 - val_loss: 293.5623\n",
      "Epoch 57/10000\n",
      "1126/1126 [==============================] - 0s - loss: 207.3976 - val_loss: 289.5456\n",
      "Epoch 58/10000\n",
      "1126/1126 [==============================] - 0s - loss: 202.5985 - val_loss: 285.6511\n",
      "Epoch 59/10000\n",
      "1126/1126 [==============================] - 0s - loss: 197.9891 - val_loss: 281.8639\n",
      "Epoch 60/10000\n",
      "1126/1126 [==============================] - 0s - loss: 193.5679 - val_loss: 278.1675\n",
      "Epoch 61/10000\n",
      "1126/1126 [==============================] - 0s - loss: 189.3350 - val_loss: 274.5686\n",
      "Epoch 62/10000\n",
      "1126/1126 [==============================] - 0s - loss: 185.2851 - val_loss: 271.0712\n",
      "Epoch 63/10000\n",
      "1126/1126 [==============================] - 0s - loss: 181.3907 - val_loss: 267.6739\n",
      "Epoch 64/10000\n",
      "1126/1126 [==============================] - 0s - loss: 177.6629 - val_loss: 264.3604\n",
      "Epoch 65/10000\n",
      "1126/1126 [==============================] - 0s - loss: 174.0984 - val_loss: 261.1378\n",
      "Epoch 66/10000\n",
      "1126/1126 [==============================] - 0s - loss: 170.6903 - val_loss: 257.9902\n",
      "Epoch 67/10000\n",
      "1126/1126 [==============================] - 0s - loss: 167.4354 - val_loss: 254.9174\n",
      "Epoch 68/10000\n",
      "1126/1126 [==============================] - 0s - loss: 164.3250 - val_loss: 251.9208\n",
      "Epoch 69/10000\n",
      "1126/1126 [==============================] - 0s - loss: 161.3439 - val_loss: 249.0177\n",
      "Epoch 70/10000\n",
      "1126/1126 [==============================] - 0s - loss: 158.4889 - val_loss: 246.1836\n",
      "Epoch 71/10000\n",
      "1126/1126 [==============================] - 0s - loss: 155.7711 - val_loss: 243.3959\n",
      "Epoch 72/10000\n",
      "1126/1126 [==============================] - 0s - loss: 153.1934 - val_loss: 240.6676\n",
      "Epoch 73/10000\n",
      "1126/1126 [==============================] - 0s - loss: 150.7390 - val_loss: 238.0057\n",
      "Epoch 74/10000\n",
      "1126/1126 [==============================] - 0s - loss: 148.3918 - val_loss: 235.4240\n",
      "Epoch 75/10000\n",
      "1126/1126 [==============================] - 0s - loss: 146.1433 - val_loss: 232.9068\n",
      "Epoch 76/10000\n",
      "1126/1126 [==============================] - 0s - loss: 143.9977 - val_loss: 230.4332\n",
      "Epoch 77/10000\n",
      "1126/1126 [==============================] - 0s - loss: 141.9501 - val_loss: 228.0033\n",
      "Epoch 78/10000\n",
      "1126/1126 [==============================] - 0s - loss: 140.0080 - val_loss: 225.6168\n",
      "Epoch 79/10000\n",
      "1126/1126 [==============================] - 0s - loss: 138.1671 - val_loss: 223.2787\n",
      "Epoch 80/10000\n",
      "1126/1126 [==============================] - 0s - loss: 136.4225 - val_loss: 220.9900\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 134.7675 - val_loss: 218.7598\n",
      "Epoch 82/10000\n",
      "1126/1126 [==============================] - 0s - loss: 133.1924 - val_loss: 216.5726\n",
      "Epoch 83/10000\n",
      "1126/1126 [==============================] - 0s - loss: 131.6962 - val_loss: 214.4362\n",
      "Epoch 84/10000\n",
      "1126/1126 [==============================] - 0s - loss: 130.2746 - val_loss: 212.3576\n",
      "Epoch 85/10000\n",
      "1126/1126 [==============================] - 0s - loss: 128.9205 - val_loss: 210.3207\n",
      "Epoch 86/10000\n",
      "1126/1126 [==============================] - 0s - loss: 127.6274 - val_loss: 208.3286\n",
      "Epoch 87/10000\n",
      "1126/1126 [==============================] - 0s - loss: 126.3898 - val_loss: 206.3752\n",
      "Epoch 88/10000\n",
      "1126/1126 [==============================] - 0s - loss: 125.2051 - val_loss: 204.4637\n",
      "Epoch 89/10000\n",
      "1126/1126 [==============================] - 0s - loss: 124.0708 - val_loss: 202.5895\n",
      "Epoch 90/10000\n",
      "1126/1126 [==============================] - 0s - loss: 122.9865 - val_loss: 200.7888\n",
      "Epoch 91/10000\n",
      "1126/1126 [==============================] - 0s - loss: 121.9389 - val_loss: 198.9906\n",
      "Epoch 92/10000\n",
      "1126/1126 [==============================] - 0s - loss: 120.9349 - val_loss: 197.2385\n",
      "Epoch 93/10000\n",
      "1126/1126 [==============================] - 0s - loss: 119.9672 - val_loss: 195.5051\n",
      "Epoch 94/10000\n",
      "1126/1126 [==============================] - 0s - loss: 119.0367 - val_loss: 193.8323\n",
      "Epoch 95/10000\n",
      "1126/1126 [==============================] - 0s - loss: 118.1349 - val_loss: 192.2006\n",
      "Epoch 96/10000\n",
      "1126/1126 [==============================] - 0s - loss: 117.2724 - val_loss: 190.6002\n",
      "Epoch 97/10000\n",
      "1126/1126 [==============================] - 0s - loss: 116.4431 - val_loss: 189.0154\n",
      "Epoch 98/10000\n",
      "1126/1126 [==============================] - 0s - loss: 115.6472 - val_loss: 187.4571\n",
      "Epoch 99/10000\n",
      "1126/1126 [==============================] - 0s - loss: 114.8789 - val_loss: 185.9255\n",
      "Epoch 100/10000\n",
      "1126/1126 [==============================] - 0s - loss: 114.1316 - val_loss: 184.4222\n",
      "Epoch 101/10000\n",
      "1126/1126 [==============================] - 0s - loss: 113.4014 - val_loss: 182.9161\n",
      "Epoch 102/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.6948 - val_loss: 181.4337\n",
      "Epoch 103/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.0034 - val_loss: 179.9758\n",
      "Epoch 104/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.3291 - val_loss: 178.5389\n",
      "Epoch 105/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.6722 - val_loss: 177.1222\n",
      "Epoch 106/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.0311 - val_loss: 175.7281\n",
      "Epoch 107/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.4053 - val_loss: 174.3497\n",
      "Epoch 108/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.7943 - val_loss: 172.9974\n",
      "Epoch 109/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.1910 - val_loss: 171.6561\n",
      "Epoch 110/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.5963 - val_loss: 170.3168\n",
      "Epoch 111/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.0114 - val_loss: 168.9939\n",
      "Epoch 112/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.4343 - val_loss: 167.6889\n",
      "Epoch 113/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.8651 - val_loss: 166.3976\n",
      "Epoch 114/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.3083 - val_loss: 165.1325\n",
      "Epoch 115/10000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 107.135 - 0s - loss: 104.7599 - val_loss: 163.8666\n",
      "Epoch 116/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2269 - val_loss: 162.6192\n",
      "Epoch 117/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.6992 - val_loss: 161.3816\n",
      "Epoch 118/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.1779 - val_loss: 160.1570\n",
      "Epoch 119/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.6663 - val_loss: 158.9542\n",
      "Epoch 120/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1603 - val_loss: 157.7739\n",
      "Epoch 121/10000\n",
      "1126/1126 [==============================] - 0s - loss: 101.6635 - val_loss: 156.6114\n",
      "Epoch 122/10000\n",
      "1126/1126 [==============================] - 0s - loss: 101.1732 - val_loss: 155.4673\n",
      "Epoch 123/10000\n",
      "1126/1126 [==============================] - 0s - loss: 100.6902 - val_loss: 154.3346\n",
      "Epoch 124/10000\n",
      "1126/1126 [==============================] - 0s - loss: 100.2122 - val_loss: 153.2221\n",
      "Epoch 125/10000\n",
      "1126/1126 [==============================] - 0s - loss: 99.7426 - val_loss: 152.1383\n",
      "Epoch 126/10000\n",
      "1126/1126 [==============================] - 0s - loss: 99.2807 - val_loss: 151.0790\n",
      "Epoch 127/10000\n",
      "1126/1126 [==============================] - 0s - loss: 98.8218 - val_loss: 150.0350\n",
      "Epoch 128/10000\n",
      "1126/1126 [==============================] - 0s - loss: 98.3694 - val_loss: 149.0039\n",
      "Epoch 129/10000\n",
      "1126/1126 [==============================] - 0s - loss: 97.9218 - val_loss: 147.9807\n",
      "Epoch 130/10000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4761 - val_loss: 146.9676\n",
      "Epoch 131/10000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0335 - val_loss: 145.9661\n",
      "Epoch 132/10000\n",
      "1126/1126 [==============================] - 0s - loss: 96.5971 - val_loss: 144.9785\n",
      "Epoch 133/10000\n",
      "1126/1126 [==============================] - 0s - loss: 96.1628 - val_loss: 143.9937\n",
      "Epoch 134/10000\n",
      "1126/1126 [==============================] - 0s - loss: 95.7348 - val_loss: 143.0169\n",
      "Epoch 135/10000\n",
      "1126/1126 [==============================] - 0s - loss: 95.3098 - val_loss: 142.0549\n",
      "Epoch 136/10000\n",
      "1126/1126 [==============================] - 0s - loss: 94.8926 - val_loss: 141.0986\n",
      "Epoch 137/10000\n",
      "1126/1126 [==============================] - 0s - loss: 94.4775 - val_loss: 140.1489\n",
      "Epoch 138/10000\n",
      "1126/1126 [==============================] - 0s - loss: 94.0696 - val_loss: 139.2209\n",
      "Epoch 139/10000\n",
      "1126/1126 [==============================] - 0s - loss: 93.6649 - val_loss: 138.3085\n",
      "Epoch 140/10000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2696 - val_loss: 137.4067\n",
      "Epoch 141/10000\n",
      "1126/1126 [==============================] - 0s - loss: 92.8744 - val_loss: 136.5268\n",
      "Epoch 142/10000\n",
      "1126/1126 [==============================] - 0s - loss: 92.4791 - val_loss: 135.6550\n",
      "Epoch 143/10000\n",
      "1126/1126 [==============================] - 0s - loss: 92.0874 - val_loss: 134.7992\n",
      "Epoch 144/10000\n",
      "1126/1126 [==============================] - 0s - loss: 91.6997 - val_loss: 133.9570\n",
      "Epoch 145/10000\n",
      "1126/1126 [==============================] - 0s - loss: 91.3207 - val_loss: 133.1248\n",
      "Epoch 146/10000\n",
      "1126/1126 [==============================] - 0s - loss: 90.9436 - val_loss: 132.3023\n",
      "Epoch 147/10000\n",
      "1126/1126 [==============================] - 0s - loss: 90.5704 - val_loss: 131.4857\n",
      "Epoch 148/10000\n",
      "1126/1126 [==============================] - 0s - loss: 90.2043 - val_loss: 130.6813\n",
      "Epoch 149/10000\n",
      "1126/1126 [==============================] - 0s - loss: 89.8412 - val_loss: 129.8986\n",
      "Epoch 150/10000\n",
      "1126/1126 [==============================] - 0s - loss: 89.4837 - val_loss: 129.1286\n",
      "Epoch 151/10000\n",
      "1126/1126 [==============================] - 0s - loss: 89.1321 - val_loss: 128.3738\n",
      "Epoch 152/10000\n",
      "1126/1126 [==============================] - 0s - loss: 88.7828 - val_loss: 127.6242\n",
      "Epoch 153/10000\n",
      "1126/1126 [==============================] - 0s - loss: 88.4352 - val_loss: 126.8801\n",
      "Epoch 154/10000\n",
      "1126/1126 [==============================] - 0s - loss: 88.0931 - val_loss: 126.1579\n",
      "Epoch 155/10000\n",
      "1126/1126 [==============================] - 0s - loss: 87.7521 - val_loss: 125.4502\n",
      "Epoch 156/10000\n",
      "1126/1126 [==============================] - 0s - loss: 87.4104 - val_loss: 124.7495\n",
      "Epoch 157/10000\n",
      "1126/1126 [==============================] - 0s - loss: 87.0719 - val_loss: 124.0535\n",
      "Epoch 158/10000\n",
      "1126/1126 [==============================] - 0s - loss: 86.7403 - val_loss: 123.3668\n",
      "Epoch 159/10000\n",
      "1126/1126 [==============================] - 0s - loss: 86.4116 - val_loss: 122.6893\n",
      "Epoch 160/10000\n",
      "1126/1126 [==============================] - 0s - loss: 86.0855 - val_loss: 122.0196\n",
      "Epoch 161/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 85.7643 - val_loss: 121.3537\n",
      "Epoch 162/10000\n",
      "1126/1126 [==============================] - 0s - loss: 85.4470 - val_loss: 120.7126\n",
      "Epoch 163/10000\n",
      "1126/1126 [==============================] - 0s - loss: 85.1309 - val_loss: 120.0818\n",
      "Epoch 164/10000\n",
      "1126/1126 [==============================] - 0s - loss: 84.8207 - val_loss: 119.4617\n",
      "Epoch 165/10000\n",
      "1126/1126 [==============================] - 0s - loss: 84.5155 - val_loss: 118.8466\n",
      "Epoch 166/10000\n",
      "1126/1126 [==============================] - 0s - loss: 84.2120 - val_loss: 118.2360\n",
      "Epoch 167/10000\n",
      "1126/1126 [==============================] - 0s - loss: 83.9111 - val_loss: 117.6392\n",
      "Epoch 168/10000\n",
      "1126/1126 [==============================] - 0s - loss: 83.6149 - val_loss: 117.0658\n",
      "Epoch 169/10000\n",
      "1126/1126 [==============================] - 0s - loss: 83.3214 - val_loss: 116.4965\n",
      "Epoch 170/10000\n",
      "1126/1126 [==============================] - 0s - loss: 83.0321 - val_loss: 115.9290\n",
      "Epoch 171/10000\n",
      "1126/1126 [==============================] - 0s - loss: 82.7433 - val_loss: 115.3724\n",
      "Epoch 172/10000\n",
      "1126/1126 [==============================] - 0s - loss: 82.4578 - val_loss: 114.8234\n",
      "Epoch 173/10000\n",
      "1126/1126 [==============================] - 0s - loss: 82.1775 - val_loss: 114.2809\n",
      "Epoch 174/10000\n",
      "1126/1126 [==============================] - 0s - loss: 81.8979 - val_loss: 113.7544\n",
      "Epoch 175/10000\n",
      "1126/1126 [==============================] - 0s - loss: 81.6220 - val_loss: 113.2355\n",
      "Epoch 176/10000\n",
      "1126/1126 [==============================] - 0s - loss: 81.3530 - val_loss: 112.7273\n",
      "Epoch 177/10000\n",
      "1126/1126 [==============================] - 0s - loss: 81.0799 - val_loss: 112.2152\n",
      "Epoch 178/10000\n",
      "1126/1126 [==============================] - 0s - loss: 80.8139 - val_loss: 111.7141\n",
      "Epoch 179/10000\n",
      "1126/1126 [==============================] - 0s - loss: 80.5527 - val_loss: 111.2214\n",
      "Epoch 180/10000\n",
      "1126/1126 [==============================] - 0s - loss: 80.2908 - val_loss: 110.7405\n",
      "Epoch 181/10000\n",
      "1126/1126 [==============================] - 0s - loss: 80.0343 - val_loss: 110.2644\n",
      "Epoch 182/10000\n",
      "1126/1126 [==============================] - 0s - loss: 79.7812 - val_loss: 109.8003\n",
      "Epoch 183/10000\n",
      "1126/1126 [==============================] - 0s - loss: 79.5302 - val_loss: 109.3417\n",
      "Epoch 184/10000\n",
      "1126/1126 [==============================] - 0s - loss: 79.2760 - val_loss: 108.8900\n",
      "Epoch 185/10000\n",
      "1126/1126 [==============================] - 0s - loss: 79.0274 - val_loss: 108.4500\n",
      "Epoch 186/10000\n",
      "1126/1126 [==============================] - 0s - loss: 78.7786 - val_loss: 108.0087\n",
      "Epoch 187/10000\n",
      "1126/1126 [==============================] - 0s - loss: 78.5314 - val_loss: 107.5708\n",
      "Epoch 188/10000\n",
      "1126/1126 [==============================] - 0s - loss: 78.2820 - val_loss: 107.1322\n",
      "Epoch 189/10000\n",
      "1126/1126 [==============================] - 0s - loss: 78.0386 - val_loss: 106.7071\n",
      "Epoch 190/10000\n",
      "1126/1126 [==============================] - 0s - loss: 77.7993 - val_loss: 106.2914\n",
      "Epoch 191/10000\n",
      "1126/1126 [==============================] - 0s - loss: 77.5608 - val_loss: 105.8769\n",
      "Epoch 192/10000\n",
      "1126/1126 [==============================] - 0s - loss: 77.3260 - val_loss: 105.4662\n",
      "Epoch 193/10000\n",
      "1126/1126 [==============================] - 0s - loss: 77.0927 - val_loss: 105.0661\n",
      "Epoch 194/10000\n",
      "1126/1126 [==============================] - 0s - loss: 76.8574 - val_loss: 104.6631\n",
      "Epoch 195/10000\n",
      "1126/1126 [==============================] - 0s - loss: 76.6276 - val_loss: 104.2685\n",
      "Epoch 196/10000\n",
      "1126/1126 [==============================] - 0s - loss: 76.4003 - val_loss: 103.8837\n",
      "Epoch 197/10000\n",
      "1126/1126 [==============================] - 0s - loss: 76.1726 - val_loss: 103.4961\n",
      "Epoch 198/10000\n",
      "1126/1126 [==============================] - 0s - loss: 75.9501 - val_loss: 103.1197\n",
      "Epoch 199/10000\n",
      "1126/1126 [==============================] - 0s - loss: 75.7297 - val_loss: 102.7495\n",
      "Epoch 200/10000\n",
      "1126/1126 [==============================] - 0s - loss: 75.5104 - val_loss: 102.3871\n",
      "Epoch 201/10000\n",
      "1126/1126 [==============================] - 0s - loss: 75.2908 - val_loss: 102.0356\n",
      "Epoch 202/10000\n",
      "1126/1126 [==============================] - 0s - loss: 75.0761 - val_loss: 101.6896\n",
      "Epoch 203/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.8645 - val_loss: 101.3531\n",
      "Epoch 204/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.6535 - val_loss: 101.0239\n",
      "Epoch 205/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.4478 - val_loss: 100.6973\n",
      "Epoch 206/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.2389 - val_loss: 100.3765\n",
      "Epoch 207/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.0372 - val_loss: 100.0635\n",
      "Epoch 208/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.8344 - val_loss: 99.7506\n",
      "Epoch 209/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.6352 - val_loss: 99.4353\n",
      "Epoch 210/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.4374 - val_loss: 99.1263\n",
      "Epoch 211/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.2407 - val_loss: 98.8180\n",
      "Epoch 212/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.0470 - val_loss: 98.5190\n",
      "Epoch 213/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.8539 - val_loss: 98.2246\n",
      "Epoch 214/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.6622 - val_loss: 97.9370\n",
      "Epoch 215/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.4710 - val_loss: 97.6540\n",
      "Epoch 216/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.2849 - val_loss: 97.3819\n",
      "Epoch 217/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.0980 - val_loss: 97.1111\n",
      "Epoch 218/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.9127 - val_loss: 96.8479\n",
      "Epoch 219/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.7290 - val_loss: 96.5905\n",
      "Epoch 220/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.5486 - val_loss: 96.3350\n",
      "Epoch 221/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.3682 - val_loss: 96.0785\n",
      "Epoch 222/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.1882 - val_loss: 95.8297\n",
      "Epoch 223/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.0137 - val_loss: 95.5836\n",
      "Epoch 224/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.8361 - val_loss: 95.3327\n",
      "Epoch 225/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.6616 - val_loss: 95.0917\n",
      "Epoch 226/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.4870 - val_loss: 94.8476\n",
      "Epoch 227/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.3148 - val_loss: 94.6089\n",
      "Epoch 228/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.1425 - val_loss: 94.3747\n",
      "Epoch 229/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.9733 - val_loss: 94.1453\n",
      "Epoch 230/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.8037 - val_loss: 93.9126\n",
      "Epoch 231/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.6356 - val_loss: 93.6877\n",
      "Epoch 232/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.4712 - val_loss: 93.4659\n",
      "Epoch 233/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.3031 - val_loss: 93.2505\n",
      "Epoch 234/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.1399 - val_loss: 93.0453\n",
      "Epoch 235/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.9756 - val_loss: 92.8354\n",
      "Epoch 236/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.8142 - val_loss: 92.6291\n",
      "Epoch 237/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.6531 - val_loss: 92.4238\n",
      "Epoch 238/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.4935 - val_loss: 92.2245\n",
      "Epoch 239/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.3367 - val_loss: 92.0275\n",
      "Epoch 240/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.1782 - val_loss: 91.8303\n",
      "Epoch 241/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.0216 - val_loss: 91.6361\n",
      "Epoch 242/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 67.8650 - val_loss: 91.4505\n",
      "Epoch 243/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.7120 - val_loss: 91.2670\n",
      "Epoch 244/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.5564 - val_loss: 91.0859\n",
      "Epoch 245/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.4043 - val_loss: 90.9076\n",
      "Epoch 246/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.2518 - val_loss: 90.7305\n",
      "Epoch 247/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.0998 - val_loss: 90.5524\n",
      "Epoch 248/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.9536 - val_loss: 90.3735\n",
      "Epoch 249/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.8019 - val_loss: 90.2033\n",
      "Epoch 250/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.6525 - val_loss: 90.0349\n",
      "Epoch 251/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.5089 - val_loss: 89.8704\n",
      "Epoch 252/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.3605 - val_loss: 89.7079\n",
      "Epoch 253/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.2151 - val_loss: 89.5449\n",
      "Epoch 254/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.0715 - val_loss: 89.3820\n",
      "Epoch 255/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.9290 - val_loss: 89.2299\n",
      "Epoch 256/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.7856 - val_loss: 89.0691\n",
      "Epoch 257/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.6462 - val_loss: 88.9220\n",
      "Epoch 258/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.5044 - val_loss: 88.7733\n",
      "Epoch 259/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.3627 - val_loss: 88.6293\n",
      "Epoch 260/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.2239 - val_loss: 88.4841\n",
      "Epoch 261/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.0843 - val_loss: 88.3426\n",
      "Epoch 262/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.9454 - val_loss: 88.1977\n",
      "Epoch 263/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.8113 - val_loss: 88.0586\n",
      "Epoch 264/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.6740 - val_loss: 87.9114\n",
      "Epoch 265/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.5387 - val_loss: 87.7767\n",
      "Epoch 266/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.4019 - val_loss: 87.6359\n",
      "Epoch 267/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.2718 - val_loss: 87.5048\n",
      "Epoch 268/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.1399 - val_loss: 87.3778\n",
      "Epoch 269/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.0084 - val_loss: 87.2531\n",
      "Epoch 270/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.8779 - val_loss: 87.1275\n",
      "Epoch 271/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.7483 - val_loss: 87.0059\n",
      "Epoch 272/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.6188 - val_loss: 86.8758\n",
      "Epoch 273/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.4905 - val_loss: 86.7497\n",
      "Epoch 274/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.3647 - val_loss: 86.6246\n",
      "Epoch 275/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.2378 - val_loss: 86.5048\n",
      "Epoch 276/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.1110 - val_loss: 86.3790\n",
      "Epoch 277/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.9857 - val_loss: 86.2544\n",
      "Epoch 278/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.8606 - val_loss: 86.1317\n",
      "Epoch 279/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.7378 - val_loss: 86.0102\n",
      "Epoch 280/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.6141 - val_loss: 85.8992\n",
      "Epoch 281/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.4938 - val_loss: 85.7870\n",
      "Epoch 282/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.3714 - val_loss: 85.6702\n",
      "Epoch 283/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.2552 - val_loss: 85.5542\n",
      "Epoch 284/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.1350 - val_loss: 85.4401\n",
      "Epoch 285/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.0170 - val_loss: 85.3298\n",
      "Epoch 286/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.9000 - val_loss: 85.2221\n",
      "Epoch 287/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.7831 - val_loss: 85.1027\n",
      "Epoch 288/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.6673 - val_loss: 84.9835\n",
      "Epoch 289/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.5532 - val_loss: 84.8665\n",
      "Epoch 290/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.4375 - val_loss: 84.7538\n",
      "Epoch 291/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.3234 - val_loss: 84.6394\n",
      "Epoch 292/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.2095 - val_loss: 84.5235\n",
      "Epoch 293/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.0954 - val_loss: 84.4146\n",
      "Epoch 294/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.9834 - val_loss: 84.3056\n",
      "Epoch 295/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.8710 - val_loss: 84.1969\n",
      "Epoch 296/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.7607 - val_loss: 84.0989\n",
      "Epoch 297/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.6505 - val_loss: 84.0027\n",
      "Epoch 298/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.5428 - val_loss: 83.9043\n",
      "Epoch 299/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.4352 - val_loss: 83.8206\n",
      "Epoch 300/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.3280 - val_loss: 83.7217\n",
      "Epoch 301/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.2205 - val_loss: 83.6201\n",
      "Epoch 302/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.1132 - val_loss: 83.5197\n",
      "Epoch 303/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.0063 - val_loss: 83.4190\n",
      "Epoch 304/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.9020 - val_loss: 83.3185\n",
      "Epoch 305/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.7961 - val_loss: 83.2257\n",
      "Epoch 306/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.6942 - val_loss: 83.1338\n",
      "Epoch 307/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.5903 - val_loss: 83.0375\n",
      "Epoch 308/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.4875 - val_loss: 82.9455\n",
      "Epoch 309/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.3882 - val_loss: 82.8571\n",
      "Epoch 310/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.2858 - val_loss: 82.7641\n",
      "Epoch 311/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.1874 - val_loss: 82.6771\n",
      "Epoch 312/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.0859 - val_loss: 82.5925\n",
      "Epoch 313/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.9905 - val_loss: 82.5039\n",
      "Epoch 314/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.8899 - val_loss: 82.4194\n",
      "Epoch 315/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.7932 - val_loss: 82.3320\n",
      "Epoch 316/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.6959 - val_loss: 82.2480\n",
      "Epoch 317/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.6016 - val_loss: 82.1677\n",
      "Epoch 318/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.5055 - val_loss: 82.0899\n",
      "Epoch 319/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.4117 - val_loss: 82.0040\n",
      "Epoch 320/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.3160 - val_loss: 81.9206\n",
      "Epoch 321/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.2236 - val_loss: 81.8417\n",
      "Epoch 322/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.1304 - val_loss: 81.7606\n",
      "Epoch 323/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.0375 - val_loss: 81.6822\n",
      "Epoch 324/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 57.9466 - val_loss: 81.6060\n",
      "Epoch 325/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.8551 - val_loss: 81.5363\n",
      "Epoch 326/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.7683 - val_loss: 81.4617\n",
      "Epoch 327/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.6736 - val_loss: 81.4051\n",
      "Epoch 328/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.5891 - val_loss: 81.3056\n",
      "Epoch 329/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.4980 - val_loss: 81.2707\n",
      "Epoch 330/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.4120 - val_loss: 81.1690\n",
      "Epoch 331/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.3207 - val_loss: 81.1279\n",
      "Epoch 332/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.2377 - val_loss: 81.0313\n",
      "Epoch 333/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.1491 - val_loss: 80.9925\n",
      "Epoch 334/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.0666 - val_loss: 80.8990\n",
      "Epoch 335/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.9779 - val_loss: 80.8657\n",
      "Epoch 336/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.8975 - val_loss: 80.7798\n",
      "Epoch 337/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.8108 - val_loss: 80.7368\n",
      "Epoch 338/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.7299 - val_loss: 80.6462\n",
      "Epoch 339/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.6457 - val_loss: 80.6074\n",
      "Epoch 340/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.5651 - val_loss: 80.5250\n",
      "Epoch 341/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.4814 - val_loss: 80.4928\n",
      "Epoch 342/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.4033 - val_loss: 80.4165\n",
      "Epoch 343/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.3200 - val_loss: 80.3761\n",
      "Epoch 344/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.2398 - val_loss: 80.2990\n",
      "Epoch 345/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.1604 - val_loss: 80.2536\n",
      "Epoch 346/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.0817 - val_loss: 80.2140\n",
      "Epoch 347/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.0015 - val_loss: 80.1390\n",
      "Epoch 348/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.9193 - val_loss: 80.0848\n",
      "Epoch 349/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.8452 - val_loss: 80.0508\n",
      "Epoch 350/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.7673 - val_loss: 79.9819\n",
      "Epoch 351/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.6917 - val_loss: 79.9255\n",
      "Epoch 352/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.6146 - val_loss: 79.8809\n",
      "Epoch 353/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.5385 - val_loss: 79.8128\n",
      "Epoch 354/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.4645 - val_loss: 79.7619\n",
      "Epoch 355/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.3900 - val_loss: 79.7105\n",
      "Epoch 356/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.3159 - val_loss: 79.6746\n",
      "Epoch 357/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.2422 - val_loss: 79.6058\n",
      "Epoch 358/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.1701 - val_loss: 79.5582\n",
      "Epoch 359/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.0933 - val_loss: 79.5068\n",
      "Epoch 360/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.0241 - val_loss: 79.4618\n",
      "Epoch 361/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.9505 - val_loss: 79.4357\n",
      "Epoch 362/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.8800 - val_loss: 79.3695\n",
      "Epoch 363/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.8115 - val_loss: 79.3334\n",
      "Epoch 364/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.7380 - val_loss: 79.2902\n",
      "Epoch 365/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.6700 - val_loss: 79.2613\n",
      "Epoch 366/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.6003 - val_loss: 79.2314\n",
      "Epoch 367/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.5360 - val_loss: 79.1996\n",
      "Epoch 368/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.4674 - val_loss: 79.1715\n",
      "Epoch 369/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.4008 - val_loss: 79.1400\n",
      "Epoch 370/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.3332 - val_loss: 79.1139\n",
      "Epoch 371/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.2678 - val_loss: 79.0830\n",
      "Epoch 372/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.2029 - val_loss: 79.0540\n",
      "Epoch 373/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.1373 - val_loss: 79.0220\n",
      "Epoch 374/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.0746 - val_loss: 78.9984\n",
      "Epoch 375/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.0100 - val_loss: 78.9713\n",
      "Epoch 376/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.9458 - val_loss: 78.9462\n",
      "Epoch 377/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.8846 - val_loss: 78.9240\n",
      "Epoch 378/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.8203 - val_loss: 78.8986\n",
      "Epoch 379/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.7581 - val_loss: 78.8744\n",
      "Epoch 380/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.6949 - val_loss: 78.8416\n",
      "Epoch 381/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.6329 - val_loss: 78.8238\n",
      "Epoch 382/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.5705 - val_loss: 78.7895\n",
      "Epoch 383/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.5097 - val_loss: 78.7792\n",
      "Epoch 384/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.4486 - val_loss: 78.7714\n",
      "Epoch 385/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.3904 - val_loss: 78.7454\n",
      "Epoch 386/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.3296 - val_loss: 78.7335\n",
      "Epoch 387/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.2713 - val_loss: 78.7044\n",
      "Epoch 388/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.2091 - val_loss: 78.7136\n",
      "Epoch 389/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.1545 - val_loss: 78.6943\n",
      "Epoch 390/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.0936 - val_loss: 78.6869\n",
      "Epoch 391/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.0358 - val_loss: 78.6806\n",
      "Epoch 392/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.9765 - val_loss: 78.6742\n",
      "Epoch 393/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.9207 - val_loss: 78.6727\n",
      "Epoch 394/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.8652 - val_loss: 78.6595\n",
      "Epoch 395/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.8055 - val_loss: 78.6533\n",
      "Epoch 396/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.7537 - val_loss: 78.6556\n",
      "Epoch 397/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.6967 - val_loss: 78.6470\n",
      "Epoch 398/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.6393 - val_loss: 78.6404\n",
      "Epoch 399/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.5872 - val_loss: 78.6374\n",
      "Epoch 400/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.5319 - val_loss: 78.6368\n",
      "Epoch 401/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.4796 - val_loss: 78.6194\n",
      "Epoch 402/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.4225 - val_loss: 78.6038\n",
      "Epoch 403/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.3731 - val_loss: 78.5907\n",
      "Epoch 404/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.3175 - val_loss: 78.5822\n",
      "Epoch 405/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.2643 - val_loss: 78.5686\n",
      "Epoch 406/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 52.2102 - val_loss: 78.5570\n",
      "Epoch 407/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.1594 - val_loss: 78.5530\n",
      "Epoch 408/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.1079 - val_loss: 78.5345\n",
      "Epoch 409/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.0540 - val_loss: 78.5171\n",
      "Epoch 410/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.0019 - val_loss: 78.5121\n",
      "Epoch 411/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.9513 - val_loss: 78.4961\n",
      "Epoch 412/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.8992 - val_loss: 78.4866\n",
      "Epoch 413/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.8481 - val_loss: 78.4801\n",
      "Epoch 414/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.7991 - val_loss: 78.4691\n",
      "Epoch 415/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.7449 - val_loss: 78.4606\n",
      "Epoch 416/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.6989 - val_loss: 78.4417\n",
      "Epoch 417/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.6446 - val_loss: 78.4408\n",
      "Epoch 418/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.5977 - val_loss: 78.4392\n",
      "Epoch 419/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.5456 - val_loss: 78.4308\n",
      "Epoch 420/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.4990 - val_loss: 78.4258\n",
      "Epoch 421/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.4473 - val_loss: 78.4234\n",
      "Epoch 422/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.4008 - val_loss: 78.4136\n",
      "Epoch 423/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.3503 - val_loss: 78.4167\n",
      "Epoch 424/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.3020 - val_loss: 78.3995\n",
      "Epoch 425/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.2535 - val_loss: 78.3972\n",
      "Epoch 426/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.2072 - val_loss: 78.3806\n",
      "Epoch 427/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.1576 - val_loss: 78.3742\n",
      "Epoch 428/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.1126 - val_loss: 78.3714\n",
      "Epoch 429/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.0648 - val_loss: 78.3662\n",
      "Epoch 430/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.0191 - val_loss: 78.3615\n",
      "Epoch 431/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.9714 - val_loss: 78.3467\n",
      "Epoch 432/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.9253 - val_loss: 78.3468\n",
      "Epoch 433/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.8793 - val_loss: 78.3251\n",
      "Epoch 434/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.8335 - val_loss: 78.3276\n",
      "Epoch 435/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.7885 - val_loss: 78.3265\n",
      "Epoch 436/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.7437 - val_loss: 78.3250\n",
      "Epoch 437/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.6986 - val_loss: 78.3236\n",
      "Epoch 438/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.6549 - val_loss: 78.3282\n",
      "Epoch 439/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.6089 - val_loss: 78.3246\n",
      "Epoch 440/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.5651 - val_loss: 78.3302\n",
      "Epoch 441/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.5187 - val_loss: 78.3281\n",
      "Epoch 442/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.4738 - val_loss: 78.3201\n",
      "Epoch 443/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.4272 - val_loss: 78.3197\n",
      "Epoch 444/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.3828 - val_loss: 78.3269\n",
      "Epoch 445/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.3362 - val_loss: 78.3276\n",
      "Epoch 446/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.2902 - val_loss: 78.3319\n",
      "Epoch 447/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.2440 - val_loss: 78.3412\n",
      "Epoch 448/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.1993 - val_loss: 78.3547\n",
      "Epoch 449/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.1543 - val_loss: 78.3484\n",
      "Epoch 450/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.1094 - val_loss: 78.3630\n",
      "Epoch 451/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.0664 - val_loss: 78.3706\n",
      "Epoch 452/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.0232 - val_loss: 78.3824\n",
      "Epoch 453/10000\n",
      "1126/1126 [==============================] - 0s - loss: 49.9817 - val_loss: 78.3909\n",
      "Epoch 454/10000\n",
      "1126/1126 [==============================] - 0s - loss: 49.9367 - val_loss: 78.4030\n",
      "Epoch 00453: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto', patience=10)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10000, validation_data=(X_valid, y_valid), callbacks=[early_stopping], verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1185a9a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1185a0a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "plt.title('Cot et cot de validation')\n",
    "line1,=plt.plot(history.history['loss'], label=\"Loss\", linestyle='-', color='r')\n",
    "line2,=plt.plot(history.history['val_loss'], label=\"Val loss\", linestyle='-', color='b')\n",
    "first_legend = plt.legend(handles=[line1, line2], loc=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.title('y_pred en fonction de y_test')\n",
    "\n",
    "plt.plot(y_pred[:], y_test[:], '+')\n",
    "plt.ylabel('Test')\n",
    "plt.xlabel('Prdiction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 32)                3936      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,969\n",
      "Trainable params: 3,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = gru_model(32, X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1126 samples, validate on 563 samples\n",
      "Epoch 1/10000\n",
      "1126/1126 [==============================] - 1s - loss: 3346.6046 - val_loss: 3005.5630\n",
      "Epoch 2/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3333.4573 - val_loss: 2992.2437\n",
      "Epoch 3/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3315.0757 - val_loss: 2972.0245\n",
      "Epoch 4/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3286.3358 - val_loss: 2940.6584\n",
      "Epoch 5/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3242.2003 - val_loss: 2893.5140\n",
      "Epoch 6/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3176.8351 - val_loss: 2825.5253\n",
      "Epoch 7/10000\n",
      "1126/1126 [==============================] - 0s - loss: 3085.3462 - val_loss: 2734.1705\n",
      "Epoch 8/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2966.1781 - val_loss: 2619.2635\n",
      "Epoch 9/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2820.3063 - val_loss: 2481.5536\n",
      "Epoch 10/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2647.8654 - val_loss: 2322.7315\n",
      "Epoch 11/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2454.3155 - val_loss: 2150.1841\n",
      "Epoch 12/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2247.7992 - val_loss: 1972.2243\n",
      "Epoch 13/10000\n",
      "1126/1126 [==============================] - 0s - loss: 2038.1709 - val_loss: 1795.0079\n",
      "Epoch 14/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1832.5553 - val_loss: 1623.0928\n",
      "Epoch 15/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1635.9918 - val_loss: 1460.7622\n",
      "Epoch 16/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1451.7774 - val_loss: 1309.4997\n",
      "Epoch 17/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1282.0786 - val_loss: 1170.9232\n",
      "Epoch 18/10000\n",
      "1126/1126 [==============================] - 0s - loss: 1128.4837 - val_loss: 1046.3294\n",
      "Epoch 19/10000\n",
      "1126/1126 [==============================] - 0s - loss: 991.9803 - val_loss: 936.3784\n",
      "Epoch 20/10000\n",
      "1126/1126 [==============================] - 0s - loss: 873.0124 - val_loss: 841.3271\n",
      "Epoch 21/10000\n",
      "1126/1126 [==============================] - 0s - loss: 771.2118 - val_loss: 760.6505\n",
      "Epoch 22/10000\n",
      "1126/1126 [==============================] - 0s - loss: 685.5581 - val_loss: 693.0452\n",
      "Epoch 23/10000\n",
      "1126/1126 [==============================] - 0s - loss: 614.6685 - val_loss: 637.0708\n",
      "Epoch 24/10000\n",
      "1126/1126 [==============================] - 0s - loss: 556.8707 - val_loss: 591.1732\n",
      "Epoch 25/10000\n",
      "1126/1126 [==============================] - 0s - loss: 510.2582 - val_loss: 553.6721\n",
      "Epoch 26/10000\n",
      "1126/1126 [==============================] - 0s - loss: 472.8318 - val_loss: 523.0165\n",
      "Epoch 27/10000\n",
      "1126/1126 [==============================] - 0s - loss: 442.7275 - val_loss: 497.7174\n",
      "Epoch 28/10000\n",
      "1126/1126 [==============================] - 0s - loss: 418.2870 - val_loss: 476.5301\n",
      "Epoch 29/10000\n",
      "1126/1126 [==============================] - 0s - loss: 398.0996 - val_loss: 458.5041\n",
      "Epoch 30/10000\n",
      "1126/1126 [==============================] - 0s - loss: 381.0488 - val_loss: 442.8225\n",
      "Epoch 31/10000\n",
      "1126/1126 [==============================] - 0s - loss: 366.2677 - val_loss: 428.9378\n",
      "Epoch 32/10000\n",
      "1126/1126 [==============================] - 0s - loss: 353.1266 - val_loss: 416.4401\n",
      "Epoch 33/10000\n",
      "1126/1126 [==============================] - 0s - loss: 341.2132 - val_loss: 405.0123\n",
      "Epoch 34/10000\n",
      "1126/1126 [==============================] - 0s - loss: 330.1903 - val_loss: 394.4341\n",
      "Epoch 35/10000\n",
      "1126/1126 [==============================] - 0s - loss: 319.8646 - val_loss: 384.5660\n",
      "Epoch 36/10000\n",
      "1126/1126 [==============================] - 0s - loss: 310.1257 - val_loss: 375.2680\n",
      "Epoch 37/10000\n",
      "1126/1126 [==============================] - 0s - loss: 300.8744 - val_loss: 366.5243\n",
      "Epoch 38/10000\n",
      "1126/1126 [==============================] - 0s - loss: 292.0719 - val_loss: 358.2403\n",
      "Epoch 39/10000\n",
      "1126/1126 [==============================] - 0s - loss: 283.6831 - val_loss: 350.4021\n",
      "Epoch 40/10000\n",
      "1126/1126 [==============================] - 0s - loss: 275.6352 - val_loss: 342.9568\n",
      "Epoch 41/10000\n",
      "1126/1126 [==============================] - 0s - loss: 267.9052 - val_loss: 335.8777\n",
      "Epoch 42/10000\n",
      "1126/1126 [==============================] - 0s - loss: 260.4771 - val_loss: 329.1405\n",
      "Epoch 43/10000\n",
      "1126/1126 [==============================] - 0s - loss: 253.3351 - val_loss: 322.7323\n",
      "Epoch 44/10000\n",
      "1126/1126 [==============================] - 0s - loss: 246.4772 - val_loss: 316.6342\n",
      "Epoch 45/10000\n",
      "1126/1126 [==============================] - 0s - loss: 239.9203 - val_loss: 310.8138\n",
      "Epoch 46/10000\n",
      "1126/1126 [==============================] - 0s - loss: 233.6497 - val_loss: 305.2699\n",
      "Epoch 47/10000\n",
      "1126/1126 [==============================] - 0s - loss: 227.6382 - val_loss: 299.9587\n",
      "Epoch 48/10000\n",
      "1126/1126 [==============================] - 0s - loss: 221.8567 - val_loss: 294.8654\n",
      "Epoch 49/10000\n",
      "1126/1126 [==============================] - 0s - loss: 216.3152 - val_loss: 290.0141\n",
      "Epoch 50/10000\n",
      "1126/1126 [==============================] - 0s - loss: 211.0107 - val_loss: 285.3877\n",
      "Epoch 51/10000\n",
      "1126/1126 [==============================] - 0s - loss: 205.9389 - val_loss: 280.9507\n",
      "Epoch 52/10000\n",
      "1126/1126 [==============================] - 0s - loss: 201.0868 - val_loss: 276.6937\n",
      "Epoch 53/10000\n",
      "1126/1126 [==============================] - 0s - loss: 196.4558 - val_loss: 272.6056\n",
      "Epoch 54/10000\n",
      "1126/1126 [==============================] - 0s - loss: 192.0336 - val_loss: 268.6920\n",
      "Epoch 55/10000\n",
      "1126/1126 [==============================] - 0s - loss: 187.8186 - val_loss: 264.9466\n",
      "Epoch 56/10000\n",
      "1126/1126 [==============================] - 0s - loss: 183.8117 - val_loss: 261.3589\n",
      "Epoch 57/10000\n",
      "1126/1126 [==============================] - 0s - loss: 179.9944 - val_loss: 257.9191\n",
      "Epoch 58/10000\n",
      "1126/1126 [==============================] - 0s - loss: 176.3548 - val_loss: 254.6208\n",
      "Epoch 59/10000\n",
      "1126/1126 [==============================] - 0s - loss: 172.9037 - val_loss: 251.4664\n",
      "Epoch 60/10000\n",
      "1126/1126 [==============================] - 0s - loss: 169.5990 - val_loss: 248.4404\n",
      "Epoch 61/10000\n",
      "1126/1126 [==============================] - 0s - loss: 166.4463 - val_loss: 245.5109\n",
      "Epoch 62/10000\n",
      "1126/1126 [==============================] - 0s - loss: 163.4482 - val_loss: 242.6588\n",
      "Epoch 63/10000\n",
      "1126/1126 [==============================] - 0s - loss: 160.5879 - val_loss: 239.8896\n",
      "Epoch 64/10000\n",
      "1126/1126 [==============================] - 0s - loss: 157.8553 - val_loss: 237.1946\n",
      "Epoch 65/10000\n",
      "1126/1126 [==============================] - 0s - loss: 155.2542 - val_loss: 234.5765\n",
      "Epoch 66/10000\n",
      "1126/1126 [==============================] - 0s - loss: 152.7776 - val_loss: 232.0192\n",
      "Epoch 67/10000\n",
      "1126/1126 [==============================] - 0s - loss: 150.4253 - val_loss: 229.5214\n",
      "Epoch 68/10000\n",
      "1126/1126 [==============================] - 0s - loss: 148.1864 - val_loss: 227.0717\n",
      "Epoch 69/10000\n",
      "1126/1126 [==============================] - 0s - loss: 146.0577 - val_loss: 224.6687\n",
      "Epoch 70/10000\n",
      "1126/1126 [==============================] - 0s - loss: 144.0418 - val_loss: 222.2866\n",
      "Epoch 71/10000\n",
      "1126/1126 [==============================] - 0s - loss: 142.1350 - val_loss: 219.9373\n",
      "Epoch 72/10000\n",
      "1126/1126 [==============================] - 0s - loss: 140.3223 - val_loss: 217.6211\n",
      "Epoch 73/10000\n",
      "1126/1126 [==============================] - 0s - loss: 138.6002 - val_loss: 215.3560\n",
      "Epoch 74/10000\n",
      "1126/1126 [==============================] - 0s - loss: 136.9616 - val_loss: 213.1328\n",
      "Epoch 75/10000\n",
      "1126/1126 [==============================] - 0s - loss: 135.3967 - val_loss: 210.9462\n",
      "Epoch 76/10000\n",
      "1126/1126 [==============================] - 0s - loss: 133.9013 - val_loss: 208.7960\n",
      "Epoch 77/10000\n",
      "1126/1126 [==============================] - 0s - loss: 132.4726 - val_loss: 206.6855\n",
      "Epoch 78/10000\n",
      "1126/1126 [==============================] - 0s - loss: 131.1086 - val_loss: 204.6110\n",
      "Epoch 79/10000\n",
      "1126/1126 [==============================] - 0s - loss: 129.8034 - val_loss: 202.5626\n",
      "Epoch 80/10000\n",
      "1126/1126 [==============================] - 0s - loss: 128.5569 - val_loss: 200.5489\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 127.3661 - val_loss: 198.5776\n",
      "Epoch 82/10000\n",
      "1126/1126 [==============================] - 0s - loss: 126.2255 - val_loss: 196.6425\n",
      "Epoch 83/10000\n",
      "1126/1126 [==============================] - 0s - loss: 125.1315 - val_loss: 194.7311\n",
      "Epoch 84/10000\n",
      "1126/1126 [==============================] - 0s - loss: 124.0790 - val_loss: 192.8481\n",
      "Epoch 85/10000\n",
      "1126/1126 [==============================] - 0s - loss: 123.0663 - val_loss: 190.9969\n",
      "Epoch 86/10000\n",
      "1126/1126 [==============================] - 0s - loss: 122.0975 - val_loss: 189.1722\n",
      "Epoch 87/10000\n",
      "1126/1126 [==============================] - 0s - loss: 121.1692 - val_loss: 187.3798\n",
      "Epoch 88/10000\n",
      "1126/1126 [==============================] - 0s - loss: 120.2793 - val_loss: 185.6113\n",
      "Epoch 89/10000\n",
      "1126/1126 [==============================] - 0s - loss: 119.4233 - val_loss: 183.8726\n",
      "Epoch 90/10000\n",
      "1126/1126 [==============================] - 0s - loss: 118.6006 - val_loss: 182.1623\n",
      "Epoch 91/10000\n",
      "1126/1126 [==============================] - 0s - loss: 117.8074 - val_loss: 180.4832\n",
      "Epoch 92/10000\n",
      "1126/1126 [==============================] - 0s - loss: 117.0405 - val_loss: 178.8259\n",
      "Epoch 93/10000\n",
      "1126/1126 [==============================] - 0s - loss: 116.2952 - val_loss: 177.1967\n",
      "Epoch 94/10000\n",
      "1126/1126 [==============================] - 0s - loss: 115.5718 - val_loss: 175.5922\n",
      "Epoch 95/10000\n",
      "1126/1126 [==============================] - 0s - loss: 114.8679 - val_loss: 174.0122\n",
      "Epoch 96/10000\n",
      "1126/1126 [==============================] - 0s - loss: 114.1828 - val_loss: 172.4597\n",
      "Epoch 97/10000\n",
      "1126/1126 [==============================] - 0s - loss: 113.5134 - val_loss: 170.9302\n",
      "Epoch 98/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.8625 - val_loss: 169.4357\n",
      "Epoch 99/10000\n",
      "1126/1126 [==============================] - 0s - loss: 112.2256 - val_loss: 167.9725\n",
      "Epoch 100/10000\n",
      "1126/1126 [==============================] - 0s - loss: 111.6015 - val_loss: 166.5271\n",
      "Epoch 101/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.9896 - val_loss: 165.1043\n",
      "Epoch 102/10000\n",
      "1126/1126 [==============================] - 0s - loss: 110.3879 - val_loss: 163.6997\n",
      "Epoch 103/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.8037 - val_loss: 162.3087\n",
      "Epoch 104/10000\n",
      "1126/1126 [==============================] - 0s - loss: 109.2360 - val_loss: 160.9450\n",
      "Epoch 105/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.6864 - val_loss: 159.6069\n",
      "Epoch 106/10000\n",
      "1126/1126 [==============================] - 0s - loss: 108.1541 - val_loss: 158.3133\n",
      "Epoch 107/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.6355 - val_loss: 157.0352\n",
      "Epoch 108/10000\n",
      "1126/1126 [==============================] - 0s - loss: 107.1332 - val_loss: 155.7988\n",
      "Epoch 109/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.6400 - val_loss: 154.5980\n",
      "Epoch 110/10000\n",
      "1126/1126 [==============================] - 0s - loss: 106.1554 - val_loss: 153.4210\n",
      "Epoch 111/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.6809 - val_loss: 152.2689\n",
      "Epoch 112/10000\n",
      "1126/1126 [==============================] - 0s - loss: 105.2132 - val_loss: 151.1271\n",
      "Epoch 113/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.7514 - val_loss: 150.0140\n",
      "Epoch 114/10000\n",
      "1126/1126 [==============================] - 0s - loss: 104.2979 - val_loss: 148.9270\n",
      "Epoch 115/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.8501 - val_loss: 147.8624\n",
      "Epoch 116/10000\n",
      "1126/1126 [==============================] - 0s - loss: 103.4104 - val_loss: 146.8258\n",
      "Epoch 117/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.9783 - val_loss: 145.8162\n",
      "Epoch 118/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.5538 - val_loss: 144.8287\n",
      "Epoch 119/10000\n",
      "1126/1126 [==============================] - 0s - loss: 102.1328 - val_loss: 143.8501\n",
      "Epoch 120/10000\n",
      "1126/1126 [==============================] - 0s - loss: 101.7168 - val_loss: 142.8911\n",
      "Epoch 121/10000\n",
      "1126/1126 [==============================] - 0s - loss: 101.3049 - val_loss: 141.9544\n",
      "Epoch 122/10000\n",
      "1126/1126 [==============================] - 0s - loss: 100.9009 - val_loss: 141.0380\n",
      "Epoch 123/10000\n",
      "1126/1126 [==============================] - 0s - loss: 100.5000 - val_loss: 140.1438\n",
      "Epoch 124/10000\n",
      "1126/1126 [==============================] - 0s - loss: 100.1052 - val_loss: 139.2713\n",
      "Epoch 125/10000\n",
      "1126/1126 [==============================] - 0s - loss: 99.7137 - val_loss: 138.4141\n",
      "Epoch 126/10000\n",
      "1126/1126 [==============================] - 0s - loss: 99.3255 - val_loss: 137.5752\n",
      "Epoch 127/10000\n",
      "1126/1126 [==============================] - 0s - loss: 98.9425 - val_loss: 136.7532\n",
      "Epoch 128/10000\n",
      "1126/1126 [==============================] - 0s - loss: 98.5647 - val_loss: 135.9436\n",
      "Epoch 129/10000\n",
      "1126/1126 [==============================] - 0s - loss: 98.1894 - val_loss: 135.1496\n",
      "Epoch 130/10000\n",
      "1126/1126 [==============================] - 0s - loss: 97.8140 - val_loss: 134.3775\n",
      "Epoch 131/10000\n",
      "1126/1126 [==============================] - 0s - loss: 97.4432 - val_loss: 133.6214\n",
      "Epoch 132/10000\n",
      "1126/1126 [==============================] - 0s - loss: 97.0740 - val_loss: 132.8779\n",
      "Epoch 133/10000\n",
      "1126/1126 [==============================] - 0s - loss: 96.7082 - val_loss: 132.1475\n",
      "Epoch 134/10000\n",
      "1126/1126 [==============================] - 0s - loss: 96.3475 - val_loss: 131.4322\n",
      "Epoch 135/10000\n",
      "1126/1126 [==============================] - 0s - loss: 95.9915 - val_loss: 130.7181\n",
      "Epoch 136/10000\n",
      "1126/1126 [==============================] - 0s - loss: 95.6392 - val_loss: 130.0288\n",
      "Epoch 137/10000\n",
      "1126/1126 [==============================] - 0s - loss: 95.2883 - val_loss: 129.3562\n",
      "Epoch 138/10000\n",
      "1126/1126 [==============================] - 0s - loss: 94.9406 - val_loss: 128.6919\n",
      "Epoch 139/10000\n",
      "1126/1126 [==============================] - 0s - loss: 94.5964 - val_loss: 128.0504\n",
      "Epoch 140/10000\n",
      "1126/1126 [==============================] - 0s - loss: 94.2563 - val_loss: 127.4129\n",
      "Epoch 141/10000\n",
      "1126/1126 [==============================] - 0s - loss: 93.9205 - val_loss: 126.7796\n",
      "Epoch 142/10000\n",
      "1126/1126 [==============================] - 0s - loss: 93.5881 - val_loss: 126.1626\n",
      "Epoch 143/10000\n",
      "1126/1126 [==============================] - 0s - loss: 93.2550 - val_loss: 125.5451\n",
      "Epoch 144/10000\n",
      "1126/1126 [==============================] - 0s - loss: 92.9249 - val_loss: 124.9481\n",
      "Epoch 145/10000\n",
      "1126/1126 [==============================] - 0s - loss: 92.5970 - val_loss: 124.3453\n",
      "Epoch 146/10000\n",
      "1126/1126 [==============================] - 0s - loss: 92.2723 - val_loss: 123.7603\n",
      "Epoch 147/10000\n",
      "1126/1126 [==============================] - 0s - loss: 91.9532 - val_loss: 123.1927\n",
      "Epoch 148/10000\n",
      "1126/1126 [==============================] - 0s - loss: 91.6322 - val_loss: 122.6364\n",
      "Epoch 149/10000\n",
      "1126/1126 [==============================] - 0s - loss: 91.3168 - val_loss: 122.0712\n",
      "Epoch 150/10000\n",
      "1126/1126 [==============================] - 0s - loss: 91.0062 - val_loss: 121.5254\n",
      "Epoch 151/10000\n",
      "1126/1126 [==============================] - 0s - loss: 90.7007 - val_loss: 120.9850\n",
      "Epoch 152/10000\n",
      "1126/1126 [==============================] - 0s - loss: 90.3976 - val_loss: 120.4519\n",
      "Epoch 153/10000\n",
      "1126/1126 [==============================] - 0s - loss: 90.0998 - val_loss: 119.9528\n",
      "Epoch 154/10000\n",
      "1126/1126 [==============================] - 0s - loss: 89.8046 - val_loss: 119.4449\n",
      "Epoch 155/10000\n",
      "1126/1126 [==============================] - 0s - loss: 89.5125 - val_loss: 118.9511\n",
      "Epoch 156/10000\n",
      "1126/1126 [==============================] - 0s - loss: 89.2228 - val_loss: 118.4713\n",
      "Epoch 157/10000\n",
      "1126/1126 [==============================] - 0s - loss: 88.9377 - val_loss: 117.9947\n",
      "Epoch 158/10000\n",
      "1126/1126 [==============================] - 0s - loss: 88.6582 - val_loss: 117.5580\n",
      "Epoch 159/10000\n",
      "1126/1126 [==============================] - 0s - loss: 88.3811 - val_loss: 117.0978\n",
      "Epoch 160/10000\n",
      "1126/1126 [==============================] - 0s - loss: 88.1079 - val_loss: 116.6697\n",
      "Epoch 161/10000\n",
      "1126/1126 [==============================] - 0s - loss: 87.8361 - val_loss: 116.2331\n",
      "Epoch 162/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 87.5667 - val_loss: 115.8297\n",
      "Epoch 163/10000\n",
      "1126/1126 [==============================] - 0s - loss: 87.2998 - val_loss: 115.4136\n",
      "Epoch 164/10000\n",
      "1126/1126 [==============================] - 0s - loss: 87.0365 - val_loss: 115.0285\n",
      "Epoch 165/10000\n",
      "1126/1126 [==============================] - 0s - loss: 86.7756 - val_loss: 114.6319\n",
      "Epoch 166/10000\n",
      "1126/1126 [==============================] - 0s - loss: 86.5164 - val_loss: 114.2528\n",
      "Epoch 167/10000\n",
      "1126/1126 [==============================] - 0s - loss: 86.2585 - val_loss: 113.8953\n",
      "Epoch 168/10000\n",
      "1126/1126 [==============================] - 0s - loss: 86.0027 - val_loss: 113.5256\n",
      "Epoch 169/10000\n",
      "1126/1126 [==============================] - 0s - loss: 85.7494 - val_loss: 113.1653\n",
      "Epoch 170/10000\n",
      "1126/1126 [==============================] - 0s - loss: 85.4979 - val_loss: 112.8321\n",
      "Epoch 171/10000\n",
      "1126/1126 [==============================] - 0s - loss: 85.2481 - val_loss: 112.5218\n",
      "Epoch 172/10000\n",
      "1126/1126 [==============================] - 0s - loss: 84.9982 - val_loss: 112.2207\n",
      "Epoch 173/10000\n",
      "1126/1126 [==============================] - 0s - loss: 84.7518 - val_loss: 111.9168\n",
      "Epoch 174/10000\n",
      "1126/1126 [==============================] - 0s - loss: 84.5048 - val_loss: 111.6204\n",
      "Epoch 175/10000\n",
      "1126/1126 [==============================] - 0s - loss: 84.2614 - val_loss: 111.2983\n",
      "Epoch 176/10000\n",
      "1126/1126 [==============================] - 0s - loss: 84.0194 - val_loss: 110.9809\n",
      "Epoch 177/10000\n",
      "1126/1126 [==============================] - 0s - loss: 83.7780 - val_loss: 110.6668\n",
      "Epoch 178/10000\n",
      "1126/1126 [==============================] - 0s - loss: 83.5372 - val_loss: 110.3535\n",
      "Epoch 179/10000\n",
      "1126/1126 [==============================] - 0s - loss: 83.2969 - val_loss: 110.0451\n",
      "Epoch 180/10000\n",
      "1126/1126 [==============================] - 0s - loss: 83.0593 - val_loss: 109.7371\n",
      "Epoch 181/10000\n",
      "1126/1126 [==============================] - 0s - loss: 82.8235 - val_loss: 109.4549\n",
      "Epoch 182/10000\n",
      "1126/1126 [==============================] - 0s - loss: 82.5912 - val_loss: 109.1400\n",
      "Epoch 183/10000\n",
      "1126/1126 [==============================] - 0s - loss: 82.3620 - val_loss: 108.8471\n",
      "Epoch 184/10000\n",
      "1126/1126 [==============================] - 0s - loss: 82.1315 - val_loss: 108.5857\n",
      "Epoch 185/10000\n",
      "1126/1126 [==============================] - 0s - loss: 81.9032 - val_loss: 108.2919\n",
      "Epoch 186/10000\n",
      "1126/1126 [==============================] - 0s - loss: 81.6781 - val_loss: 108.0399\n",
      "Epoch 187/10000\n",
      "1126/1126 [==============================] - 0s - loss: 81.4523 - val_loss: 107.7574\n",
      "Epoch 188/10000\n",
      "1126/1126 [==============================] - 0s - loss: 81.2306 - val_loss: 107.5189\n",
      "Epoch 189/10000\n",
      "1126/1126 [==============================] - 0s - loss: 81.0083 - val_loss: 107.2424\n",
      "Epoch 190/10000\n",
      "1126/1126 [==============================] - 0s - loss: 80.7863 - val_loss: 106.9867\n",
      "Epoch 191/10000\n",
      "1126/1126 [==============================] - 0s - loss: 80.5662 - val_loss: 106.7530\n",
      "Epoch 192/10000\n",
      "1126/1126 [==============================] - 0s - loss: 80.3499 - val_loss: 106.4830\n",
      "Epoch 193/10000\n",
      "1126/1126 [==============================] - 0s - loss: 80.1344 - val_loss: 106.2188\n",
      "Epoch 194/10000\n",
      "1126/1126 [==============================] - 0s - loss: 79.9207 - val_loss: 105.9787\n",
      "Epoch 195/10000\n",
      "1126/1126 [==============================] - 0s - loss: 79.7100 - val_loss: 105.7327\n",
      "Epoch 196/10000\n",
      "1126/1126 [==============================] - 0s - loss: 79.4998 - val_loss: 105.4902\n",
      "Epoch 197/10000\n",
      "1126/1126 [==============================] - 0s - loss: 79.2896 - val_loss: 105.2390\n",
      "Epoch 198/10000\n",
      "1126/1126 [==============================] - 0s - loss: 79.0827 - val_loss: 105.0233\n",
      "Epoch 199/10000\n",
      "1126/1126 [==============================] - 0s - loss: 78.8765 - val_loss: 104.7951\n",
      "Epoch 200/10000\n",
      "1126/1126 [==============================] - 0s - loss: 78.6712 - val_loss: 104.5638\n",
      "Epoch 201/10000\n",
      "1126/1126 [==============================] - 0s - loss: 78.4693 - val_loss: 104.3681\n",
      "Epoch 202/10000\n",
      "1126/1126 [==============================] - 0s - loss: 78.2661 - val_loss: 104.1459\n",
      "Epoch 203/10000\n",
      "1126/1126 [==============================] - 0s - loss: 78.0628 - val_loss: 103.9130\n",
      "Epoch 204/10000\n",
      "1126/1126 [==============================] - 0s - loss: 77.8637 - val_loss: 103.7013\n",
      "Epoch 205/10000\n",
      "1126/1126 [==============================] - 0s - loss: 77.6650 - val_loss: 103.4901\n",
      "Epoch 206/10000\n",
      "1126/1126 [==============================] - 0s - loss: 77.4675 - val_loss: 103.2825\n",
      "Epoch 207/10000\n",
      "1126/1126 [==============================] - 0s - loss: 77.2721 - val_loss: 103.1241\n",
      "Epoch 208/10000\n",
      "1126/1126 [==============================] - 0s - loss: 77.0746 - val_loss: 102.9362\n",
      "Epoch 209/10000\n",
      "1126/1126 [==============================] - 0s - loss: 76.8817 - val_loss: 102.7584\n",
      "Epoch 210/10000\n",
      "1126/1126 [==============================] - 0s - loss: 76.6874 - val_loss: 102.5429\n",
      "Epoch 211/10000\n",
      "1126/1126 [==============================] - 0s - loss: 76.4941 - val_loss: 102.3361\n",
      "Epoch 212/10000\n",
      "1126/1126 [==============================] - 0s - loss: 76.3019 - val_loss: 102.1555\n",
      "Epoch 213/10000\n",
      "1126/1126 [==============================] - 0s - loss: 76.1091 - val_loss: 101.9484\n",
      "Epoch 214/10000\n",
      "1126/1126 [==============================] - 0s - loss: 75.9236 - val_loss: 101.7648\n",
      "Epoch 215/10000\n",
      "1126/1126 [==============================] - 0s - loss: 75.7328 - val_loss: 101.5767\n",
      "Epoch 216/10000\n",
      "1126/1126 [==============================] - 0s - loss: 75.5499 - val_loss: 101.3805\n",
      "Epoch 217/10000\n",
      "1126/1126 [==============================] - 0s - loss: 75.3625 - val_loss: 101.1952\n",
      "Epoch 218/10000\n",
      "1126/1126 [==============================] - 0s - loss: 75.1814 - val_loss: 101.0176\n",
      "Epoch 219/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.9988 - val_loss: 100.8232\n",
      "Epoch 220/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.8163 - val_loss: 100.6365\n",
      "Epoch 221/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.6389 - val_loss: 100.4516\n",
      "Epoch 222/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.4584 - val_loss: 100.2564\n",
      "Epoch 223/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.2782 - val_loss: 100.0733\n",
      "Epoch 224/10000\n",
      "1126/1126 [==============================] - 0s - loss: 74.1049 - val_loss: 99.8878\n",
      "Epoch 225/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.9297 - val_loss: 99.7282\n",
      "Epoch 226/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.7549 - val_loss: 99.5572\n",
      "Epoch 227/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.5835 - val_loss: 99.3846\n",
      "Epoch 228/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.4100 - val_loss: 99.2233\n",
      "Epoch 229/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.2401 - val_loss: 99.0322\n",
      "Epoch 230/10000\n",
      "1126/1126 [==============================] - 0s - loss: 73.0695 - val_loss: 98.8693\n",
      "Epoch 231/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.8982 - val_loss: 98.7113\n",
      "Epoch 232/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.7320 - val_loss: 98.5474\n",
      "Epoch 233/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.5595 - val_loss: 98.4010\n",
      "Epoch 234/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.3953 - val_loss: 98.2160\n",
      "Epoch 235/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.2289 - val_loss: 98.0596\n",
      "Epoch 236/10000\n",
      "1126/1126 [==============================] - 0s - loss: 72.0600 - val_loss: 97.8882\n",
      "Epoch 237/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.9034 - val_loss: 97.7513\n",
      "Epoch 238/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.7377 - val_loss: 97.5948\n",
      "Epoch 239/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.5813 - val_loss: 97.4212\n",
      "Epoch 240/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.4184 - val_loss: 97.2659\n",
      "Epoch 241/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.2626 - val_loss: 97.1121\n",
      "Epoch 242/10000\n",
      "1126/1126 [==============================] - 0s - loss: 71.1031 - val_loss: 96.9325\n",
      "Epoch 243/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 70.9477 - val_loss: 96.7498\n",
      "Epoch 244/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.7922 - val_loss: 96.6384\n",
      "Epoch 245/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.6390 - val_loss: 96.4028\n",
      "Epoch 246/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.4860 - val_loss: 96.3005\n",
      "Epoch 247/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.3346 - val_loss: 96.1081\n",
      "Epoch 248/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.1789 - val_loss: 95.9426\n",
      "Epoch 249/10000\n",
      "1126/1126 [==============================] - 0s - loss: 70.0328 - val_loss: 95.8295\n",
      "Epoch 250/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.8815 - val_loss: 95.6497\n",
      "Epoch 251/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.7297 - val_loss: 95.4395\n",
      "Epoch 252/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.5834 - val_loss: 95.3052\n",
      "Epoch 253/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.4346 - val_loss: 95.0823\n",
      "Epoch 254/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.2915 - val_loss: 94.9182\n",
      "Epoch 255/10000\n",
      "1126/1126 [==============================] - 0s - loss: 69.1481 - val_loss: 94.7166\n",
      "Epoch 256/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.9999 - val_loss: 94.5612\n",
      "Epoch 257/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.8594 - val_loss: 94.3649\n",
      "Epoch 258/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.7174 - val_loss: 94.2218\n",
      "Epoch 259/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.5758 - val_loss: 94.0542\n",
      "Epoch 260/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.4404 - val_loss: 93.8691\n",
      "Epoch 261/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.3022 - val_loss: 93.6884\n",
      "Epoch 262/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.1632 - val_loss: 93.5621\n",
      "Epoch 263/10000\n",
      "1126/1126 [==============================] - 0s - loss: 68.0301 - val_loss: 93.3188\n",
      "Epoch 264/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.8957 - val_loss: 93.1999\n",
      "Epoch 265/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.7605 - val_loss: 92.9748\n",
      "Epoch 266/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.6296 - val_loss: 92.8233\n",
      "Epoch 267/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.4998 - val_loss: 92.6130\n",
      "Epoch 268/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.3634 - val_loss: 92.4564\n",
      "Epoch 269/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.2375 - val_loss: 92.2929\n",
      "Epoch 270/10000\n",
      "1126/1126 [==============================] - 0s - loss: 67.1088 - val_loss: 92.1171\n",
      "Epoch 271/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.9759 - val_loss: 91.9658\n",
      "Epoch 272/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.8533 - val_loss: 91.8024\n",
      "Epoch 273/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.7249 - val_loss: 91.6200\n",
      "Epoch 274/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.5998 - val_loss: 91.4959\n",
      "Epoch 275/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.4740 - val_loss: 91.3334\n",
      "Epoch 276/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.3566 - val_loss: 91.1348\n",
      "Epoch 277/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.2340 - val_loss: 91.0042\n",
      "Epoch 278/10000\n",
      "1126/1126 [==============================] - 0s - loss: 66.1108 - val_loss: 90.7907\n",
      "Epoch 279/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.9865 - val_loss: 90.6847\n",
      "Epoch 280/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.8685 - val_loss: 90.4433\n",
      "Epoch 281/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.7466 - val_loss: 90.3076\n",
      "Epoch 282/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.6240 - val_loss: 90.1195\n",
      "Epoch 283/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.5064 - val_loss: 89.9545\n",
      "Epoch 284/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.3818 - val_loss: 89.7679\n",
      "Epoch 285/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.2644 - val_loss: 89.5802\n",
      "Epoch 286/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.1409 - val_loss: 89.4487\n",
      "Epoch 287/10000\n",
      "1126/1126 [==============================] - 0s - loss: 65.0244 - val_loss: 89.2167\n",
      "Epoch 288/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.9038 - val_loss: 89.0868\n",
      "Epoch 289/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.7899 - val_loss: 88.8925\n",
      "Epoch 290/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.6714 - val_loss: 88.8037\n",
      "Epoch 291/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.5586 - val_loss: 88.5794\n",
      "Epoch 292/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.4392 - val_loss: 88.5083\n",
      "Epoch 293/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.3315 - val_loss: 88.2946\n",
      "Epoch 294/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.2153 - val_loss: 88.1855\n",
      "Epoch 295/10000\n",
      "1126/1126 [==============================] - 0s - loss: 64.1026 - val_loss: 88.0367\n",
      "Epoch 296/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.9910 - val_loss: 87.8879\n",
      "Epoch 297/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.8805 - val_loss: 87.7253\n",
      "Epoch 298/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.7672 - val_loss: 87.6014\n",
      "Epoch 299/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.6583 - val_loss: 87.4146\n",
      "Epoch 300/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.5463 - val_loss: 87.3253\n",
      "Epoch 301/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.4378 - val_loss: 87.1180\n",
      "Epoch 302/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.3297 - val_loss: 86.9909\n",
      "Epoch 303/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.2272 - val_loss: 86.8051\n",
      "Epoch 304/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.1221 - val_loss: 86.7136\n",
      "Epoch 305/10000\n",
      "1126/1126 [==============================] - 0s - loss: 63.0192 - val_loss: 86.5210:\n",
      "Epoch 306/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.9123 - val_loss: 86.4192\n",
      "Epoch 307/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.8114 - val_loss: 86.2201\n",
      "Epoch 308/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.7057 - val_loss: 86.1516\n",
      "Epoch 309/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.6048 - val_loss: 85.9607\n",
      "Epoch 310/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.5025 - val_loss: 85.8349\n",
      "Epoch 311/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.4039 - val_loss: 85.6943\n",
      "Epoch 312/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.3038 - val_loss: 85.5666\n",
      "Epoch 313/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.2043 - val_loss: 85.4288\n",
      "Epoch 314/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.1068 - val_loss: 85.2954\n",
      "Epoch 315/10000\n",
      "1126/1126 [==============================] - 0s - loss: 62.0088 - val_loss: 85.1749\n",
      "Epoch 316/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.9129 - val_loss: 85.0317\n",
      "Epoch 317/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.8139 - val_loss: 84.9368\n",
      "Epoch 318/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.7212 - val_loss: 84.7889\n",
      "Epoch 319/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.6231 - val_loss: 84.6625\n",
      "Epoch 320/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.5280 - val_loss: 84.5684\n",
      "Epoch 321/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.4357 - val_loss: 84.4204\n",
      "Epoch 322/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.3401 - val_loss: 84.3205\n",
      "Epoch 323/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.2474 - val_loss: 84.1764\n",
      "Epoch 324/10000\n",
      "1126/1126 [==============================] - 0s - loss: 61.1522 - val_loss: 84.0743\n",
      "Epoch 325/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 61.0593 - val_loss: 83.9336\n",
      "Epoch 326/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.9675 - val_loss: 83.8219\n",
      "Epoch 327/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.8749 - val_loss: 83.7082\n",
      "Epoch 328/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.7845 - val_loss: 83.5885\n",
      "Epoch 329/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.6962 - val_loss: 83.4897\n",
      "Epoch 330/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.6079 - val_loss: 83.3806\n",
      "Epoch 331/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.5182 - val_loss: 83.2715\n",
      "Epoch 332/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.4336 - val_loss: 83.1610\n",
      "Epoch 333/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.3415 - val_loss: 83.0582\n",
      "Epoch 334/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.2576 - val_loss: 82.9289\n",
      "Epoch 335/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.1695 - val_loss: 82.8189\n",
      "Epoch 336/10000\n",
      "1126/1126 [==============================] - 0s - loss: 60.0854 - val_loss: 82.6939\n",
      "Epoch 337/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.9974 - val_loss: 82.5917\n",
      "Epoch 338/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.9136 - val_loss: 82.4758\n",
      "Epoch 339/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.8268 - val_loss: 82.3660\n",
      "Epoch 340/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.7429 - val_loss: 82.2561\n",
      "Epoch 341/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.6589 - val_loss: 82.1532\n",
      "Epoch 342/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.5734 - val_loss: 82.0457\n",
      "Epoch 343/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.4895 - val_loss: 81.9417\n",
      "Epoch 344/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.4066 - val_loss: 81.8532\n",
      "Epoch 345/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.3235 - val_loss: 81.7149\n",
      "Epoch 346/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.2418 - val_loss: 81.6054\n",
      "Epoch 347/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.1579 - val_loss: 81.4902\n",
      "Epoch 348/10000\n",
      "1126/1126 [==============================] - 0s - loss: 59.0788 - val_loss: 81.3578\n",
      "Epoch 349/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.9933 - val_loss: 81.2482\n",
      "Epoch 350/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.9146 - val_loss: 81.1407\n",
      "Epoch 351/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.8359 - val_loss: 81.0332\n",
      "Epoch 352/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.7566 - val_loss: 80.9123\n",
      "Epoch 353/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.6782 - val_loss: 80.8133\n",
      "Epoch 354/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.5990 - val_loss: 80.7014\n",
      "Epoch 355/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.5248 - val_loss: 80.5982\n",
      "Epoch 356/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.4467 - val_loss: 80.4913\n",
      "Epoch 357/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.3742 - val_loss: 80.3713\n",
      "Epoch 358/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.2988 - val_loss: 80.2879\n",
      "Epoch 359/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.2266 - val_loss: 80.1706\n",
      "Epoch 360/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.1513 - val_loss: 80.0787\n",
      "Epoch 361/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.0822 - val_loss: 79.9768\n",
      "Epoch 362/10000\n",
      "1126/1126 [==============================] - 0s - loss: 58.0109 - val_loss: 79.9125\n",
      "Epoch 363/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.9405 - val_loss: 79.8100\n",
      "Epoch 364/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.8667 - val_loss: 79.7313\n",
      "Epoch 365/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.8017 - val_loss: 79.6196\n",
      "Epoch 366/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.7308 - val_loss: 79.5471\n",
      "Epoch 367/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.6635 - val_loss: 79.4446\n",
      "Epoch 368/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.5945 - val_loss: 79.3805\n",
      "Epoch 369/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.5259 - val_loss: 79.2914\n",
      "Epoch 370/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.4578 - val_loss: 79.2110\n",
      "Epoch 371/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.3910 - val_loss: 79.1257\n",
      "Epoch 372/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.3231 - val_loss: 79.0409\n",
      "Epoch 373/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.2580 - val_loss: 78.9601\n",
      "Epoch 374/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.1886 - val_loss: 78.8952\n",
      "Epoch 375/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.1230 - val_loss: 78.8202\n",
      "Epoch 376/10000\n",
      "1126/1126 [==============================] - 0s - loss: 57.0560 - val_loss: 78.7573\n",
      "Epoch 377/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.9902 - val_loss: 78.6854\n",
      "Epoch 378/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.9240 - val_loss: 78.6061\n",
      "Epoch 379/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.8589 - val_loss: 78.5386\n",
      "Epoch 380/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.7928 - val_loss: 78.4584\n",
      "Epoch 381/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.7284 - val_loss: 78.3858\n",
      "Epoch 382/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.6639 - val_loss: 78.3182\n",
      "Epoch 383/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.6008 - val_loss: 78.2423\n",
      "Epoch 384/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.5375 - val_loss: 78.1781\n",
      "Epoch 385/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.4726 - val_loss: 78.1617\n",
      "Epoch 386/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.4118 - val_loss: 78.0314\n",
      "Epoch 387/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.3441 - val_loss: 78.0544\n",
      "Epoch 388/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.2866 - val_loss: 77.9131\n",
      "Epoch 389/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.2205 - val_loss: 77.9236\n",
      "Epoch 390/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.1618 - val_loss: 77.7952\n",
      "Epoch 391/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.0983 - val_loss: 77.8282\n",
      "Epoch 392/10000\n",
      "1126/1126 [==============================] - 0s - loss: 56.0401 - val_loss: 77.7555\n",
      "Epoch 393/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.9754 - val_loss: 77.7081\n",
      "Epoch 394/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.9208 - val_loss: 77.6318\n",
      "Epoch 395/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.8535 - val_loss: 77.6405\n",
      "Epoch 396/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.7959 - val_loss: 77.5065\n",
      "Epoch 397/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.7326 - val_loss: 77.5460\n",
      "Epoch 398/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.6780 - val_loss: 77.4813\n",
      "Epoch 399/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.6167 - val_loss: 77.4831\n",
      "Epoch 400/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.5604 - val_loss: 77.3737\n",
      "Epoch 401/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.4997 - val_loss: 77.4213\n",
      "Epoch 402/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.4459 - val_loss: 77.3440\n",
      "Epoch 403/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.3838 - val_loss: 77.3335\n",
      "Epoch 404/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.3302 - val_loss: 77.2753\n",
      "Epoch 405/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.2716 - val_loss: 77.3046\n",
      "Epoch 406/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.2188 - val_loss: 77.1398\n",
      "Epoch 407/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 55.1564 - val_loss: 77.2195\n",
      "Epoch 408/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.1051 - val_loss: 77.1669\n",
      "Epoch 409/10000\n",
      "1126/1126 [==============================] - 0s - loss: 55.0465 - val_loss: 77.1183\n",
      "Epoch 410/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.9924 - val_loss: 77.0927\n",
      "Epoch 411/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.9364 - val_loss: 77.0476\n",
      "Epoch 412/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.8790 - val_loss: 77.0326\n",
      "Epoch 413/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.8278 - val_loss: 76.9876\n",
      "Epoch 414/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.7694 - val_loss: 76.9491\n",
      "Epoch 415/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.7147 - val_loss: 76.9213\n",
      "Epoch 416/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.6578 - val_loss: 76.9238\n",
      "Epoch 417/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.6019 - val_loss: 76.8466\n",
      "Epoch 418/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.5438 - val_loss: 76.8585\n",
      "Epoch 419/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.4899 - val_loss: 76.8082\n",
      "Epoch 420/10000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 54.26 - 0s - loss: 54.4301 - val_loss: 76.7856\n",
      "Epoch 421/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.3787 - val_loss: 76.7320\n",
      "Epoch 422/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.3210 - val_loss: 76.7417\n",
      "Epoch 423/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.2668 - val_loss: 76.6536\n",
      "Epoch 424/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.2084 - val_loss: 76.6724\n",
      "Epoch 425/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.1543 - val_loss: 76.6554\n",
      "Epoch 426/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.1003 - val_loss: 76.5897\n",
      "Epoch 427/10000\n",
      "1126/1126 [==============================] - 0s - loss: 54.0457 - val_loss: 76.6023\n",
      "Epoch 428/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.9924 - val_loss: 76.5591\n",
      "Epoch 429/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.9342 - val_loss: 76.5273\n",
      "Epoch 430/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.8838 - val_loss: 76.5109\n",
      "Epoch 431/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.8270 - val_loss: 76.5068\n",
      "Epoch 432/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.7798 - val_loss: 76.4663\n",
      "Epoch 433/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.7249 - val_loss: 76.4681\n",
      "Epoch 434/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.6740 - val_loss: 76.4412\n",
      "Epoch 435/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.6229 - val_loss: 76.4291\n",
      "Epoch 436/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.5724 - val_loss: 76.4149\n",
      "Epoch 437/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.5147 - val_loss: 76.3742\n",
      "Epoch 438/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.4667 - val_loss: 76.3691\n",
      "Epoch 439/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.4115 - val_loss: 76.3734\n",
      "Epoch 440/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.3633 - val_loss: 76.3270\n",
      "Epoch 441/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.3083 - val_loss: 76.3198\n",
      "Epoch 442/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.2586 - val_loss: 76.3399\n",
      "Epoch 443/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.2069 - val_loss: 76.3099\n",
      "Epoch 444/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.1580 - val_loss: 76.3099\n",
      "Epoch 445/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.1029 - val_loss: 76.3123\n",
      "Epoch 446/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.0569 - val_loss: 76.2641\n",
      "Epoch 447/10000\n",
      "1126/1126 [==============================] - 0s - loss: 53.0046 - val_loss: 76.2712\n",
      "Epoch 448/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.9557 - val_loss: 76.2487\n",
      "Epoch 449/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.9033 - val_loss: 76.2677\n",
      "Epoch 450/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.8552 - val_loss: 76.2295\n",
      "Epoch 451/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.8027 - val_loss: 76.2405\n",
      "Epoch 452/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.7555 - val_loss: 76.2430\n",
      "Epoch 453/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.7039 - val_loss: 76.1743\n",
      "Epoch 454/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.6515 - val_loss: 76.2826\n",
      "Epoch 455/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.6031 - val_loss: 76.2126\n",
      "Epoch 456/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.5519 - val_loss: 76.2265\n",
      "Epoch 457/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.5022 - val_loss: 76.1793\n",
      "Epoch 458/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.4532 - val_loss: 76.1967\n",
      "Epoch 459/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.4040 - val_loss: 76.1768\n",
      "Epoch 460/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.3562 - val_loss: 76.1693\n",
      "Epoch 461/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.3086 - val_loss: 76.1768\n",
      "Epoch 462/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.2600 - val_loss: 76.1550\n",
      "Epoch 463/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.2123 - val_loss: 76.1424\n",
      "Epoch 464/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.1648 - val_loss: 76.1682\n",
      "Epoch 465/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.1176 - val_loss: 76.1149\n",
      "Epoch 466/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.0711 - val_loss: 76.0972\n",
      "Epoch 467/10000\n",
      "1126/1126 [==============================] - 0s - loss: 52.0232 - val_loss: 76.1095\n",
      "Epoch 468/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.9782 - val_loss: 76.0564\n",
      "Epoch 469/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.9311 - val_loss: 76.0820\n",
      "Epoch 470/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.8843 - val_loss: 76.0333\n",
      "Epoch 471/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.8403 - val_loss: 76.0231\n",
      "Epoch 472/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.7947 - val_loss: 76.0219\n",
      "Epoch 473/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.7480 - val_loss: 75.9724\n",
      "Epoch 474/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.7034 - val_loss: 75.9915\n",
      "Epoch 475/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.6583 - val_loss: 75.9579\n",
      "Epoch 476/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.6131 - val_loss: 75.9742\n",
      "Epoch 477/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.5687 - val_loss: 75.9316\n",
      "Epoch 478/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.5218 - val_loss: 75.9318\n",
      "Epoch 479/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.4784 - val_loss: 75.9616\n",
      "Epoch 480/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.4342 - val_loss: 75.9336\n",
      "Epoch 481/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.3905 - val_loss: 75.9393\n",
      "Epoch 482/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.3479 - val_loss: 75.9331\n",
      "Epoch 483/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.3035 - val_loss: 75.8892\n",
      "Epoch 484/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.2594 - val_loss: 75.9220\n",
      "Epoch 485/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.2157 - val_loss: 75.8867\n",
      "Epoch 486/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.1736 - val_loss: 75.8807\n",
      "Epoch 487/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.1294 - val_loss: 75.8879\n",
      "Epoch 488/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s - loss: 51.0849 - val_loss: 75.9213\n",
      "Epoch 489/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.0454 - val_loss: 75.8730\n",
      "Epoch 490/10000\n",
      "1126/1126 [==============================] - 0s - loss: 51.0005 - val_loss: 75.8963\n",
      "Epoch 491/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.9553 - val_loss: 75.8653\n",
      "Epoch 492/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.9165 - val_loss: 75.9190\n",
      "Epoch 493/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.8727 - val_loss: 75.9006\n",
      "Epoch 494/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.8323 - val_loss: 75.9210\n",
      "Epoch 495/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.7907 - val_loss: 75.9640\n",
      "Epoch 496/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.7480 - val_loss: 75.9243\n",
      "Epoch 497/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.7068 - val_loss: 75.9900\n",
      "Epoch 498/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.6667 - val_loss: 75.9635\n",
      "Epoch 499/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.6266 - val_loss: 76.0038\n",
      "Epoch 500/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.5850 - val_loss: 75.9915\n",
      "Epoch 501/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.5417 - val_loss: 75.9906\n",
      "Epoch 502/10000\n",
      "1126/1126 [==============================] - 0s - loss: 50.5006 - val_loss: 76.0576\n",
      "Epoch 00501: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto', patience=10)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10000, validation_data=(X_valid, y_valid), callbacks=[early_stopping], verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119152e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11966ff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "plt.title('Cot et cot de validation')\n",
    "line1,=plt.plot(history.history['loss'], label=\"Loss\", linestyle='-', color='r')\n",
    "line2,=plt.plot(history.history['val_loss'], label=\"Val loss\", linestyle='-', color='b')\n",
    "first_legend = plt.legend(handles=[line1, line2], loc=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.title('y_pred en fonction de y_test')\n",
    "\n",
    "plt.plot(y_pred[:], y_test[:], '+')\n",
    "plt.ylabel('Test')\n",
    "plt.xlabel('Prdiction')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

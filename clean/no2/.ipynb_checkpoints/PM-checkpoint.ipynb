{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AllNO2_QH.csv',\n",
       " 'AllPM_QH.csv',\n",
       " 'Env_QH.csv',\n",
       " 'GradientTemp_15minDataSet.csv',\n",
       " 'micro_sud3.pkl',\n",
       " 'micro_sud3_normalized.pkl',\n",
       " 'Patm_15minDataSet.csv',\n",
       " 'pickles']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>PM_ref</th>\n",
       "      <th>PM_6182</th>\n",
       "      <th>PM_6179</th>\n",
       "      <th>PM_617B</th>\n",
       "      <th>PM25_6182</th>\n",
       "      <th>PM25_6179</th>\n",
       "      <th>PM25_617B</th>\n",
       "      <th>NO2_ref</th>\n",
       "      <th>NO2_61FD</th>\n",
       "      <th>NO2_61F0</th>\n",
       "      <th>NO2_61EF</th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "      <th>tgrad</th>\n",
       "      <th>pressure</th>\n",
       "      <th>pluvio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>2017-09-28 14:00:00</td>\n",
       "      <td>16.2</td>\n",
       "      <td>-1.178505</td>\n",
       "      <td>-1.137844</td>\n",
       "      <td>-1.134624</td>\n",
       "      <td>-1.183081</td>\n",
       "      <td>-1.128074</td>\n",
       "      <td>-1.148204</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.986031</td>\n",
       "      <td>-1.114144</td>\n",
       "      <td>-0.922393</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>2017-09-28 14:15:00</td>\n",
       "      <td>9.6</td>\n",
       "      <td>-1.108262</td>\n",
       "      <td>-1.085060</td>\n",
       "      <td>-1.121956</td>\n",
       "      <td>-1.101652</td>\n",
       "      <td>-1.071229</td>\n",
       "      <td>-1.128278</td>\n",
       "      <td>9.9</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>2.057032</td>\n",
       "      <td>-1.123212</td>\n",
       "      <td>-0.977185</td>\n",
       "      <td>0.335134</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>2017-09-28 14:30:00</td>\n",
       "      <td>10.3</td>\n",
       "      <td>-1.178505</td>\n",
       "      <td>-1.169515</td>\n",
       "      <td>-1.257077</td>\n",
       "      <td>-1.176817</td>\n",
       "      <td>-1.167865</td>\n",
       "      <td>-1.252817</td>\n",
       "      <td>16.1</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>2.080699</td>\n",
       "      <td>-1.232038</td>\n",
       "      <td>-1.086769</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2017-09-28 14:45:00</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-1.137530</td>\n",
       "      <td>-1.000606</td>\n",
       "      <td>-1.206407</td>\n",
       "      <td>-1.139235</td>\n",
       "      <td>-1.008700</td>\n",
       "      <td>-1.222928</td>\n",
       "      <td>10.9</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>2.009698</td>\n",
       "      <td>-1.259245</td>\n",
       "      <td>-0.812809</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2017-09-28 15:00:00</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-1.166798</td>\n",
       "      <td>-1.164236</td>\n",
       "      <td>-1.138846</td>\n",
       "      <td>-1.164290</td>\n",
       "      <td>-1.167865</td>\n",
       "      <td>-1.148204</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.867697</td>\n",
       "      <td>-1.141350</td>\n",
       "      <td>-0.922393</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>2017-09-28 15:15:00</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-1.166798</td>\n",
       "      <td>-1.201185</td>\n",
       "      <td>-1.037506</td>\n",
       "      <td>-1.158026</td>\n",
       "      <td>-1.196288</td>\n",
       "      <td>-1.038610</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.749363</td>\n",
       "      <td>-1.050662</td>\n",
       "      <td>-0.867601</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>2017-09-28 15:30:00</td>\n",
       "      <td>9.6</td>\n",
       "      <td>-1.078994</td>\n",
       "      <td>-1.169515</td>\n",
       "      <td>-1.007948</td>\n",
       "      <td>-1.070333</td>\n",
       "      <td>-1.162181</td>\n",
       "      <td>-0.998757</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.654695</td>\n",
       "      <td>-0.959974</td>\n",
       "      <td>-0.812809</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>2017-09-28 15:45:00</td>\n",
       "      <td>10.2</td>\n",
       "      <td>-1.032164</td>\n",
       "      <td>-1.132566</td>\n",
       "      <td>-0.995280</td>\n",
       "      <td>-1.032750</td>\n",
       "      <td>-1.122389</td>\n",
       "      <td>-0.988794</td>\n",
       "      <td>19.1</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.583695</td>\n",
       "      <td>-0.887423</td>\n",
       "      <td>-0.758017</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>2017-09-28 16:00:00</td>\n",
       "      <td>9.8</td>\n",
       "      <td>-1.043872</td>\n",
       "      <td>-1.095617</td>\n",
       "      <td>-0.910830</td>\n",
       "      <td>-1.039014</td>\n",
       "      <td>-1.093967</td>\n",
       "      <td>-0.919052</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.536361</td>\n",
       "      <td>-0.851148</td>\n",
       "      <td>-0.758017</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>2017-09-28 16:15:00</td>\n",
       "      <td>8.9</td>\n",
       "      <td>-1.043872</td>\n",
       "      <td>-1.042833</td>\n",
       "      <td>-1.181072</td>\n",
       "      <td>-1.039014</td>\n",
       "      <td>-1.037122</td>\n",
       "      <td>-1.173112</td>\n",
       "      <td>19.4</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.489027</td>\n",
       "      <td>-0.851148</td>\n",
       "      <td>-0.703225</td>\n",
       "      <td>0.335134</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>2017-09-28 16:30:00</td>\n",
       "      <td>9.8</td>\n",
       "      <td>-0.915092</td>\n",
       "      <td>-0.889760</td>\n",
       "      <td>-1.185294</td>\n",
       "      <td>-0.913739</td>\n",
       "      <td>-0.889325</td>\n",
       "      <td>-1.178094</td>\n",
       "      <td>20.6</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.441693</td>\n",
       "      <td>-0.805804</td>\n",
       "      <td>-0.648433</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>2017-09-28 16:45:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-0.920945</td>\n",
       "      <td>-0.784192</td>\n",
       "      <td>-1.029061</td>\n",
       "      <td>-0.926266</td>\n",
       "      <td>-0.787005</td>\n",
       "      <td>-1.013702</td>\n",
       "      <td>17.3</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.576624</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.370693</td>\n",
       "      <td>-0.715116</td>\n",
       "      <td>-0.648433</td>\n",
       "      <td>0.315942</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>2017-09-28 17:00:00</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-0.862409</td>\n",
       "      <td>-0.842254</td>\n",
       "      <td>-0.969945</td>\n",
       "      <td>-0.869892</td>\n",
       "      <td>-0.843850</td>\n",
       "      <td>-0.963886</td>\n",
       "      <td>16.3</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.299692</td>\n",
       "      <td>-0.642565</td>\n",
       "      <td>-0.648433</td>\n",
       "      <td>0.335134</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28</td>\n",
       "      <td>2017-09-28 17:15:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.932653</td>\n",
       "      <td>-0.778913</td>\n",
       "      <td>-0.915052</td>\n",
       "      <td>-0.932530</td>\n",
       "      <td>-0.775636</td>\n",
       "      <td>-0.914070</td>\n",
       "      <td>16.4</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.228692</td>\n",
       "      <td>-0.506533</td>\n",
       "      <td>-0.593641</td>\n",
       "      <td>0.335134</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>2017-09-28 17:30:00</td>\n",
       "      <td>12.3</td>\n",
       "      <td>-0.903385</td>\n",
       "      <td>-0.905595</td>\n",
       "      <td>-0.817934</td>\n",
       "      <td>-0.901211</td>\n",
       "      <td>-0.900694</td>\n",
       "      <td>-0.814439</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.134024</td>\n",
       "      <td>-0.397707</td>\n",
       "      <td>-0.538849</td>\n",
       "      <td>0.354326</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30</td>\n",
       "      <td>2017-09-28 17:45:00</td>\n",
       "      <td>13.7</td>\n",
       "      <td>-0.967775</td>\n",
       "      <td>-0.805305</td>\n",
       "      <td>-0.843269</td>\n",
       "      <td>-0.963849</td>\n",
       "      <td>-0.804058</td>\n",
       "      <td>-0.844329</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.525787</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.063024</td>\n",
       "      <td>-0.288882</td>\n",
       "      <td>-0.429265</td>\n",
       "      <td>0.354326</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31</td>\n",
       "      <td>2017-09-28 18:00:00</td>\n",
       "      <td>14.3</td>\n",
       "      <td>-0.698507</td>\n",
       "      <td>-0.615283</td>\n",
       "      <td>-0.910830</td>\n",
       "      <td>-0.688243</td>\n",
       "      <td>-0.616470</td>\n",
       "      <td>-0.904107</td>\n",
       "      <td>27.1</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.589334</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.992023</td>\n",
       "      <td>-0.189125</td>\n",
       "      <td>-0.319681</td>\n",
       "      <td>0.373518</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>2017-09-28 18:15:00</td>\n",
       "      <td>14.7</td>\n",
       "      <td>-0.885824</td>\n",
       "      <td>-0.662789</td>\n",
       "      <td>-0.847492</td>\n",
       "      <td>-0.876156</td>\n",
       "      <td>-0.667631</td>\n",
       "      <td>-0.839347</td>\n",
       "      <td>21.9</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.589334</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.921022</td>\n",
       "      <td>-0.044024</td>\n",
       "      <td>-0.264889</td>\n",
       "      <td>0.392710</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>2017-09-28 19:45:00</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.751190</td>\n",
       "      <td>-0.625840</td>\n",
       "      <td>-0.796821</td>\n",
       "      <td>-0.744617</td>\n",
       "      <td>-0.616470</td>\n",
       "      <td>-0.794513</td>\n",
       "      <td>32.4</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.363744</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.613353</td>\n",
       "      <td>0.382210</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39</td>\n",
       "      <td>2017-09-28 20:00:00</td>\n",
       "      <td>20.1</td>\n",
       "      <td>-0.827287</td>\n",
       "      <td>-0.757800</td>\n",
       "      <td>-0.813711</td>\n",
       "      <td>-0.826046</td>\n",
       "      <td>-0.741529</td>\n",
       "      <td>-0.819421</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.427290</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.566019</td>\n",
       "      <td>0.427554</td>\n",
       "      <td>-0.155305</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>2017-09-28 20:15:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.721922</td>\n",
       "      <td>-0.794749</td>\n",
       "      <td>-0.906607</td>\n",
       "      <td>-0.725825</td>\n",
       "      <td>-0.787005</td>\n",
       "      <td>-0.889163</td>\n",
       "      <td>27.5</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.576624</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.518686</td>\n",
       "      <td>0.509174</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>41</td>\n",
       "      <td>2017-09-28 20:30:00</td>\n",
       "      <td>19.2</td>\n",
       "      <td>-0.598996</td>\n",
       "      <td>-0.757800</td>\n",
       "      <td>-0.915052</td>\n",
       "      <td>-0.600550</td>\n",
       "      <td>-0.752898</td>\n",
       "      <td>-0.914070</td>\n",
       "      <td>25.6</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.589334</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.495019</td>\n",
       "      <td>0.554518</td>\n",
       "      <td>0.063863</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42</td>\n",
       "      <td>2017-09-28 20:45:00</td>\n",
       "      <td>17.9</td>\n",
       "      <td>-0.803873</td>\n",
       "      <td>-0.889760</td>\n",
       "      <td>-0.898162</td>\n",
       "      <td>-0.807254</td>\n",
       "      <td>-0.895010</td>\n",
       "      <td>-0.899126</td>\n",
       "      <td>27.3</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.495019</td>\n",
       "      <td>0.581724</td>\n",
       "      <td>0.173447</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43</td>\n",
       "      <td>2017-09-28 21:00:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.757044</td>\n",
       "      <td>-0.842254</td>\n",
       "      <td>-0.733483</td>\n",
       "      <td>-0.750880</td>\n",
       "      <td>-0.838165</td>\n",
       "      <td>-0.729752</td>\n",
       "      <td>26.3</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.589334</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.471352</td>\n",
       "      <td>0.581724</td>\n",
       "      <td>0.118655</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44</td>\n",
       "      <td>2017-09-28 21:15:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.798019</td>\n",
       "      <td>-0.858089</td>\n",
       "      <td>-0.695481</td>\n",
       "      <td>-0.788463</td>\n",
       "      <td>-0.860903</td>\n",
       "      <td>-0.684918</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.471352</td>\n",
       "      <td>0.636137</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.411902</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>45</td>\n",
       "      <td>2017-09-28 21:30:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.973628</td>\n",
       "      <td>-0.873925</td>\n",
       "      <td>-0.670145</td>\n",
       "      <td>-0.963849</td>\n",
       "      <td>-0.872272</td>\n",
       "      <td>-0.655029</td>\n",
       "      <td>25.7</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.447685</td>\n",
       "      <td>0.672412</td>\n",
       "      <td>0.173447</td>\n",
       "      <td>0.392710</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>46</td>\n",
       "      <td>2017-09-28 21:45:00</td>\n",
       "      <td>18.5</td>\n",
       "      <td>-0.838995</td>\n",
       "      <td>-0.810584</td>\n",
       "      <td>-0.657478</td>\n",
       "      <td>-0.832310</td>\n",
       "      <td>-0.809743</td>\n",
       "      <td>-0.660010</td>\n",
       "      <td>23.2</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.447685</td>\n",
       "      <td>0.672412</td>\n",
       "      <td>0.118655</td>\n",
       "      <td>0.392710</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>47</td>\n",
       "      <td>2017-09-28 22:00:00</td>\n",
       "      <td>18.6</td>\n",
       "      <td>-0.838995</td>\n",
       "      <td>-0.831697</td>\n",
       "      <td>-0.678591</td>\n",
       "      <td>-0.838573</td>\n",
       "      <td>-0.821112</td>\n",
       "      <td>-0.674955</td>\n",
       "      <td>21.2</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.471352</td>\n",
       "      <td>0.672412</td>\n",
       "      <td>0.228239</td>\n",
       "      <td>0.392710</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>48</td>\n",
       "      <td>2017-09-28 22:15:00</td>\n",
       "      <td>18.8</td>\n",
       "      <td>-0.622410</td>\n",
       "      <td>-0.678624</td>\n",
       "      <td>-0.535024</td>\n",
       "      <td>-0.619341</td>\n",
       "      <td>-0.684684</td>\n",
       "      <td>-0.540453</td>\n",
       "      <td>20.8</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.471352</td>\n",
       "      <td>0.672412</td>\n",
       "      <td>0.611783</td>\n",
       "      <td>0.373518</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>49</td>\n",
       "      <td>2017-09-28 22:30:00</td>\n",
       "      <td>18.5</td>\n",
       "      <td>-0.657532</td>\n",
       "      <td>-0.652232</td>\n",
       "      <td>-0.678591</td>\n",
       "      <td>-0.663188</td>\n",
       "      <td>-0.656262</td>\n",
       "      <td>-0.674955</td>\n",
       "      <td>22.3</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>0.447685</td>\n",
       "      <td>0.717756</td>\n",
       "      <td>0.830951</td>\n",
       "      <td>0.373518</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>94</td>\n",
       "      <td>2017-09-29 09:45:00</td>\n",
       "      <td>26.6</td>\n",
       "      <td>-0.236071</td>\n",
       "      <td>-0.018825</td>\n",
       "      <td>-0.146552</td>\n",
       "      <td>-0.243514</td>\n",
       "      <td>-0.025284</td>\n",
       "      <td>-0.156872</td>\n",
       "      <td>40.8</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.106382</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.252359</td>\n",
       "      <td>-0.370501</td>\n",
       "      <td>-1.031977</td>\n",
       "      <td>-0.183054</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>95</td>\n",
       "      <td>2017-09-29 10:00:00</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-0.236071</td>\n",
       "      <td>-0.134949</td>\n",
       "      <td>-0.311230</td>\n",
       "      <td>-0.243514</td>\n",
       "      <td>-0.150342</td>\n",
       "      <td>-0.311301</td>\n",
       "      <td>29.2</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.459064</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.276025</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-1.251145</td>\n",
       "      <td>-0.202246</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>96</td>\n",
       "      <td>2017-09-29 10:15:00</td>\n",
       "      <td>29.9</td>\n",
       "      <td>-0.165827</td>\n",
       "      <td>0.033959</td>\n",
       "      <td>-0.370346</td>\n",
       "      <td>-0.168349</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>-0.381043</td>\n",
       "      <td>32.3</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.331971</td>\n",
       "      <td>-0.266085</td>\n",
       "      <td>1.323359</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-1.031977</td>\n",
       "      <td>-0.221438</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>97</td>\n",
       "      <td>2017-09-29 10:30:00</td>\n",
       "      <td>30.1</td>\n",
       "      <td>-0.066315</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.218335</td>\n",
       "      <td>-0.086920</td>\n",
       "      <td>0.020192</td>\n",
       "      <td>-0.206688</td>\n",
       "      <td>27.2</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.363744</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.394360</td>\n",
       "      <td>-0.307019</td>\n",
       "      <td>-1.141561</td>\n",
       "      <td>-0.240630</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>98</td>\n",
       "      <td>2017-09-29 10:45:00</td>\n",
       "      <td>29.7</td>\n",
       "      <td>-0.253631</td>\n",
       "      <td>-0.024103</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>-0.262306</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>20.5</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.427290</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.465360</td>\n",
       "      <td>-0.343295</td>\n",
       "      <td>-1.086769</td>\n",
       "      <td>-0.240630</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>99</td>\n",
       "      <td>2017-09-29 11:00:00</td>\n",
       "      <td>27.5</td>\n",
       "      <td>-0.095583</td>\n",
       "      <td>0.134249</td>\n",
       "      <td>-0.176109</td>\n",
       "      <td>-0.099448</td>\n",
       "      <td>0.133882</td>\n",
       "      <td>-0.161853</td>\n",
       "      <td>12.3</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.536361</td>\n",
       "      <td>-0.433983</td>\n",
       "      <td>-0.977185</td>\n",
       "      <td>-0.221438</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>100</td>\n",
       "      <td>2017-09-29 11:15:00</td>\n",
       "      <td>26.4</td>\n",
       "      <td>-0.095583</td>\n",
       "      <td>0.213425</td>\n",
       "      <td>-0.150774</td>\n",
       "      <td>-0.086920</td>\n",
       "      <td>0.207780</td>\n",
       "      <td>-0.161853</td>\n",
       "      <td>16.2</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.489027</td>\n",
       "      <td>-0.397707</td>\n",
       "      <td>-1.086769</td>\n",
       "      <td>-0.221438</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>101</td>\n",
       "      <td>2017-09-29 11:30:00</td>\n",
       "      <td>26.3</td>\n",
       "      <td>-0.037047</td>\n",
       "      <td>0.313714</td>\n",
       "      <td>-0.015653</td>\n",
       "      <td>-0.024282</td>\n",
       "      <td>0.298732</td>\n",
       "      <td>-0.017388</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.192169</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.465360</td>\n",
       "      <td>-0.370501</td>\n",
       "      <td>-0.977185</td>\n",
       "      <td>-0.202246</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>102</td>\n",
       "      <td>2017-09-29 11:45:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.312168</td>\n",
       "      <td>0.055073</td>\n",
       "      <td>-0.129661</td>\n",
       "      <td>-0.299888</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>-0.131964</td>\n",
       "      <td>17.8</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.465360</td>\n",
       "      <td>-0.352363</td>\n",
       "      <td>-1.031977</td>\n",
       "      <td>-0.221438</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>103</td>\n",
       "      <td>2017-09-29 12:00:00</td>\n",
       "      <td>28.8</td>\n",
       "      <td>-0.277046</td>\n",
       "      <td>-0.177176</td>\n",
       "      <td>-0.345011</td>\n",
       "      <td>-0.268570</td>\n",
       "      <td>-0.167396</td>\n",
       "      <td>-0.341190</td>\n",
       "      <td>30.7</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.459064</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.441693</td>\n",
       "      <td>-0.370501</td>\n",
       "      <td>-1.031977</td>\n",
       "      <td>-0.202246</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>106</td>\n",
       "      <td>2017-09-29 12:45:00</td>\n",
       "      <td>24.9</td>\n",
       "      <td>-0.312168</td>\n",
       "      <td>-0.076887</td>\n",
       "      <td>-0.450574</td>\n",
       "      <td>-0.299888</td>\n",
       "      <td>-0.087813</td>\n",
       "      <td>-0.440821</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.589334</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.441693</td>\n",
       "      <td>-0.361432</td>\n",
       "      <td>-1.031977</td>\n",
       "      <td>-0.279014</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>107</td>\n",
       "      <td>2017-09-29 13:00:00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-0.470216</td>\n",
       "      <td>-0.156063</td>\n",
       "      <td>-0.302785</td>\n",
       "      <td>-0.462747</td>\n",
       "      <td>-0.161711</td>\n",
       "      <td>-0.301337</td>\n",
       "      <td>14.3</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.589334</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.441693</td>\n",
       "      <td>-0.397707</td>\n",
       "      <td>-0.922393</td>\n",
       "      <td>-0.298206</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>108</td>\n",
       "      <td>2017-09-29 13:15:00</td>\n",
       "      <td>22.5</td>\n",
       "      <td>-0.645825</td>\n",
       "      <td>-0.467488</td>\n",
       "      <td>-0.391458</td>\n",
       "      <td>-0.644396</td>\n",
       "      <td>-0.468674</td>\n",
       "      <td>-0.381043</td>\n",
       "      <td>16.1</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.560028</td>\n",
       "      <td>-0.433983</td>\n",
       "      <td>-1.141561</td>\n",
       "      <td>-0.298206</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>109</td>\n",
       "      <td>2017-09-29 13:30:00</td>\n",
       "      <td>20.9</td>\n",
       "      <td>-0.874116</td>\n",
       "      <td>-0.810584</td>\n",
       "      <td>-0.712371</td>\n",
       "      <td>-0.863628</td>\n",
       "      <td>-0.792689</td>\n",
       "      <td>-0.689900</td>\n",
       "      <td>8.9</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.867697</td>\n",
       "      <td>-0.706047</td>\n",
       "      <td>-1.086769</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>110</td>\n",
       "      <td>2017-09-29 13:45:00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-0.897531</td>\n",
       "      <td>-0.794749</td>\n",
       "      <td>-0.953055</td>\n",
       "      <td>-0.888684</td>\n",
       "      <td>-0.792689</td>\n",
       "      <td>-0.948941</td>\n",
       "      <td>11.6</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.915031</td>\n",
       "      <td>-0.987180</td>\n",
       "      <td>-0.977185</td>\n",
       "      <td>-0.298206</td>\n",
       "      <td>0.647429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>111</td>\n",
       "      <td>2017-09-29 14:00:00</td>\n",
       "      <td>17.4</td>\n",
       "      <td>-0.604849</td>\n",
       "      <td>-0.768357</td>\n",
       "      <td>-0.893940</td>\n",
       "      <td>-0.606814</td>\n",
       "      <td>-0.764267</td>\n",
       "      <td>-0.889163</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.796696</td>\n",
       "      <td>-0.932767</td>\n",
       "      <td>-0.922393</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>112</td>\n",
       "      <td>2017-09-29 14:15:00</td>\n",
       "      <td>16.4</td>\n",
       "      <td>-0.680947</td>\n",
       "      <td>-0.678624</td>\n",
       "      <td>-0.991058</td>\n",
       "      <td>-0.688243</td>\n",
       "      <td>-0.696053</td>\n",
       "      <td>-0.963886</td>\n",
       "      <td>17.2</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.557560</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.725696</td>\n",
       "      <td>-0.896492</td>\n",
       "      <td>-0.922393</td>\n",
       "      <td>-0.298206</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>113</td>\n",
       "      <td>2017-09-29 14:30:00</td>\n",
       "      <td>18.4</td>\n",
       "      <td>-0.879970</td>\n",
       "      <td>-0.546664</td>\n",
       "      <td>-0.995280</td>\n",
       "      <td>-0.876156</td>\n",
       "      <td>-0.553941</td>\n",
       "      <td>-0.983812</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.702029</td>\n",
       "      <td>-0.950905</td>\n",
       "      <td>-0.867601</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>114</td>\n",
       "      <td>2017-09-29 14:45:00</td>\n",
       "      <td>19.3</td>\n",
       "      <td>-0.774605</td>\n",
       "      <td>-0.573056</td>\n",
       "      <td>-0.868604</td>\n",
       "      <td>-0.763408</td>\n",
       "      <td>-0.582363</td>\n",
       "      <td>-0.864255</td>\n",
       "      <td>21.3</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.654695</td>\n",
       "      <td>-0.932767</td>\n",
       "      <td>-0.703225</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>115</td>\n",
       "      <td>2017-09-29 15:00:00</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-0.704361</td>\n",
       "      <td>-0.536107</td>\n",
       "      <td>-0.716593</td>\n",
       "      <td>-0.694506</td>\n",
       "      <td>-0.553941</td>\n",
       "      <td>-0.729752</td>\n",
       "      <td>18.6</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.621107</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.607362</td>\n",
       "      <td>-0.914630</td>\n",
       "      <td>-0.703225</td>\n",
       "      <td>-0.298206</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>116</td>\n",
       "      <td>2017-09-29 15:15:00</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-0.581435</td>\n",
       "      <td>-0.778913</td>\n",
       "      <td>-0.771486</td>\n",
       "      <td>-0.575495</td>\n",
       "      <td>-0.781320</td>\n",
       "      <td>-0.774587</td>\n",
       "      <td>25.7</td>\n",
       "      <td>-0.392423</td>\n",
       "      <td>-0.589334</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.536361</td>\n",
       "      <td>-0.896492</td>\n",
       "      <td>-0.648433</td>\n",
       "      <td>-0.298206</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>117</td>\n",
       "      <td>2017-09-29 15:30:00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-0.405826</td>\n",
       "      <td>-0.710294</td>\n",
       "      <td>-0.868604</td>\n",
       "      <td>-0.400109</td>\n",
       "      <td>-0.701737</td>\n",
       "      <td>-0.864255</td>\n",
       "      <td>45.4</td>\n",
       "      <td>-0.331906</td>\n",
       "      <td>0.344797</td>\n",
       "      <td>-0.209981</td>\n",
       "      <td>1.489027</td>\n",
       "      <td>-0.914630</td>\n",
       "      <td>-0.648433</td>\n",
       "      <td>-0.298206</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>118</td>\n",
       "      <td>2017-09-29 15:45:00</td>\n",
       "      <td>20.1</td>\n",
       "      <td>-0.575581</td>\n",
       "      <td>-0.414704</td>\n",
       "      <td>-0.817934</td>\n",
       "      <td>-0.575495</td>\n",
       "      <td>-0.411829</td>\n",
       "      <td>-0.814439</td>\n",
       "      <td>49.9</td>\n",
       "      <td>-0.350061</td>\n",
       "      <td>-0.071431</td>\n",
       "      <td>-0.419097</td>\n",
       "      <td>1.394360</td>\n",
       "      <td>-0.842079</td>\n",
       "      <td>-0.648433</td>\n",
       "      <td>-0.279014</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>119</td>\n",
       "      <td>2017-09-29 16:00:00</td>\n",
       "      <td>22.6</td>\n",
       "      <td>-0.692654</td>\n",
       "      <td>-0.483323</td>\n",
       "      <td>-0.649033</td>\n",
       "      <td>-0.688243</td>\n",
       "      <td>-0.497096</td>\n",
       "      <td>-0.635103</td>\n",
       "      <td>58.8</td>\n",
       "      <td>-0.271390</td>\n",
       "      <td>0.668883</td>\n",
       "      <td>-0.317089</td>\n",
       "      <td>1.299692</td>\n",
       "      <td>-0.751391</td>\n",
       "      <td>-0.648433</td>\n",
       "      <td>-0.279014</td>\n",
       "      <td>0.647429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>120</td>\n",
       "      <td>2017-09-29 16:15:00</td>\n",
       "      <td>23.9</td>\n",
       "      <td>-0.446801</td>\n",
       "      <td>-0.610005</td>\n",
       "      <td>-0.767264</td>\n",
       "      <td>-0.462747</td>\n",
       "      <td>-0.627839</td>\n",
       "      <td>-0.749679</td>\n",
       "      <td>50.4</td>\n",
       "      <td>0.097758</td>\n",
       "      <td>-0.007885</td>\n",
       "      <td>0.203151</td>\n",
       "      <td>1.252359</td>\n",
       "      <td>-0.742322</td>\n",
       "      <td>-0.703225</td>\n",
       "      <td>-0.240630</td>\n",
       "      <td>0.647429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>121</td>\n",
       "      <td>2017-09-29 16:30:00</td>\n",
       "      <td>25.7</td>\n",
       "      <td>-0.429240</td>\n",
       "      <td>-0.076887</td>\n",
       "      <td>-0.450574</td>\n",
       "      <td>-0.431428</td>\n",
       "      <td>-0.087813</td>\n",
       "      <td>-0.440821</td>\n",
       "      <td>77.2</td>\n",
       "      <td>0.466906</td>\n",
       "      <td>0.668883</td>\n",
       "      <td>0.565278</td>\n",
       "      <td>1.157691</td>\n",
       "      <td>-0.461189</td>\n",
       "      <td>-0.812809</td>\n",
       "      <td>-0.240630</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>122</td>\n",
       "      <td>2017-09-29 16:45:00</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.173684</td>\n",
       "      <td>0.355941</td>\n",
       "      <td>0.187028</td>\n",
       "      <td>0.176159</td>\n",
       "      <td>0.327154</td>\n",
       "      <td>0.186856</td>\n",
       "      <td>86.4</td>\n",
       "      <td>1.017602</td>\n",
       "      <td>1.269396</td>\n",
       "      <td>1.600657</td>\n",
       "      <td>1.063024</td>\n",
       "      <td>-0.325157</td>\n",
       "      <td>-0.812809</td>\n",
       "      <td>-0.183054</td>\n",
       "      <td>-0.150524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>123</td>\n",
       "      <td>2017-09-29 17:00:00</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.144416</td>\n",
       "      <td>0.398169</td>\n",
       "      <td>0.524831</td>\n",
       "      <td>0.144840</td>\n",
       "      <td>0.389684</td>\n",
       "      <td>0.505677</td>\n",
       "      <td>88.7</td>\n",
       "      <td>1.084170</td>\n",
       "      <td>0.506840</td>\n",
       "      <td>2.013788</td>\n",
       "      <td>0.944689</td>\n",
       "      <td>-0.216331</td>\n",
       "      <td>-0.758017</td>\n",
       "      <td>-0.144669</td>\n",
       "      <td>0.647429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>124</td>\n",
       "      <td>2017-09-29 17:15:00</td>\n",
       "      <td>31.2</td>\n",
       "      <td>-0.259485</td>\n",
       "      <td>0.334828</td>\n",
       "      <td>0.305259</td>\n",
       "      <td>-0.262306</td>\n",
       "      <td>0.349892</td>\n",
       "      <td>0.296451</td>\n",
       "      <td>87.3</td>\n",
       "      <td>1.326234</td>\n",
       "      <td>1.765057</td>\n",
       "      <td>1.804672</td>\n",
       "      <td>0.850022</td>\n",
       "      <td>-0.053093</td>\n",
       "      <td>-0.593641</td>\n",
       "      <td>-0.106285</td>\n",
       "      <td>3.041287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>125</td>\n",
       "      <td>2017-09-29 17:30:00</td>\n",
       "      <td>30.7</td>\n",
       "      <td>-0.054608</td>\n",
       "      <td>0.387612</td>\n",
       "      <td>0.305259</td>\n",
       "      <td>-0.049337</td>\n",
       "      <td>0.401053</td>\n",
       "      <td>0.281506</td>\n",
       "      <td>124.1</td>\n",
       "      <td>3.044891</td>\n",
       "      <td>2.861231</td>\n",
       "      <td>3.344989</td>\n",
       "      <td>0.708021</td>\n",
       "      <td>0.110146</td>\n",
       "      <td>-0.538849</td>\n",
       "      <td>-0.106285</td>\n",
       "      <td>7.031051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                 date  PM_ref   PM_6182   PM_6179   PM_617B  \\\n",
       "0      15  2017-09-28 14:00:00    16.2 -1.178505 -1.137844 -1.134624   \n",
       "1      16  2017-09-28 14:15:00     9.6 -1.108262 -1.085060 -1.121956   \n",
       "2      17  2017-09-28 14:30:00    10.3 -1.178505 -1.169515 -1.257077   \n",
       "3      18  2017-09-28 14:45:00     9.4 -1.137530 -1.000606 -1.206407   \n",
       "4      19  2017-09-28 15:00:00    10.7 -1.166798 -1.164236 -1.138846   \n",
       "5      20  2017-09-28 15:15:00    10.7 -1.166798 -1.201185 -1.037506   \n",
       "6      21  2017-09-28 15:30:00     9.6 -1.078994 -1.169515 -1.007948   \n",
       "7      22  2017-09-28 15:45:00    10.2 -1.032164 -1.132566 -0.995280   \n",
       "8      23  2017-09-28 16:00:00     9.8 -1.043872 -1.095617 -0.910830   \n",
       "9      24  2017-09-28 16:15:00     8.9 -1.043872 -1.042833 -1.181072   \n",
       "10     25  2017-09-28 16:30:00     9.8 -0.915092 -0.889760 -1.185294   \n",
       "11     26  2017-09-28 16:45:00    10.1 -0.920945 -0.784192 -1.029061   \n",
       "12     27  2017-09-28 17:00:00    10.7 -0.862409 -0.842254 -0.969945   \n",
       "13     28  2017-09-28 17:15:00    12.0 -0.932653 -0.778913 -0.915052   \n",
       "14     29  2017-09-28 17:30:00    12.3 -0.903385 -0.905595 -0.817934   \n",
       "15     30  2017-09-28 17:45:00    13.7 -0.967775 -0.805305 -0.843269   \n",
       "16     31  2017-09-28 18:00:00    14.3 -0.698507 -0.615283 -0.910830   \n",
       "17     32  2017-09-28 18:15:00    14.7 -0.885824 -0.662789 -0.847492   \n",
       "18     38  2017-09-28 19:45:00     9.4 -0.751190 -0.625840 -0.796821   \n",
       "19     39  2017-09-28 20:00:00    20.1 -0.827287 -0.757800 -0.813711   \n",
       "20     40  2017-09-28 20:15:00    20.0 -0.721922 -0.794749 -0.906607   \n",
       "21     41  2017-09-28 20:30:00    19.2 -0.598996 -0.757800 -0.915052   \n",
       "22     42  2017-09-28 20:45:00    17.9 -0.803873 -0.889760 -0.898162   \n",
       "23     43  2017-09-28 21:00:00    16.0 -0.757044 -0.842254 -0.733483   \n",
       "24     44  2017-09-28 21:15:00    16.0 -0.798019 -0.858089 -0.695481   \n",
       "25     45  2017-09-28 21:30:00    17.0 -0.973628 -0.873925 -0.670145   \n",
       "26     46  2017-09-28 21:45:00    18.5 -0.838995 -0.810584 -0.657478   \n",
       "27     47  2017-09-28 22:00:00    18.6 -0.838995 -0.831697 -0.678591   \n",
       "28     48  2017-09-28 22:15:00    18.8 -0.622410 -0.678624 -0.535024   \n",
       "29     49  2017-09-28 22:30:00    18.5 -0.657532 -0.652232 -0.678591   \n",
       "..    ...                  ...     ...       ...       ...       ...   \n",
       "70     94  2017-09-29 09:45:00    26.6 -0.236071 -0.018825 -0.146552   \n",
       "71     95  2017-09-29 10:00:00    29.4 -0.236071 -0.134949 -0.311230   \n",
       "72     96  2017-09-29 10:15:00    29.9 -0.165827  0.033959 -0.370346   \n",
       "73     97  2017-09-29 10:30:00    30.1 -0.066315  0.023403 -0.218335   \n",
       "74     98  2017-09-29 10:45:00    29.7 -0.253631 -0.024103  0.056130   \n",
       "75     99  2017-09-29 11:00:00    27.5 -0.095583  0.134249 -0.176109   \n",
       "76    100  2017-09-29 11:15:00    26.4 -0.095583  0.213425 -0.150774   \n",
       "77    101  2017-09-29 11:30:00    26.3 -0.037047  0.313714 -0.015653   \n",
       "78    102  2017-09-29 11:45:00    28.0 -0.312168  0.055073 -0.129661   \n",
       "79    103  2017-09-29 12:00:00    28.8 -0.277046 -0.177176 -0.345011   \n",
       "80    106  2017-09-29 12:45:00    24.9 -0.312168 -0.076887 -0.450574   \n",
       "81    107  2017-09-29 13:00:00    23.0 -0.470216 -0.156063 -0.302785   \n",
       "82    108  2017-09-29 13:15:00    22.5 -0.645825 -0.467488 -0.391458   \n",
       "83    109  2017-09-29 13:30:00    20.9 -0.874116 -0.810584 -0.712371   \n",
       "84    110  2017-09-29 13:45:00    18.9 -0.897531 -0.794749 -0.953055   \n",
       "85    111  2017-09-29 14:00:00    17.4 -0.604849 -0.768357 -0.893940   \n",
       "86    112  2017-09-29 14:15:00    16.4 -0.680947 -0.678624 -0.991058   \n",
       "87    113  2017-09-29 14:30:00    18.4 -0.879970 -0.546664 -0.995280   \n",
       "88    114  2017-09-29 14:45:00    19.3 -0.774605 -0.573056 -0.868604   \n",
       "89    115  2017-09-29 15:00:00    19.9 -0.704361 -0.536107 -0.716593   \n",
       "90    116  2017-09-29 15:15:00    19.9 -0.581435 -0.778913 -0.771486   \n",
       "91    117  2017-09-29 15:30:00    18.9 -0.405826 -0.710294 -0.868604   \n",
       "92    118  2017-09-29 15:45:00    20.1 -0.575581 -0.414704 -0.817934   \n",
       "93    119  2017-09-29 16:00:00    22.6 -0.692654 -0.483323 -0.649033   \n",
       "94    120  2017-09-29 16:15:00    23.9 -0.446801 -0.610005 -0.767264   \n",
       "95    121  2017-09-29 16:30:00    25.7 -0.429240 -0.076887 -0.450574   \n",
       "96    122  2017-09-29 16:45:00    26.4  0.173684  0.355941  0.187028   \n",
       "97    123  2017-09-29 17:00:00    29.3  0.144416  0.398169  0.524831   \n",
       "98    124  2017-09-29 17:15:00    31.2 -0.259485  0.334828  0.305259   \n",
       "99    125  2017-09-29 17:30:00    30.7 -0.054608  0.387612  0.305259   \n",
       "\n",
       "    PM25_6182  PM25_6179  PM25_617B  NO2_ref  NO2_61FD  NO2_61F0  NO2_61EF  \\\n",
       "0   -1.183081  -1.128074  -1.148204     10.1 -0.392423 -0.621107 -0.419097   \n",
       "1   -1.101652  -1.071229  -1.128278      9.9 -0.392423 -0.621107 -0.419097   \n",
       "2   -1.176817  -1.167865  -1.252817     16.1 -0.392423 -0.621107 -0.419097   \n",
       "3   -1.139235  -1.008700  -1.222928     10.9 -0.392423 -0.621107 -0.419097   \n",
       "4   -1.164290  -1.167865  -1.148204     16.0 -0.392423 -0.621107 -0.419097   \n",
       "5   -1.158026  -1.196288  -1.038610      9.7 -0.392423 -0.621107 -0.419097   \n",
       "6   -1.070333  -1.162181  -0.998757     10.0 -0.392423 -0.621107 -0.419097   \n",
       "7   -1.032750  -1.122389  -0.988794     19.1 -0.392423 -0.621107 -0.419097   \n",
       "8   -1.039014  -1.093967  -0.919052     15.0 -0.392423 -0.621107 -0.419097   \n",
       "9   -1.039014  -1.037122  -1.173112     19.4 -0.392423 -0.621107 -0.419097   \n",
       "10  -0.913739  -0.889325  -1.178094     20.6 -0.392423 -0.621107 -0.419097   \n",
       "11  -0.926266  -0.787005  -1.013702     17.3 -0.392423 -0.576624 -0.419097   \n",
       "12  -0.869892  -0.843850  -0.963886     16.3 -0.392423 -0.621107 -0.419097   \n",
       "13  -0.932530  -0.775636  -0.914070     16.4 -0.392423 -0.621107 -0.419097   \n",
       "14  -0.901211  -0.900694  -0.814439     22.0 -0.392423 -0.621107 -0.419097   \n",
       "15  -0.963849  -0.804058  -0.844329     28.2 -0.392423 -0.525787 -0.419097   \n",
       "16  -0.688243  -0.616470  -0.904107     27.1 -0.392423 -0.589334 -0.419097   \n",
       "17  -0.876156  -0.667631  -0.839347     21.9 -0.392423 -0.589334 -0.419097   \n",
       "18  -0.744617  -0.616470  -0.794513     32.4 -0.392423 -0.363744 -0.419097   \n",
       "19  -0.826046  -0.741529  -0.819421     37.0 -0.392423 -0.427290 -0.419097   \n",
       "20  -0.725825  -0.787005  -0.889163     27.5 -0.392423 -0.576624 -0.419097   \n",
       "21  -0.600550  -0.752898  -0.914070     25.6 -0.392423 -0.589334 -0.419097   \n",
       "22  -0.807254  -0.895010  -0.899126     27.3 -0.392423 -0.621107 -0.419097   \n",
       "23  -0.750880  -0.838165  -0.729752     26.3 -0.392423 -0.589334 -0.419097   \n",
       "24  -0.788463  -0.860903  -0.684918     27.0 -0.392423 -0.621107 -0.419097   \n",
       "25  -0.963849  -0.872272  -0.655029     25.7 -0.392423 -0.621107 -0.419097   \n",
       "26  -0.832310  -0.809743  -0.660010     23.2 -0.392423 -0.621107 -0.419097   \n",
       "27  -0.838573  -0.821112  -0.674955     21.2 -0.392423 -0.621107 -0.419097   \n",
       "28  -0.619341  -0.684684  -0.540453     20.8 -0.392423 -0.621107 -0.419097   \n",
       "29  -0.663188  -0.656262  -0.674955     22.3 -0.392423 -0.621107 -0.419097   \n",
       "..        ...        ...        ...      ...       ...       ...       ...   \n",
       "70  -0.243514  -0.025284  -0.156872     40.8 -0.392423 -0.106382 -0.419097   \n",
       "71  -0.243514  -0.150342  -0.311301     29.2 -0.392423 -0.459064 -0.419097   \n",
       "72  -0.168349   0.014508  -0.381043     32.3 -0.392423 -0.331971 -0.266085   \n",
       "73  -0.086920   0.020192  -0.206688     27.2 -0.392423 -0.363744 -0.419097   \n",
       "74  -0.262306  -0.002546   0.062317     20.5 -0.392423 -0.427290 -0.419097   \n",
       "75  -0.099448   0.133882  -0.161853     12.3 -0.392423 -0.621107 -0.419097   \n",
       "76  -0.086920   0.207780  -0.161853     16.2 -0.392423 -0.621107 -0.419097   \n",
       "77  -0.024282   0.298732  -0.017388     32.0 -0.392423 -0.192169 -0.419097   \n",
       "78  -0.299888   0.054299  -0.131964     17.8 -0.392423 -0.621107 -0.419097   \n",
       "79  -0.268570  -0.167396  -0.341190     30.7 -0.392423 -0.459064 -0.419097   \n",
       "80  -0.299888  -0.087813  -0.440821     21.3 -0.392423 -0.589334 -0.419097   \n",
       "81  -0.462747  -0.161711  -0.301337     14.3 -0.392423 -0.589334 -0.419097   \n",
       "82  -0.644396  -0.468674  -0.381043     16.1 -0.392423 -0.621107 -0.419097   \n",
       "83  -0.863628  -0.792689  -0.689900      8.9 -0.392423 -0.621107 -0.419097   \n",
       "84  -0.888684  -0.792689  -0.948941     11.6 -0.392423 -0.621107 -0.419097   \n",
       "85  -0.606814  -0.764267  -0.889163     13.5 -0.392423 -0.621107 -0.419097   \n",
       "86  -0.688243  -0.696053  -0.963886     17.2 -0.392423 -0.557560 -0.419097   \n",
       "87  -0.876156  -0.553941  -0.983812     12.2 -0.392423 -0.621107 -0.419097   \n",
       "88  -0.763408  -0.582363  -0.864255     21.3 -0.392423 -0.621107 -0.419097   \n",
       "89  -0.694506  -0.553941  -0.729752     18.6 -0.392423 -0.621107 -0.419097   \n",
       "90  -0.575495  -0.781320  -0.774587     25.7 -0.392423 -0.589334 -0.419097   \n",
       "91  -0.400109  -0.701737  -0.864255     45.4 -0.331906  0.344797 -0.209981   \n",
       "92  -0.575495  -0.411829  -0.814439     49.9 -0.350061 -0.071431 -0.419097   \n",
       "93  -0.688243  -0.497096  -0.635103     58.8 -0.271390  0.668883 -0.317089   \n",
       "94  -0.462747  -0.627839  -0.749679     50.4  0.097758 -0.007885  0.203151   \n",
       "95  -0.431428  -0.087813  -0.440821     77.2  0.466906  0.668883  0.565278   \n",
       "96   0.176159   0.327154   0.186856     86.4  1.017602  1.269396  1.600657   \n",
       "97   0.144840   0.389684   0.505677     88.7  1.084170  0.506840  2.013788   \n",
       "98  -0.262306   0.349892   0.296451     87.3  1.326234  1.765057  1.804672   \n",
       "99  -0.049337   0.401053   0.281506    124.1  3.044891  2.861231  3.344989   \n",
       "\n",
       "        temp        rh     tgrad  pressure    pluvio  \n",
       "0   1.986031 -1.114144 -0.922393  0.315942 -0.150524  \n",
       "1   2.057032 -1.123212 -0.977185  0.335134 -0.150524  \n",
       "2   2.080699 -1.232038 -1.086769  0.315942 -0.150524  \n",
       "3   2.009698 -1.259245 -0.812809  0.315942 -0.150524  \n",
       "4   1.867697 -1.141350 -0.922393  0.315942 -0.150524  \n",
       "5   1.749363 -1.050662 -0.867601  0.315942 -0.150524  \n",
       "6   1.654695 -0.959974 -0.812809  0.315942 -0.150524  \n",
       "7   1.583695 -0.887423 -0.758017  0.315942 -0.150524  \n",
       "8   1.536361 -0.851148 -0.758017  0.315942 -0.150524  \n",
       "9   1.489027 -0.851148 -0.703225  0.335134 -0.150524  \n",
       "10  1.441693 -0.805804 -0.648433  0.315942 -0.150524  \n",
       "11  1.370693 -0.715116 -0.648433  0.315942 -0.150524  \n",
       "12  1.299692 -0.642565 -0.648433  0.335134 -0.150524  \n",
       "13  1.228692 -0.506533 -0.593641  0.335134 -0.150524  \n",
       "14  1.134024 -0.397707 -0.538849  0.354326 -0.150524  \n",
       "15  1.063024 -0.288882 -0.429265  0.354326 -0.150524  \n",
       "16  0.992023 -0.189125 -0.319681  0.373518 -0.150524  \n",
       "17  0.921022 -0.044024 -0.264889  0.392710 -0.150524  \n",
       "18  0.613353  0.382210  0.009071  0.431095 -0.150524  \n",
       "19  0.566019  0.427554 -0.155305  0.431095 -0.150524  \n",
       "20  0.518686  0.509174  0.009071  0.431095 -0.150524  \n",
       "21  0.495019  0.554518  0.063863  0.431095 -0.150524  \n",
       "22  0.495019  0.581724  0.173447  0.431095 -0.150524  \n",
       "23  0.471352  0.581724  0.118655  0.431095 -0.150524  \n",
       "24  0.471352  0.636137  0.009071  0.411902 -0.150524  \n",
       "25  0.447685  0.672412  0.173447  0.392710 -0.150524  \n",
       "26  0.447685  0.672412  0.118655  0.392710 -0.150524  \n",
       "27  0.471352  0.672412  0.228239  0.392710 -0.150524  \n",
       "28  0.471352  0.672412  0.611783  0.373518 -0.150524  \n",
       "29  0.447685  0.717756  0.830951  0.373518 -0.150524  \n",
       "..       ...       ...       ...       ...       ...  \n",
       "70  1.252359 -0.370501 -1.031977 -0.183054 -0.150524  \n",
       "71  1.276025 -0.352363 -1.251145 -0.202246 -0.150524  \n",
       "72  1.323359 -0.352363 -1.031977 -0.221438 -0.150524  \n",
       "73  1.394360 -0.307019 -1.141561 -0.240630 -0.150524  \n",
       "74  1.465360 -0.343295 -1.086769 -0.240630 -0.150524  \n",
       "75  1.536361 -0.433983 -0.977185 -0.221438 -0.150524  \n",
       "76  1.489027 -0.397707 -1.086769 -0.221438 -0.150524  \n",
       "77  1.465360 -0.370501 -0.977185 -0.202246 -0.150524  \n",
       "78  1.465360 -0.352363 -1.031977 -0.221438 -0.150524  \n",
       "79  1.441693 -0.370501 -1.031977 -0.202246 -0.150524  \n",
       "80  1.441693 -0.361432 -1.031977 -0.279014 -0.150524  \n",
       "81  1.441693 -0.397707 -0.922393 -0.298206 -0.150524  \n",
       "82  1.560028 -0.433983 -1.141561 -0.298206 -0.150524  \n",
       "83  1.867697 -0.706047 -1.086769 -0.317398 -0.150524  \n",
       "84  1.915031 -0.987180 -0.977185 -0.298206  0.647429  \n",
       "85  1.796696 -0.932767 -0.922393 -0.317398 -0.150524  \n",
       "86  1.725696 -0.896492 -0.922393 -0.298206 -0.150524  \n",
       "87  1.702029 -0.950905 -0.867601 -0.317398 -0.150524  \n",
       "88  1.654695 -0.932767 -0.703225 -0.317398 -0.150524  \n",
       "89  1.607362 -0.914630 -0.703225 -0.298206 -0.150524  \n",
       "90  1.536361 -0.896492 -0.648433 -0.298206 -0.150524  \n",
       "91  1.489027 -0.914630 -0.648433 -0.298206 -0.150524  \n",
       "92  1.394360 -0.842079 -0.648433 -0.279014 -0.150524  \n",
       "93  1.299692 -0.751391 -0.648433 -0.279014  0.647429  \n",
       "94  1.252359 -0.742322 -0.703225 -0.240630  0.647429  \n",
       "95  1.157691 -0.461189 -0.812809 -0.240630 -0.150524  \n",
       "96  1.063024 -0.325157 -0.812809 -0.183054 -0.150524  \n",
       "97  0.944689 -0.216331 -0.758017 -0.144669  0.647429  \n",
       "98  0.850022 -0.053093 -0.593641 -0.106285  3.041287  \n",
       "99  0.708021  0.110146 -0.538849 -0.106285  7.031051  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/micro_sud3_normalized.pkl')\n",
    "df = df.reset_index()\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['date', 'PM_ref', 'PM_6182', 'PM_6179','PM_617B', 'PM25_6182', 'PM25_617B', 'PM25_6179',\\\n",
    "         'temp', 'rh', 'tgrad', 'pressure', 'pluvio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premier modèle: simple DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def baseline_model(dense_size, input_dim, loss='mean_squared_error', optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_size, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "def split_dataframe(dataframe, percent):\n",
    "    nb_rows = int(np.floor(percent * len(dataframe)))\n",
    "    return dataframe[:nb_rows], dataframe[nb_rows:]\n",
    "\n",
    "def dataframe_to_xy(df):\n",
    "    return (np.array(df[['PM_6182', 'PM_6179', 'PM_617B', 'PM25_6182', 'PM25_6179',\\\n",
    "                         'PM25_617B', 'temp', 'rh',\\\n",
    "                         'tgrad', 'pressure', 'pluvio']]),\\\n",
    "            np.array(df['PM_ref']))\n",
    "\n",
    "df_train, df_test = split_dataframe(df, 0.5) \n",
    "df_valid, df_test = split_dataframe(df_test, 0.5)\n",
    "\n",
    "X_train, y_train = dataframe_to_xy(df_train)\n",
    "X_valid, y_valid = dataframe_to_xy(df_valid)\n",
    "X_test, y_test = dataframe_to_xy(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f474c973fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTgghG4GCTgghG+H/A6ZndiqG2byyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f474a8f1f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQshGoKATQshGoKATQshG+P9kKPs2Zpn4sAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f474a84f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_train, '+r')\n",
    "plt.show()\n",
    "plt.plot(y_valid, '+r')\n",
    "plt.show()\n",
    "plt.plot(y_test, '+r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 417\n",
      "Trainable params: 417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1126 samples, validate on 563 samples\n",
      "Epoch 1/5000\n",
      "1126/1126 [==============================] - 0s 262us/step - loss: 527.4402 - val_loss: 513.2259\n",
      "Epoch 2/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 461.5309 - val_loss: 448.2731\n",
      "Epoch 3/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 400.5792 - val_loss: 392.1457\n",
      "Epoch 4/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 349.6647 - val_loss: 345.8717\n",
      "Epoch 5/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 308.0765 - val_loss: 309.8257\n",
      "Epoch 6/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 275.8596 - val_loss: 280.4256\n",
      "Epoch 7/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 249.9989 - val_loss: 257.7933\n",
      "Epoch 8/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 230.3253 - val_loss: 240.2919\n",
      "Epoch 9/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 215.1143 - val_loss: 226.3967\n",
      "Epoch 10/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 196.135 - 0s 33us/step - loss: 203.1239 - val_loss: 215.1447\n",
      "Epoch 11/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 193.4607 - val_loss: 206.0281\n",
      "Epoch 12/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 185.5446 - val_loss: 198.6191\n",
      "Epoch 13/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 179.1019 - val_loss: 192.0933\n",
      "Epoch 14/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 173.4299 - val_loss: 186.3004\n",
      "Epoch 15/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 168.4249 - val_loss: 181.1643\n",
      "Epoch 16/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 163.9689 - val_loss: 176.5005\n",
      "Epoch 17/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 159.9577 - val_loss: 172.2354\n",
      "Epoch 18/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 156.2833 - val_loss: 168.3646\n",
      "Epoch 19/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 152.8317 - val_loss: 164.6816\n",
      "Epoch 20/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 149.5570 - val_loss: 161.1951\n",
      "Epoch 21/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 146.5275 - val_loss: 157.8458\n",
      "Epoch 22/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 143.6153 - val_loss: 154.6545\n",
      "Epoch 23/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 140.8505 - val_loss: 151.6067\n",
      "Epoch 24/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 138.1263 - val_loss: 148.5344\n",
      "Epoch 25/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 135.5201 - val_loss: 145.7432\n",
      "Epoch 26/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 133.1047 - val_loss: 143.0882\n",
      "Epoch 27/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 130.7502 - val_loss: 140.6646\n",
      "Epoch 28/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 128.5615 - val_loss: 138.2804\n",
      "Epoch 29/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 126.4496 - val_loss: 136.0490\n",
      "Epoch 30/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 124.4956 - val_loss: 133.9116\n",
      "Epoch 31/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 122.5105 - val_loss: 131.9082\n",
      "Epoch 32/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 120.7281 - val_loss: 129.9197\n",
      "Epoch 33/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 118.9884 - val_loss: 128.0374\n",
      "Epoch 34/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 117.2727 - val_loss: 126.2553\n",
      "Epoch 35/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 115.6895 - val_loss: 124.5200\n",
      "Epoch 36/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 114.1142 - val_loss: 122.7508\n",
      "Epoch 37/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 112.6000 - val_loss: 121.1985\n",
      "Epoch 38/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 111.1769 - val_loss: 119.6315\n",
      "Epoch 39/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 109.7421 - val_loss: 118.1100\n",
      "Epoch 40/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 108.3801 - val_loss: 116.6713\n",
      "Epoch 41/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 107.0314 - val_loss: 115.3273\n",
      "Epoch 42/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 105.7681 - val_loss: 113.9696\n",
      "Epoch 43/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 104.5265 - val_loss: 112.6804\n",
      "Epoch 44/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 103.3603 - val_loss: 111.4953\n",
      "Epoch 45/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 102.2487 - val_loss: 110.3701\n",
      "Epoch 46/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 101.2149 - val_loss: 109.2361\n",
      "Epoch 47/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 100.1865 - val_loss: 108.2451\n",
      "Epoch 48/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 99.2211 - val_loss: 107.2490\n",
      "Epoch 49/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 98.2735 - val_loss: 106.3196\n",
      "Epoch 50/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 97.3852 - val_loss: 105.3681\n",
      "Epoch 51/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 96.5166 - val_loss: 104.4482\n",
      "Epoch 52/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 95.6524 - val_loss: 103.5663\n",
      "Epoch 53/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 94.8469 - val_loss: 102.7079\n",
      "Epoch 54/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 94.0544 - val_loss: 101.8534\n",
      "Epoch 55/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 93.3220 - val_loss: 101.0589\n",
      "Epoch 56/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 92.5588 - val_loss: 100.3033\n",
      "Epoch 57/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 91.8356 - val_loss: 99.5367\n",
      "Epoch 58/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 91.1511 - val_loss: 98.8605\n",
      "Epoch 59/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 90.4660 - val_loss: 98.1321\n",
      "Epoch 60/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 89.7799 - val_loss: 97.4614\n",
      "Epoch 61/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 89.1378 - val_loss: 96.7888\n",
      "Epoch 62/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 88.5098 - val_loss: 96.1277\n",
      "Epoch 63/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 87.9065 - val_loss: 95.5429\n",
      "Epoch 64/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 87.3361 - val_loss: 94.9828\n",
      "Epoch 65/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 86.7788 - val_loss: 94.3907\n",
      "Epoch 66/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 86.2325 - val_loss: 93.8064\n",
      "Epoch 67/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 85.6819 - val_loss: 93.3031\n",
      "Epoch 68/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 85.1677 - val_loss: 92.8110\n",
      "Epoch 69/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 84.6677 - val_loss: 92.2682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 84.1482 - val_loss: 91.7712\n",
      "Epoch 71/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 83.6708 - val_loss: 91.2975\n",
      "Epoch 72/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 83.2044 - val_loss: 90.8417\n",
      "Epoch 73/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 82.7498 - val_loss: 90.3782\n",
      "Epoch 74/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 82.2896 - val_loss: 89.9495\n",
      "Epoch 75/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 81.8527 - val_loss: 89.4981\n",
      "Epoch 76/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 81.3994 - val_loss: 89.0548\n",
      "Epoch 77/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 80.9737 - val_loss: 88.6151\n",
      "Epoch 78/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 80.5410 - val_loss: 88.3638\n",
      "Epoch 79/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 80.1380 - val_loss: 87.9030\n",
      "Epoch 80/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 79.7233 - val_loss: 87.4824\n",
      "Epoch 81/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 79.3303 - val_loss: 87.0769\n",
      "Epoch 82/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 78.9262 - val_loss: 86.6798\n",
      "Epoch 83/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 78.5420 - val_loss: 86.2587\n",
      "Epoch 84/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 78.1553 - val_loss: 85.8625\n",
      "Epoch 85/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 77.7721 - val_loss: 85.4717\n",
      "Epoch 86/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 77.4093 - val_loss: 85.1703\n",
      "Epoch 87/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 77.0705 - val_loss: 84.7784\n",
      "Epoch 88/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 76.7083 - val_loss: 84.3980\n",
      "Epoch 89/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 76.3553 - val_loss: 84.0516\n",
      "Epoch 90/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 76.0173 - val_loss: 83.7204\n",
      "Epoch 91/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 75.6787 - val_loss: 83.3934\n",
      "Epoch 92/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 75.3459 - val_loss: 83.1151\n",
      "Epoch 93/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 75.0382 - val_loss: 82.7907\n",
      "Epoch 94/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 74.7254 - val_loss: 82.5627\n",
      "Epoch 95/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 74.4141 - val_loss: 82.2579\n",
      "Epoch 96/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 74.1098 - val_loss: 81.9223\n",
      "Epoch 97/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 73.7823 - val_loss: 81.6409\n",
      "Epoch 98/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 73.4710 - val_loss: 81.3275\n",
      "Epoch 99/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 73.1606 - val_loss: 81.0505\n",
      "Epoch 100/5000\n",
      "1126/1126 [==============================] - 0s 44us/step - loss: 72.8773 - val_loss: 80.8198\n",
      "Epoch 101/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 72.6013 - val_loss: 80.5425\n",
      "Epoch 102/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 56.69 - 0s 32us/step - loss: 72.3053 - val_loss: 80.2748\n",
      "Epoch 103/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 72.0093 - val_loss: 80.0082\n",
      "Epoch 104/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 71.7283 - val_loss: 79.7440\n",
      "Epoch 105/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 71.4469 - val_loss: 79.4899\n",
      "Epoch 106/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 71.1520 - val_loss: 79.2544\n",
      "Epoch 107/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 70.8672 - val_loss: 79.0517\n",
      "Epoch 108/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 70.6065 - val_loss: 78.8299\n",
      "Epoch 109/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 70.3303 - val_loss: 78.6466\n",
      "Epoch 110/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 70.0883 - val_loss: 78.3673\n",
      "Epoch 111/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 69.8240 - val_loss: 78.1213\n",
      "Epoch 112/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 69.5718 - val_loss: 77.9389\n",
      "Epoch 113/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 69.3107 - val_loss: 77.7318\n",
      "Epoch 114/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 69.0755 - val_loss: 77.5324\n",
      "Epoch 115/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 68.8373 - val_loss: 77.3225\n",
      "Epoch 116/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 68.5984 - val_loss: 77.0986\n",
      "Epoch 117/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 68.3539 - val_loss: 76.9215\n",
      "Epoch 118/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 68.1261 - val_loss: 76.7241\n",
      "Epoch 119/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 67.9069 - val_loss: 76.5296\n",
      "Epoch 120/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 67.7002 - val_loss: 76.3490\n",
      "Epoch 121/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 67.4885 - val_loss: 76.2267\n",
      "Epoch 122/5000\n",
      "1126/1126 [==============================] - 0s 43us/step - loss: 67.2747 - val_loss: 76.1217\n",
      "Epoch 123/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 67.0906 - val_loss: 75.9371\n",
      "Epoch 124/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 66.8759 - val_loss: 75.7831\n",
      "Epoch 125/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 66.7044 - val_loss: 75.5509\n",
      "Epoch 126/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 66.5005 - val_loss: 75.4312\n",
      "Epoch 127/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 66.3221 - val_loss: 75.2971\n",
      "Epoch 128/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 66.1529 - val_loss: 75.1478\n",
      "Epoch 129/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 65.9874 - val_loss: 75.0182\n",
      "Epoch 130/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 65.8276 - val_loss: 74.8778\n",
      "Epoch 131/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 65.6663 - val_loss: 74.7496\n",
      "Epoch 132/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 65.5088 - val_loss: 74.5997\n",
      "Epoch 133/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 65.3472 - val_loss: 74.4517\n",
      "Epoch 134/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 65.1885 - val_loss: 74.3836\n",
      "Epoch 135/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 65.0286 - val_loss: 74.2743\n",
      "Epoch 136/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 64.8783 - val_loss: 74.1400\n",
      "Epoch 137/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 64.7308 - val_loss: 74.0243\n",
      "Epoch 138/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 64.5871 - val_loss: 73.9262\n",
      "Epoch 139/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 64.4608 - val_loss: 73.7911\n",
      "Epoch 140/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 64.3295 - val_loss: 73.6937\n",
      "Epoch 141/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 64.2086 - val_loss: 73.6301\n",
      "Epoch 142/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 64.0651 - val_loss: 73.5346\n",
      "Epoch 143/5000\n",
      "1126/1126 [==============================] - 0s 50us/step - loss: 63.9463 - val_loss: 73.4593\n",
      "Epoch 144/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 63.8236 - val_loss: 73.4060\n",
      "Epoch 145/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 40us/step - loss: 63.7122 - val_loss: 73.3357\n",
      "Epoch 146/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 63.5863 - val_loss: 73.2337\n",
      "Epoch 147/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 63.4743 - val_loss: 73.1290\n",
      "Epoch 148/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 63.3622 - val_loss: 73.0730\n",
      "Epoch 149/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 63.2562 - val_loss: 73.0339\n",
      "Epoch 150/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 63.1675 - val_loss: 72.9498\n",
      "Epoch 151/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 63.0621 - val_loss: 72.8668\n",
      "Epoch 152/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 62.9500 - val_loss: 72.8115\n",
      "Epoch 153/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 62.8613 - val_loss: 72.8054\n",
      "Epoch 154/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 62.7534 - val_loss: 72.7491\n",
      "Epoch 155/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 62.6603 - val_loss: 72.6690\n",
      "Epoch 156/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 62.5648 - val_loss: 72.5438\n",
      "Epoch 157/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 62.4612 - val_loss: 72.4618\n",
      "Epoch 158/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 62.3664 - val_loss: 72.3982\n",
      "Epoch 159/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 62.2860 - val_loss: 72.3366\n",
      "Epoch 160/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 62.2000 - val_loss: 72.2585\n",
      "Epoch 161/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 62.1107 - val_loss: 72.2105\n",
      "Epoch 162/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 62.0321 - val_loss: 72.1470\n",
      "Epoch 163/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 61.9427 - val_loss: 72.0700\n",
      "Epoch 164/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 61.8659 - val_loss: 72.0535\n",
      "Epoch 165/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 61.7831 - val_loss: 72.0215\n",
      "Epoch 166/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 61.6980 - val_loss: 71.9909\n",
      "Epoch 167/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 61.6274 - val_loss: 71.9195\n",
      "Epoch 168/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 61.5465 - val_loss: 71.8499\n",
      "Epoch 169/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 61.4807 - val_loss: 71.8038\n",
      "Epoch 170/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 61.4099 - val_loss: 71.7637\n",
      "Epoch 171/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 61.3259 - val_loss: 71.7166\n",
      "Epoch 172/5000\n",
      "1126/1126 [==============================] - 0s 46us/step - loss: 61.2545 - val_loss: 71.6778\n",
      "Epoch 173/5000\n",
      "1126/1126 [==============================] - 0s 42us/step - loss: 61.1906 - val_loss: 71.6212\n",
      "Epoch 174/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 61.1095 - val_loss: 71.5825\n",
      "Epoch 175/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 61.0329 - val_loss: 71.5553\n",
      "Epoch 176/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 60.9736 - val_loss: 71.5333\n",
      "Epoch 177/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 60.9133 - val_loss: 71.4459\n",
      "Epoch 178/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 60.8362 - val_loss: 71.4351\n",
      "Epoch 179/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 60.7619 - val_loss: 71.3963\n",
      "Epoch 180/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 60.7054 - val_loss: 71.3608\n",
      "Epoch 181/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 60.6349 - val_loss: 71.3077\n",
      "Epoch 182/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 60.5682 - val_loss: 71.2710\n",
      "Epoch 183/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 60.5000 - val_loss: 71.2258\n",
      "Epoch 184/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 60.4325 - val_loss: 71.1625\n",
      "Epoch 185/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 60.3702 - val_loss: 71.1146\n",
      "Epoch 186/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 60.3008 - val_loss: 71.0691\n",
      "Epoch 187/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 60.2426 - val_loss: 71.0400\n",
      "Epoch 188/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 60.1704 - val_loss: 71.0050\n",
      "Epoch 189/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 60.1052 - val_loss: 70.9839\n",
      "Epoch 190/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 60.0471 - val_loss: 70.9371\n",
      "Epoch 191/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 59.9930 - val_loss: 70.8882\n",
      "Epoch 192/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 59.9279 - val_loss: 70.8542\n",
      "Epoch 193/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 59.8726 - val_loss: 70.8313\n",
      "Epoch 194/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 59.8253 - val_loss: 70.7845\n",
      "Epoch 195/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 59.7585 - val_loss: 70.7484\n",
      "Epoch 196/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 59.6974 - val_loss: 70.7267\n",
      "Epoch 197/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 59.6445 - val_loss: 70.6996\n",
      "Epoch 198/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 37.20 - 0s 36us/step - loss: 59.5844 - val_loss: 70.6572\n",
      "Epoch 199/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 59.5272 - val_loss: 70.6193\n",
      "Epoch 200/5000\n",
      "1126/1126 [==============================] - 0s 46us/step - loss: 59.4736 - val_loss: 70.5645\n",
      "Epoch 201/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 59.4200 - val_loss: 70.5091\n",
      "Epoch 202/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 59.3575 - val_loss: 70.4544\n",
      "Epoch 203/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 59.3025 - val_loss: 70.4323\n",
      "Epoch 204/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 59.2467 - val_loss: 70.4124\n",
      "Epoch 205/5000\n",
      "1126/1126 [==============================] - 0s 43us/step - loss: 59.2022 - val_loss: 70.3927\n",
      "Epoch 206/5000\n",
      "1126/1126 [==============================] - 0s 45us/step - loss: 59.1500 - val_loss: 70.3286\n",
      "Epoch 207/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 59.0891 - val_loss: 70.2784\n",
      "Epoch 208/5000\n",
      "1126/1126 [==============================] - 0s 43us/step - loss: 59.0389 - val_loss: 70.2267\n",
      "Epoch 209/5000\n",
      "1126/1126 [==============================] - 0s 73us/step - loss: 58.9879 - val_loss: 70.1619\n",
      "Epoch 210/5000\n",
      "1126/1126 [==============================] - 0s 42us/step - loss: 58.9336 - val_loss: 70.1350\n",
      "Epoch 211/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 58.8835 - val_loss: 70.0635\n",
      "Epoch 212/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 58.8290 - val_loss: 70.0277\n",
      "Epoch 213/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 58.7837 - val_loss: 69.9943\n",
      "Epoch 214/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 58.7331 - val_loss: 69.9565\n",
      "Epoch 215/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 58.6790 - val_loss: 69.8981\n",
      "Epoch 216/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 58.6355 - val_loss: 69.8661\n",
      "Epoch 217/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 58.5789 - val_loss: 69.8476\n",
      "Epoch 218/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 58.5399 - val_loss: 69.8037\n",
      "Epoch 219/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 58.4818 - val_loss: 69.7944\n",
      "Epoch 220/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 34us/step - loss: 58.4381 - val_loss: 69.7691\n",
      "Epoch 221/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 58.3873 - val_loss: 69.7301\n",
      "Epoch 222/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 58.3372 - val_loss: 69.6899\n",
      "Epoch 223/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 58.2979 - val_loss: 69.6684\n",
      "Epoch 224/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 58.2465 - val_loss: 69.6169\n",
      "Epoch 225/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 58.1976 - val_loss: 69.5917\n",
      "Epoch 226/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 58.1549 - val_loss: 69.5595\n",
      "Epoch 227/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 58.1204 - val_loss: 69.5440\n",
      "Epoch 228/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 58.0651 - val_loss: 69.5287\n",
      "Epoch 229/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 58.0207 - val_loss: 69.5179\n",
      "Epoch 230/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 57.9752 - val_loss: 69.4722\n",
      "Epoch 231/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 57.9369 - val_loss: 69.4461\n",
      "Epoch 232/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 57.8902 - val_loss: 69.3974\n",
      "Epoch 233/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 57.8507 - val_loss: 69.3687\n",
      "Epoch 234/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 57.8048 - val_loss: 69.3820\n",
      "Epoch 235/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 57.7656 - val_loss: 69.3442\n",
      "Epoch 236/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 57.7235 - val_loss: 69.2938\n",
      "Epoch 237/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 57.6856 - val_loss: 69.2683\n",
      "Epoch 238/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 57.6361 - val_loss: 69.2338\n",
      "Epoch 239/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 57.5944 - val_loss: 69.1975\n",
      "Epoch 240/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 57.5531 - val_loss: 69.1615\n",
      "Epoch 241/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 57.5224 - val_loss: 69.1506\n",
      "Epoch 242/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 57.4792 - val_loss: 69.1215\n",
      "Epoch 243/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 57.4441 - val_loss: 69.0850\n",
      "Epoch 244/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 57.4036 - val_loss: 69.0569\n",
      "Epoch 245/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 57.3614 - val_loss: 69.0310\n",
      "Epoch 246/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 57.3268 - val_loss: 68.9988\n",
      "Epoch 247/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 57.2840 - val_loss: 68.9736\n",
      "Epoch 248/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 57.2427 - val_loss: 68.9410\n",
      "Epoch 249/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 57.2098 - val_loss: 68.9112\n",
      "Epoch 250/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 57.1842 - val_loss: 68.8703\n",
      "Epoch 251/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 57.1338 - val_loss: 68.8318\n",
      "Epoch 252/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 57.0905 - val_loss: 68.8402\n",
      "Epoch 253/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 57.0581 - val_loss: 68.8163\n",
      "Epoch 254/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 57.0206 - val_loss: 68.7952\n",
      "Epoch 255/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 56.9946 - val_loss: 68.7658\n",
      "Epoch 256/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 56.9558 - val_loss: 68.7458\n",
      "Epoch 257/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 56.9095 - val_loss: 68.7597\n",
      "Epoch 258/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 56.8831 - val_loss: 68.7238\n",
      "Epoch 259/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 56.8466 - val_loss: 68.6871\n",
      "Epoch 260/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 56.8086 - val_loss: 68.6552\n",
      "Epoch 261/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.7750 - val_loss: 68.6183\n",
      "Epoch 262/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 56.7341 - val_loss: 68.6065\n",
      "Epoch 263/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 56.7068 - val_loss: 68.5709\n",
      "Epoch 264/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 56.6759 - val_loss: 68.5338\n",
      "Epoch 265/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 56.6372 - val_loss: 68.4962\n",
      "Epoch 266/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 56.6089 - val_loss: 68.4763\n",
      "Epoch 267/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.5738 - val_loss: 68.4388\n",
      "Epoch 268/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 56.5412 - val_loss: 68.4119\n",
      "Epoch 269/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.5026 - val_loss: 68.3764\n",
      "Epoch 270/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 56.4692 - val_loss: 68.3326\n",
      "Epoch 271/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 56.4361 - val_loss: 68.3065\n",
      "Epoch 272/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 56.4034 - val_loss: 68.2740\n",
      "Epoch 273/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 56.3640 - val_loss: 68.2839\n",
      "Epoch 274/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 56.3385 - val_loss: 68.2663\n",
      "Epoch 275/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 56.3059 - val_loss: 68.2297\n",
      "Epoch 276/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 56.2756 - val_loss: 68.2077\n",
      "Epoch 277/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 56.2431 - val_loss: 68.1746\n",
      "Epoch 278/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 56.2064 - val_loss: 68.1435\n",
      "Epoch 279/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 56.1800 - val_loss: 68.1091\n",
      "Epoch 280/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 56.1486 - val_loss: 68.0926\n",
      "Epoch 281/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 56.1232 - val_loss: 68.0622\n",
      "Epoch 282/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 56.0955 - val_loss: 68.0450\n",
      "Epoch 283/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 56.0576 - val_loss: 68.0219\n",
      "Epoch 284/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 56.0309 - val_loss: 68.0053\n",
      "Epoch 285/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 56.0094 - val_loss: 67.9608\n",
      "Epoch 286/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 55.9744 - val_loss: 67.9324\n",
      "Epoch 287/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.9445 - val_loss: 67.9037\n",
      "Epoch 288/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 55.9176 - val_loss: 67.8816\n",
      "Epoch 289/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.8907 - val_loss: 67.8660\n",
      "Epoch 290/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 55.8639 - val_loss: 67.8444\n",
      "Epoch 291/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.8345 - val_loss: 67.8178\n",
      "Epoch 292/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 55.8102 - val_loss: 67.7943\n",
      "Epoch 293/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 55.7825 - val_loss: 67.7791\n",
      "Epoch 294/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 55.7566 - val_loss: 67.7569\n",
      "Epoch 295/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 32us/step - loss: 55.7419 - val_loss: 67.7265\n",
      "Epoch 296/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 55.7059 - val_loss: 67.7127\n",
      "Epoch 297/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 55.6774 - val_loss: 67.6858\n",
      "Epoch 298/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 55.6577 - val_loss: 67.6499\n",
      "Epoch 299/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.6314 - val_loss: 67.6262\n",
      "Epoch 300/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.6071 - val_loss: 67.5983\n",
      "Epoch 301/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 55.5787 - val_loss: 67.5749\n",
      "Epoch 302/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 55.5531 - val_loss: 67.5565\n",
      "Epoch 303/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 55.5271 - val_loss: 67.5089\n",
      "Epoch 304/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.4908 - val_loss: 67.4861\n",
      "Epoch 305/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 55.4809 - val_loss: 67.4362\n",
      "Epoch 306/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.4468 - val_loss: 67.4164\n",
      "Epoch 307/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.4246 - val_loss: 67.3850\n",
      "Epoch 308/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.3954 - val_loss: 67.3558\n",
      "Epoch 309/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 55.3760 - val_loss: 67.3352\n",
      "Epoch 310/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 55.3461 - val_loss: 67.3116\n",
      "Epoch 311/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 55.3208 - val_loss: 67.2900\n",
      "Epoch 312/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.3003 - val_loss: 67.2649\n",
      "Epoch 313/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.2759 - val_loss: 67.2462\n",
      "Epoch 314/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.2471 - val_loss: 67.2123\n",
      "Epoch 315/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.2311 - val_loss: 67.2092\n",
      "Epoch 316/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 55.2047 - val_loss: 67.1699\n",
      "Epoch 317/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.1897 - val_loss: 67.1479\n",
      "Epoch 318/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 55.1583 - val_loss: 67.1300\n",
      "Epoch 319/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.1294 - val_loss: 67.1057\n",
      "Epoch 320/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 55.1067 - val_loss: 67.0926\n",
      "Epoch 321/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 55.0809 - val_loss: 67.0713\n",
      "Epoch 322/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 55.0629 - val_loss: 67.0466\n",
      "Epoch 323/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 55.0366 - val_loss: 67.0274\n",
      "Epoch 324/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 55.0196 - val_loss: 66.9974\n",
      "Epoch 325/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 54.9982 - val_loss: 66.9651\n",
      "Epoch 326/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 54.9728 - val_loss: 66.9344\n",
      "Epoch 327/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.9523 - val_loss: 66.9132\n",
      "Epoch 328/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 54.9259 - val_loss: 66.8951\n",
      "Epoch 329/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 54.8999 - val_loss: 66.8647\n",
      "Epoch 330/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 54.8767 - val_loss: 66.8388\n",
      "Epoch 331/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 54.8593 - val_loss: 66.8097\n",
      "Epoch 332/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.8397 - val_loss: 66.8000\n",
      "Epoch 333/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 54.8072 - val_loss: 66.7628\n",
      "Epoch 334/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 54.7944 - val_loss: 66.7335\n",
      "Epoch 335/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 40.18 - 0s 35us/step - loss: 54.7727 - val_loss: 66.6976\n",
      "Epoch 336/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 54.7389 - val_loss: 66.6750\n",
      "Epoch 337/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.7218 - val_loss: 66.6619\n",
      "Epoch 338/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 54.6888 - val_loss: 66.6500\n",
      "Epoch 339/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 54.6708 - val_loss: 66.6287\n",
      "Epoch 340/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.6466 - val_loss: 66.5891\n",
      "Epoch 341/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.6266 - val_loss: 66.5698\n",
      "Epoch 342/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 54.6028 - val_loss: 66.5483\n",
      "Epoch 343/5000\n",
      "1126/1126 [==============================] - 0s 41us/step - loss: 54.5839 - val_loss: 66.5226\n",
      "Epoch 344/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.5649 - val_loss: 66.4925\n",
      "Epoch 345/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.5405 - val_loss: 66.4811\n",
      "Epoch 346/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.5117 - val_loss: 66.4683\n",
      "Epoch 347/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 54.4977 - val_loss: 66.4378\n",
      "Epoch 348/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.4755 - val_loss: 66.4084\n",
      "Epoch 349/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.4496 - val_loss: 66.3859\n",
      "Epoch 350/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.4354 - val_loss: 66.3666\n",
      "Epoch 351/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 54.4124 - val_loss: 66.3391\n",
      "Epoch 352/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 54.3968 - val_loss: 66.3030\n",
      "Epoch 353/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 54.3705 - val_loss: 66.2779\n",
      "Epoch 354/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 54.3454 - val_loss: 66.2698\n",
      "Epoch 355/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 54.3238 - val_loss: 66.2382\n",
      "Epoch 356/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 54.3146 - val_loss: 66.2143\n",
      "Epoch 357/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.2824 - val_loss: 66.1921\n",
      "Epoch 358/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 54.2627 - val_loss: 66.1687\n",
      "Epoch 359/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 54.2463 - val_loss: 66.1403\n",
      "Epoch 360/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 54.2206 - val_loss: 66.1108\n",
      "Epoch 361/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 54.2080 - val_loss: 66.0928\n",
      "Epoch 362/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 54.1811 - val_loss: 66.0619\n",
      "Epoch 363/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 54.1645 - val_loss: 66.0337\n",
      "Epoch 364/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 54.1352 - val_loss: 66.0207\n",
      "Epoch 365/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 54.1207 - val_loss: 66.0050\n",
      "Epoch 366/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 54.1026 - val_loss: 65.9848\n",
      "Epoch 367/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 54.0797 - val_loss: 65.9704\n",
      "Epoch 368/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.0618 - val_loss: 65.9371\n",
      "Epoch 369/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 54.0408 - val_loss: 65.9079\n",
      "Epoch 370/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 30us/step - loss: 54.0199 - val_loss: 65.8860\n",
      "Epoch 371/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.9985 - val_loss: 65.8667\n",
      "Epoch 372/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.9838 - val_loss: 65.8456\n",
      "Epoch 373/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.9579 - val_loss: 65.8212\n",
      "Epoch 374/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.9488 - val_loss: 65.7964\n",
      "Epoch 375/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.9195 - val_loss: 65.7708\n",
      "Epoch 376/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 53.9018 - val_loss: 65.7508\n",
      "Epoch 377/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 53.8817 - val_loss: 65.7230\n",
      "Epoch 378/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 53.8650 - val_loss: 65.7031\n",
      "Epoch 379/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 53.8476 - val_loss: 65.6631\n",
      "Epoch 380/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 53.8241 - val_loss: 65.6444\n",
      "Epoch 381/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.8051 - val_loss: 65.6273\n",
      "Epoch 382/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 53.7862 - val_loss: 65.6043\n",
      "Epoch 383/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 53.7627 - val_loss: 65.5838\n",
      "Epoch 384/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 53.7493 - val_loss: 65.5734\n",
      "Epoch 385/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 53.7314 - val_loss: 65.5433\n",
      "Epoch 386/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 67.03 - 0s 33us/step - loss: 53.7173 - val_loss: 65.5173\n",
      "Epoch 387/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 53.6928 - val_loss: 65.5020\n",
      "Epoch 388/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.6750 - val_loss: 65.4817\n",
      "Epoch 389/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.6554 - val_loss: 65.4494\n",
      "Epoch 390/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.6379 - val_loss: 65.4259\n",
      "Epoch 391/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 53.6177 - val_loss: 65.4072\n",
      "Epoch 392/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 53.5993 - val_loss: 65.3726\n",
      "Epoch 393/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 53.5817 - val_loss: 65.3528\n",
      "Epoch 394/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 53.5631 - val_loss: 65.3059\n",
      "Epoch 395/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.5419 - val_loss: 65.2780\n",
      "Epoch 396/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.5204 - val_loss: 65.2448\n",
      "Epoch 397/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.4948 - val_loss: 65.2266\n",
      "Epoch 398/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.4731 - val_loss: 65.2258\n",
      "Epoch 399/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.4539 - val_loss: 65.2046\n",
      "Epoch 400/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.4370 - val_loss: 65.1669\n",
      "Epoch 401/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.4065 - val_loss: 65.1293\n",
      "Epoch 402/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.3812 - val_loss: 65.1075\n",
      "Epoch 403/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.3593 - val_loss: 65.0799\n",
      "Epoch 404/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.3323 - val_loss: 65.0566\n",
      "Epoch 405/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.3077 - val_loss: 65.0247\n",
      "Epoch 406/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.2850 - val_loss: 64.9957\n",
      "Epoch 407/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.2579 - val_loss: 64.9678\n",
      "Epoch 408/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.2426 - val_loss: 64.9268\n",
      "Epoch 409/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 53.2097 - val_loss: 64.9120\n",
      "Epoch 410/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 53.1955 - val_loss: 64.8807\n",
      "Epoch 411/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 53.1613 - val_loss: 64.8474\n",
      "Epoch 412/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.1385 - val_loss: 64.8216\n",
      "Epoch 413/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.1182 - val_loss: 64.8026\n",
      "Epoch 414/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.0883 - val_loss: 64.7655\n",
      "Epoch 415/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 53.0643 - val_loss: 64.7540\n",
      "Epoch 416/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 53.0375 - val_loss: 64.7267\n",
      "Epoch 417/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 53.0209 - val_loss: 64.7018\n",
      "Epoch 418/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.9970 - val_loss: 64.6718\n",
      "Epoch 419/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 52.9683 - val_loss: 64.6542\n",
      "Epoch 420/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.9467 - val_loss: 64.6283\n",
      "Epoch 421/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.9216 - val_loss: 64.6006\n",
      "Epoch 422/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 52.9010 - val_loss: 64.5777\n",
      "Epoch 423/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.8698 - val_loss: 64.5511\n",
      "Epoch 424/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 52.8542 - val_loss: 64.5320\n",
      "Epoch 425/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 52.8315 - val_loss: 64.4903\n",
      "Epoch 426/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 52.7920 - val_loss: 64.4655\n",
      "Epoch 427/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.7857 - val_loss: 64.4536\n",
      "Epoch 428/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 52.7580 - val_loss: 64.4225\n",
      "Epoch 429/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 52.7335 - val_loss: 64.4026\n",
      "Epoch 430/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 52.7118 - val_loss: 64.3715\n",
      "Epoch 431/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.6844 - val_loss: 64.3538\n",
      "Epoch 432/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.6669 - val_loss: 64.3211\n",
      "Epoch 433/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 52.6426 - val_loss: 64.2962\n",
      "Epoch 434/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.6198 - val_loss: 64.2681\n",
      "Epoch 435/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.5992 - val_loss: 64.2537\n",
      "Epoch 436/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.5810 - val_loss: 64.2085\n",
      "Epoch 437/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.5506 - val_loss: 64.1801\n",
      "Epoch 438/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.5323 - val_loss: 64.1555\n",
      "Epoch 439/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.5092 - val_loss: 64.1242\n",
      "Epoch 440/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.4857 - val_loss: 64.0989\n",
      "Epoch 441/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 52.4647 - val_loss: 64.0480\n",
      "Epoch 442/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.4397 - val_loss: 64.0258\n",
      "Epoch 443/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.4192 - val_loss: 64.0045\n",
      "Epoch 444/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 52.3986 - val_loss: 63.9743\n",
      "Epoch 445/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.3853 - val_loss: 63.9444\n",
      "Epoch 446/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.3595 - val_loss: 63.9067\n",
      "Epoch 447/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 52.3411 - val_loss: 63.8759\n",
      "Epoch 448/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.3219 - val_loss: 63.8500\n",
      "Epoch 449/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 52.2992 - val_loss: 63.8391\n",
      "Epoch 450/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 52.2862 - val_loss: 63.8153\n",
      "Epoch 451/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 52.2615 - val_loss: 63.7823\n",
      "Epoch 452/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 52.2371 - val_loss: 63.7498\n",
      "Epoch 453/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 52.2213 - val_loss: 63.7240\n",
      "Epoch 454/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.2026 - val_loss: 63.6971\n",
      "Epoch 455/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 52.1829 - val_loss: 63.6763\n",
      "Epoch 456/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.1586 - val_loss: 63.6563\n",
      "Epoch 457/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.1445 - val_loss: 63.6149\n",
      "Epoch 458/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 52.1170 - val_loss: 63.5918\n",
      "Epoch 459/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 52.1034 - val_loss: 63.5714\n",
      "Epoch 460/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 52.0814 - val_loss: 63.5510\n",
      "Epoch 461/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 52.0666 - val_loss: 63.5310\n",
      "Epoch 462/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 52.0483 - val_loss: 63.5020\n",
      "Epoch 463/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 52.0304 - val_loss: 63.4791\n",
      "Epoch 464/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 52.0135 - val_loss: 63.4598\n",
      "Epoch 465/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.9914 - val_loss: 63.4388\n",
      "Epoch 466/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.9739 - val_loss: 63.4159\n",
      "Epoch 467/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.9595 - val_loss: 63.3971\n",
      "Epoch 468/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.9377 - val_loss: 63.3498\n",
      "Epoch 469/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.9161 - val_loss: 63.3359\n",
      "Epoch 470/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.9002 - val_loss: 63.3231\n",
      "Epoch 471/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.8863 - val_loss: 63.3095\n",
      "Epoch 472/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.8669 - val_loss: 63.2812\n",
      "Epoch 473/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.8493 - val_loss: 63.2580\n",
      "Epoch 474/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.8361 - val_loss: 63.2319\n",
      "Epoch 475/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.8127 - val_loss: 63.2153\n",
      "Epoch 476/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.8004 - val_loss: 63.1939\n",
      "Epoch 477/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.7803 - val_loss: 63.1818\n",
      "Epoch 478/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.7726 - val_loss: 63.1555\n",
      "Epoch 479/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.7506 - val_loss: 63.1477\n",
      "Epoch 480/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.7382 - val_loss: 63.1259\n",
      "Epoch 481/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.7220 - val_loss: 63.1012\n",
      "Epoch 482/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.7029 - val_loss: 63.0834\n",
      "Epoch 483/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.6848 - val_loss: 63.0620\n",
      "Epoch 484/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.6677 - val_loss: 63.0453\n",
      "Epoch 485/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.6484 - val_loss: 63.0222\n",
      "Epoch 486/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 51.6370 - val_loss: 63.0020\n",
      "Epoch 487/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 51.6228 - val_loss: 62.9724\n",
      "Epoch 488/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 51.5993 - val_loss: 62.9530\n",
      "Epoch 489/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 51.5853 - val_loss: 62.9295\n",
      "Epoch 490/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 51.5690 - val_loss: 62.9057\n",
      "Epoch 491/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.5601 - val_loss: 62.8808\n",
      "Epoch 492/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.5368 - val_loss: 62.8568\n",
      "Epoch 493/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.5239 - val_loss: 62.8349\n",
      "Epoch 494/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 51.5092 - val_loss: 62.8097\n",
      "Epoch 495/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.4925 - val_loss: 62.7929\n",
      "Epoch 496/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.4817 - val_loss: 62.7794\n",
      "Epoch 497/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.4660 - val_loss: 62.7569\n",
      "Epoch 498/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 51.4477 - val_loss: 62.7361\n",
      "Epoch 499/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.4286 - val_loss: 62.6997\n",
      "Epoch 500/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.4132 - val_loss: 62.6687\n",
      "Epoch 501/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.3990 - val_loss: 62.6569\n",
      "Epoch 502/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.3801 - val_loss: 62.6401\n",
      "Epoch 503/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.3708 - val_loss: 62.6225\n",
      "Epoch 504/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.3553 - val_loss: 62.6090\n",
      "Epoch 505/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.3370 - val_loss: 62.5846\n",
      "Epoch 506/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.3326 - val_loss: 62.5594\n",
      "Epoch 507/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.3169 - val_loss: 62.5478\n",
      "Epoch 508/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 51.2967 - val_loss: 62.5210\n",
      "Epoch 509/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.2822 - val_loss: 62.5056\n",
      "Epoch 510/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.2682 - val_loss: 62.4895\n",
      "Epoch 511/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.2489 - val_loss: 62.4830\n",
      "Epoch 512/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.2377 - val_loss: 62.4680\n",
      "Epoch 513/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.2230 - val_loss: 62.4489\n",
      "Epoch 514/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 51.2096 - val_loss: 62.4274\n",
      "Epoch 515/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 51.2027 - val_loss: 62.4098\n",
      "Epoch 516/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 51.1851 - val_loss: 62.3948\n",
      "Epoch 517/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 32.11 - 0s 38us/step - loss: 51.1688 - val_loss: 62.3830\n",
      "Epoch 518/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 51.1529 - val_loss: 62.3662\n",
      "Epoch 519/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 51.1397 - val_loss: 62.3486\n",
      "Epoch 520/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 34us/step - loss: 51.1331 - val_loss: 62.3240\n",
      "Epoch 521/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 51.1144 - val_loss: 62.3092\n",
      "Epoch 522/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 51.1009 - val_loss: 62.3010\n",
      "Epoch 523/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.0864 - val_loss: 62.2828\n",
      "Epoch 524/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 51.0750 - val_loss: 62.2620\n",
      "Epoch 525/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.0568 - val_loss: 62.2404\n",
      "Epoch 526/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.0447 - val_loss: 62.2332\n",
      "Epoch 527/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 51.0293 - val_loss: 62.2177\n",
      "Epoch 528/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 51.0156 - val_loss: 62.2042\n",
      "Epoch 529/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.0056 - val_loss: 62.2012\n",
      "Epoch 530/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.9911 - val_loss: 62.1914\n",
      "Epoch 531/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.9838 - val_loss: 62.1706\n",
      "Epoch 532/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.9668 - val_loss: 62.1675\n",
      "Epoch 533/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.9524 - val_loss: 62.1373\n",
      "Epoch 534/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.9430 - val_loss: 62.1254\n",
      "Epoch 535/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.9245 - val_loss: 62.1090\n",
      "Epoch 536/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.9143 - val_loss: 62.0866\n",
      "Epoch 537/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 50.8980 - val_loss: 62.0727\n",
      "Epoch 538/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.8945 - val_loss: 62.0569\n",
      "Epoch 539/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 50.8769 - val_loss: 62.0388\n",
      "Epoch 540/5000\n",
      "1126/1126 [==============================] - 0s 41us/step - loss: 50.8651 - val_loss: 62.0213\n",
      "Epoch 541/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.8536 - val_loss: 62.0086\n",
      "Epoch 542/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.8399 - val_loss: 61.9827\n",
      "Epoch 543/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.8239 - val_loss: 61.9532\n",
      "Epoch 544/5000\n",
      "1126/1126 [==============================] - 0s 44us/step - loss: 50.8139 - val_loss: 61.9347\n",
      "Epoch 545/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.8021 - val_loss: 61.9168\n",
      "Epoch 546/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.7864 - val_loss: 61.9054\n",
      "Epoch 547/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.7747 - val_loss: 61.8974\n",
      "Epoch 548/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 50.7582 - val_loss: 61.8874\n",
      "Epoch 549/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 50.7507 - val_loss: 61.8550\n",
      "Epoch 550/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 50.7359 - val_loss: 61.8463\n",
      "Epoch 551/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.7219 - val_loss: 61.8333\n",
      "Epoch 552/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.7126 - val_loss: 61.8258\n",
      "Epoch 553/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.7028 - val_loss: 61.8013\n",
      "Epoch 554/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.6831 - val_loss: 61.7889\n",
      "Epoch 555/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.6769 - val_loss: 61.7727\n",
      "Epoch 556/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.6608 - val_loss: 61.7513\n",
      "Epoch 557/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.6543 - val_loss: 61.7370\n",
      "Epoch 558/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.6318 - val_loss: 61.7221\n",
      "Epoch 559/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.6281 - val_loss: 61.7003\n",
      "Epoch 560/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.6114 - val_loss: 61.6984\n",
      "Epoch 561/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.5999 - val_loss: 61.6840\n",
      "Epoch 562/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.5902 - val_loss: 61.6652\n",
      "Epoch 563/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 50.5772 - val_loss: 61.6557\n",
      "Epoch 564/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 50.5638 - val_loss: 61.6530\n",
      "Epoch 565/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 50.5508 - val_loss: 61.6159\n",
      "Epoch 566/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 50.5389 - val_loss: 61.6002\n",
      "Epoch 567/5000\n",
      "1126/1126 [==============================] - 0s 42us/step - loss: 50.5316 - val_loss: 61.5844\n",
      "Epoch 568/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 50.5166 - val_loss: 61.5625\n",
      "Epoch 569/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.5137 - val_loss: 61.5559\n",
      "Epoch 570/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.4988 - val_loss: 61.5407\n",
      "Epoch 571/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.4823 - val_loss: 61.5268\n",
      "Epoch 572/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.4734 - val_loss: 61.5143\n",
      "Epoch 573/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 50.4628 - val_loss: 61.5035\n",
      "Epoch 574/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.4479 - val_loss: 61.5109\n",
      "Epoch 575/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.4404 - val_loss: 61.4910\n",
      "Epoch 576/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.4294 - val_loss: 61.4894\n",
      "Epoch 577/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.4171 - val_loss: 61.4762\n",
      "Epoch 578/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.4024 - val_loss: 61.4563\n",
      "Epoch 579/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.3910 - val_loss: 61.4425\n",
      "Epoch 580/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.3783 - val_loss: 61.4288\n",
      "Epoch 581/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.3690 - val_loss: 61.4196\n",
      "Epoch 582/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.3581 - val_loss: 61.4155\n",
      "Epoch 583/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.3444 - val_loss: 61.3974\n",
      "Epoch 584/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.3274 - val_loss: 61.3832\n",
      "Epoch 585/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 50.3196 - val_loss: 61.3827\n",
      "Epoch 586/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.3074 - val_loss: 61.3694\n",
      "Epoch 587/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.3002 - val_loss: 61.3485\n",
      "Epoch 588/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.2859 - val_loss: 61.3353\n",
      "Epoch 589/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.2797 - val_loss: 61.3206\n",
      "Epoch 590/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.2640 - val_loss: 61.3091\n",
      "Epoch 591/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 50.2649 - val_loss: 61.2919\n",
      "Epoch 592/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 50.2418 - val_loss: 61.2766\n",
      "Epoch 593/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 50.2280 - val_loss: 61.2601\n",
      "Epoch 594/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.2192 - val_loss: 61.2547\n",
      "Epoch 595/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 30us/step - loss: 50.2122 - val_loss: 61.2441\n",
      "Epoch 596/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 50.2030 - val_loss: 61.2273\n",
      "Epoch 597/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.1892 - val_loss: 61.2219\n",
      "Epoch 598/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 50.1791 - val_loss: 61.2096\n",
      "Epoch 599/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.1678 - val_loss: 61.1901\n",
      "Epoch 600/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.1564 - val_loss: 61.1779\n",
      "Epoch 601/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.1484 - val_loss: 61.1630\n",
      "Epoch 602/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.1339 - val_loss: 61.1520\n",
      "Epoch 603/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 50.1201 - val_loss: 61.1420\n",
      "Epoch 604/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 50.1165 - val_loss: 61.1268\n",
      "Epoch 605/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.1032 - val_loss: 61.1186\n",
      "Epoch 606/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.0949 - val_loss: 61.1114\n",
      "Epoch 607/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.0863 - val_loss: 61.1041\n",
      "Epoch 608/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 50.0707 - val_loss: 61.1038\n",
      "Epoch 609/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.0609 - val_loss: 61.0905\n",
      "Epoch 610/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.0547 - val_loss: 61.0768\n",
      "Epoch 611/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.0389 - val_loss: 61.0603\n",
      "Epoch 612/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.0315 - val_loss: 61.0494\n",
      "Epoch 613/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 50.0166 - val_loss: 61.0421\n",
      "Epoch 614/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.0112 - val_loss: 61.0290\n",
      "Epoch 615/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.0056 - val_loss: 61.0122\n",
      "Epoch 616/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.9855 - val_loss: 60.9937\n",
      "Epoch 617/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.9781 - val_loss: 60.9834\n",
      "Epoch 618/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.9673 - val_loss: 60.9737\n",
      "Epoch 619/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.9590 - val_loss: 60.9645\n",
      "Epoch 620/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.9451 - val_loss: 60.9482\n",
      "Epoch 621/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.9346 - val_loss: 60.9348\n",
      "Epoch 622/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.9263 - val_loss: 60.9177\n",
      "Epoch 623/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.9171 - val_loss: 60.9142\n",
      "Epoch 624/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.9202 - val_loss: 60.8984\n",
      "Epoch 625/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.8985 - val_loss: 60.8819\n",
      "Epoch 626/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.8914 - val_loss: 60.8654\n",
      "Epoch 627/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.8769 - val_loss: 60.8518\n",
      "Epoch 628/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 49.8715 - val_loss: 60.8303\n",
      "Epoch 629/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.8587 - val_loss: 60.8191\n",
      "Epoch 630/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.8493 - val_loss: 60.8098\n",
      "Epoch 631/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.8388 - val_loss: 60.7957\n",
      "Epoch 632/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.8330 - val_loss: 60.7955\n",
      "Epoch 633/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.8227 - val_loss: 60.7874\n",
      "Epoch 634/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.8116 - val_loss: 60.7815\n",
      "Epoch 635/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.7985 - val_loss: 60.7726\n",
      "Epoch 636/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.7891 - val_loss: 60.7660\n",
      "Epoch 637/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.7797 - val_loss: 60.7565\n",
      "Epoch 638/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.7714 - val_loss: 60.7417\n",
      "Epoch 639/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.7620 - val_loss: 60.7348\n",
      "Epoch 640/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.7606 - val_loss: 60.7212\n",
      "Epoch 641/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.7427 - val_loss: 60.7091\n",
      "Epoch 642/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.7385 - val_loss: 60.7029\n",
      "Epoch 643/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.7284 - val_loss: 60.6915\n",
      "Epoch 644/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 49.7129 - val_loss: 60.6795\n",
      "Epoch 645/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.7049 - val_loss: 60.6735\n",
      "Epoch 646/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.6947 - val_loss: 60.6605\n",
      "Epoch 647/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 49.6866 - val_loss: 60.6534\n",
      "Epoch 648/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.6743 - val_loss: 60.6564\n",
      "Epoch 649/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.6685 - val_loss: 60.6471\n",
      "Epoch 650/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.6561 - val_loss: 60.6332\n",
      "Epoch 651/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.6515 - val_loss: 60.6197\n",
      "Epoch 652/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.6414 - val_loss: 60.6111\n",
      "Epoch 653/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.6301 - val_loss: 60.5919\n",
      "Epoch 654/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.6203 - val_loss: 60.5856\n",
      "Epoch 655/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.6091 - val_loss: 60.5764\n",
      "Epoch 656/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.6046 - val_loss: 60.5637\n",
      "Epoch 657/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.5961 - val_loss: 60.5585\n",
      "Epoch 658/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.5862 - val_loss: 60.5339\n",
      "Epoch 659/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.5809 - val_loss: 60.5175\n",
      "Epoch 660/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.5626 - val_loss: 60.5019\n",
      "Epoch 661/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.5590 - val_loss: 60.4831\n",
      "Epoch 662/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.5463 - val_loss: 60.4672\n",
      "Epoch 663/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.5402 - val_loss: 60.4582\n",
      "Epoch 664/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.5282 - val_loss: 60.4475\n",
      "Epoch 665/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.5199 - val_loss: 60.4437\n",
      "Epoch 666/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.5116 - val_loss: 60.4312\n",
      "Epoch 667/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.5016 - val_loss: 60.4216\n",
      "Epoch 668/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.4956 - val_loss: 60.4166\n",
      "Epoch 669/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 49.4851 - val_loss: 60.3903\n",
      "Epoch 670/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.4732 - val_loss: 60.3745\n",
      "Epoch 671/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 49.4631 - val_loss: 60.3700\n",
      "Epoch 672/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.4588 - val_loss: 60.3654\n",
      "Epoch 673/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.4494 - val_loss: 60.3592\n",
      "Epoch 674/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.4383 - val_loss: 60.3532\n",
      "Epoch 675/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.4300 - val_loss: 60.3489\n",
      "Epoch 676/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.4249 - val_loss: 60.3420\n",
      "Epoch 677/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.4110 - val_loss: 60.3489\n",
      "Epoch 678/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.4059 - val_loss: 60.3491\n",
      "Epoch 679/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 49.4002 - val_loss: 60.3426\n",
      "Epoch 680/5000\n",
      "1126/1126 [==============================] - 0s 42us/step - loss: 49.3856 - val_loss: 60.3385\n",
      "Epoch 681/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 49.3770 - val_loss: 60.3285\n",
      "Epoch 682/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.3709 - val_loss: 60.3196\n",
      "Epoch 683/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.3609 - val_loss: 60.3130\n",
      "Epoch 684/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.3519 - val_loss: 60.3063\n",
      "Epoch 685/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.3482 - val_loss: 60.3030\n",
      "Epoch 686/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.3392 - val_loss: 60.2922\n",
      "Epoch 687/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.3282 - val_loss: 60.3167\n",
      "Epoch 688/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.3295 - val_loss: 60.2942\n",
      "Epoch 689/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.3169 - val_loss: 60.2734\n",
      "Epoch 690/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.3015 - val_loss: 60.2589\n",
      "Epoch 691/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.2902 - val_loss: 60.2532\n",
      "Epoch 692/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.2835 - val_loss: 60.2281\n",
      "Epoch 693/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.2715 - val_loss: 60.2182\n",
      "Epoch 694/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.2677 - val_loss: 60.2105\n",
      "Epoch 695/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.2593 - val_loss: 60.1988\n",
      "Epoch 696/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.2450 - val_loss: 60.1887\n",
      "Epoch 697/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 49.2405 - val_loss: 60.1789\n",
      "Epoch 698/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.2331 - val_loss: 60.1682\n",
      "Epoch 699/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.2222 - val_loss: 60.1594\n",
      "Epoch 700/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.2216 - val_loss: 60.1485\n",
      "Epoch 701/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.2153 - val_loss: 60.1464\n",
      "Epoch 702/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.1977 - val_loss: 60.1361\n",
      "Epoch 703/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.1923 - val_loss: 60.1317\n",
      "Epoch 704/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.1871 - val_loss: 60.1226\n",
      "Epoch 705/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.1737 - val_loss: 60.1157\n",
      "Epoch 706/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 49.1677 - val_loss: 60.1102\n",
      "Epoch 707/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.1576 - val_loss: 60.1053\n",
      "Epoch 708/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.1491 - val_loss: 60.1001\n",
      "Epoch 709/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.1431 - val_loss: 60.0879\n",
      "Epoch 710/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.1352 - val_loss: 60.0840\n",
      "Epoch 711/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.1262 - val_loss: 60.0841\n",
      "Epoch 712/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 49.1174 - val_loss: 60.0806\n",
      "Epoch 713/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.1082 - val_loss: 60.0654\n",
      "Epoch 714/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.1033 - val_loss: 60.0532\n",
      "Epoch 715/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 49.0944 - val_loss: 60.0517\n",
      "Epoch 716/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.0873 - val_loss: 60.0424\n",
      "Epoch 717/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.0802 - val_loss: 60.0320\n",
      "Epoch 718/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.0709 - val_loss: 60.0222\n",
      "Epoch 719/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.0640 - val_loss: 60.0102\n",
      "Epoch 720/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.0506 - val_loss: 60.0003\n",
      "Epoch 721/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.0521 - val_loss: 59.9954\n",
      "Epoch 722/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.0378 - val_loss: 59.9853\n",
      "Epoch 723/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.0338 - val_loss: 59.9760\n",
      "Epoch 724/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.0219 - val_loss: 59.9713\n",
      "Epoch 725/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.0137 - val_loss: 59.9794\n",
      "Epoch 726/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.0058 - val_loss: 59.9651\n",
      "Epoch 727/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.9934 - val_loss: 59.9565\n",
      "Epoch 728/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.9870 - val_loss: 59.9503\n",
      "Epoch 729/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.9813 - val_loss: 59.9385\n",
      "Epoch 730/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.9759 - val_loss: 59.9262\n",
      "Epoch 731/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.9672 - val_loss: 59.9160\n",
      "Epoch 732/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.9597 - val_loss: 59.9105\n",
      "Epoch 733/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.9485 - val_loss: 59.9022\n",
      "Epoch 734/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.9425 - val_loss: 59.8901\n",
      "Epoch 735/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.9381 - val_loss: 59.8866\n",
      "Epoch 736/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.9296 - val_loss: 59.8751\n",
      "Epoch 737/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.9238 - val_loss: 59.8626\n",
      "Epoch 738/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.9135 - val_loss: 59.8561\n",
      "Epoch 739/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.9079 - val_loss: 59.8495\n",
      "Epoch 740/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.8940 - val_loss: 59.8405\n",
      "Epoch 741/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.8861 - val_loss: 59.8302\n",
      "Epoch 742/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 48.8802 - val_loss: 59.8167\n",
      "Epoch 743/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 48.8716 - val_loss: 59.8105\n",
      "Epoch 744/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.8640 - val_loss: 59.8045\n",
      "Epoch 745/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.8544 - val_loss: 59.7920\n",
      "Epoch 746/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 48.8506 - val_loss: 59.7881\n",
      "Epoch 747/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.8402 - val_loss: 59.7749\n",
      "Epoch 748/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.8304 - val_loss: 59.7641\n",
      "Epoch 749/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.8268 - val_loss: 59.7695\n",
      "Epoch 750/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 48.8169 - val_loss: 59.7664\n",
      "Epoch 751/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.8040 - val_loss: 59.7684\n",
      "Epoch 752/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.7988 - val_loss: 59.7622\n",
      "Epoch 753/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.7930 - val_loss: 59.7586\n",
      "Epoch 754/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.7824 - val_loss: 59.7554\n",
      "Epoch 755/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.7780 - val_loss: 59.7568\n",
      "Epoch 756/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.7720 - val_loss: 59.7493\n",
      "Epoch 757/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.7641 - val_loss: 59.7416\n",
      "Epoch 758/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.7560 - val_loss: 59.7308\n",
      "Epoch 759/5000\n",
      "1126/1126 [==============================] - 0s 42us/step - loss: 48.7483 - val_loss: 59.7097\n",
      "Epoch 760/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.7425 - val_loss: 59.7006\n",
      "Epoch 761/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.7272 - val_loss: 59.6861\n",
      "Epoch 762/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.7247 - val_loss: 59.6806\n",
      "Epoch 763/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.7166 - val_loss: 59.6781\n",
      "Epoch 764/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.7103 - val_loss: 59.6710\n",
      "Epoch 765/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.7030 - val_loss: 59.6679\n",
      "Epoch 766/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.6910 - val_loss: 59.6616\n",
      "Epoch 767/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.6865 - val_loss: 59.6478\n",
      "Epoch 768/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 48.6829 - val_loss: 59.6387\n",
      "Epoch 769/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 48.6718 - val_loss: 59.6360\n",
      "Epoch 770/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.6677 - val_loss: 59.6242\n",
      "Epoch 771/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.6580 - val_loss: 59.6210\n",
      "Epoch 772/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.6497 - val_loss: 59.6150\n",
      "Epoch 773/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.6422 - val_loss: 59.6072\n",
      "Epoch 774/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.6335 - val_loss: 59.6054\n",
      "Epoch 775/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.6288 - val_loss: 59.5987\n",
      "Epoch 776/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.6206 - val_loss: 59.5956\n",
      "Epoch 777/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 48.6126 - val_loss: 59.5864\n",
      "Epoch 778/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.6041 - val_loss: 59.5833\n",
      "Epoch 779/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.6042 - val_loss: 59.5791\n",
      "Epoch 780/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.5905 - val_loss: 59.5771\n",
      "Epoch 781/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.5827 - val_loss: 59.5728\n",
      "Epoch 782/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.5783 - val_loss: 59.5706\n",
      "Epoch 783/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.5740 - val_loss: 59.5682\n",
      "Epoch 784/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.5660 - val_loss: 59.5596\n",
      "Epoch 785/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.5578 - val_loss: 59.5517\n",
      "Epoch 786/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.5484 - val_loss: 59.5422\n",
      "Epoch 787/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.5426 - val_loss: 59.5359\n",
      "Epoch 788/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.5326 - val_loss: 59.5269\n",
      "Epoch 789/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.5228 - val_loss: 59.5207\n",
      "Epoch 790/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.5163 - val_loss: 59.5104\n",
      "Epoch 791/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.5073 - val_loss: 59.5086\n",
      "Epoch 792/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.5039 - val_loss: 59.4996\n",
      "Epoch 793/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.4975 - val_loss: 59.4959\n",
      "Epoch 794/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.4896 - val_loss: 59.4877\n",
      "Epoch 795/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.4831 - val_loss: 59.4855\n",
      "Epoch 796/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.4708 - val_loss: 59.4783\n",
      "Epoch 797/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.4704 - val_loss: 59.4700\n",
      "Epoch 798/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 48.4643 - val_loss: 59.4623\n",
      "Epoch 799/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 48.4552 - val_loss: 59.4577\n",
      "Epoch 800/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 48.4516 - val_loss: 59.4546\n",
      "Epoch 801/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.4408 - val_loss: 59.4356\n",
      "Epoch 802/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.4401 - val_loss: 59.4306\n",
      "Epoch 803/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 48.4290 - val_loss: 59.4181\n",
      "Epoch 804/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.4209 - val_loss: 59.4050\n",
      "Epoch 805/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.4129 - val_loss: 59.4065\n",
      "Epoch 806/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.4082 - val_loss: 59.3990\n",
      "Epoch 807/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.4063 - val_loss: 59.3856\n",
      "Epoch 808/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.3956 - val_loss: 59.3718\n",
      "Epoch 809/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.3872 - val_loss: 59.3704\n",
      "Epoch 810/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.3810 - val_loss: 59.3686\n",
      "Epoch 811/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.3734 - val_loss: 59.3618\n",
      "Epoch 812/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.3688 - val_loss: 59.3540\n",
      "Epoch 813/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.3635 - val_loss: 59.3503\n",
      "Epoch 814/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.3511 - val_loss: 59.3498\n",
      "Epoch 815/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.3456 - val_loss: 59.3444\n",
      "Epoch 816/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.3353 - val_loss: 59.3403\n",
      "Epoch 817/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.3322 - val_loss: 59.3319\n",
      "Epoch 818/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.3279 - val_loss: 59.3283\n",
      "Epoch 819/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.3258 - val_loss: 59.3235\n",
      "Epoch 820/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.3119 - val_loss: 59.3239\n",
      "Epoch 821/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 48.3080 - val_loss: 59.3234\n",
      "Epoch 822/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.2958 - val_loss: 59.3196\n",
      "Epoch 823/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.2931 - val_loss: 59.3223\n",
      "Epoch 824/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.2880 - val_loss: 59.3221\n",
      "Epoch 825/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.2777 - val_loss: 59.3161\n",
      "Epoch 826/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 48.2751 - val_loss: 59.3121\n",
      "Epoch 827/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.2683 - val_loss: 59.3028\n",
      "Epoch 828/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.2617 - val_loss: 59.2987\n",
      "Epoch 829/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.2534 - val_loss: 59.2956\n",
      "Epoch 830/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.2485 - val_loss: 59.2903\n",
      "Epoch 831/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.2409 - val_loss: 59.2899\n",
      "Epoch 832/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.2355 - val_loss: 59.2768\n",
      "Epoch 833/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.2263 - val_loss: 59.2681\n",
      "Epoch 834/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.2230 - val_loss: 59.2549\n",
      "Epoch 835/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.2177 - val_loss: 59.2473\n",
      "Epoch 836/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 48.2107 - val_loss: 59.2444\n",
      "Epoch 837/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.2003 - val_loss: 59.2479\n",
      "Epoch 838/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.1971 - val_loss: 59.2417\n",
      "Epoch 839/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.1892 - val_loss: 59.2417\n",
      "Epoch 840/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.1822 - val_loss: 59.2342\n",
      "Epoch 841/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.1769 - val_loss: 59.2347\n",
      "Epoch 842/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.1691 - val_loss: 59.2266\n",
      "Epoch 843/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.1631 - val_loss: 59.2256\n",
      "Epoch 844/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.1543 - val_loss: 59.2187\n",
      "Epoch 845/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.1543 - val_loss: 59.2210\n",
      "Epoch 846/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.1470 - val_loss: 59.2155\n",
      "Epoch 847/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.1402 - val_loss: 59.2096\n",
      "Epoch 848/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.1301 - val_loss: 59.2019\n",
      "Epoch 849/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.1265 - val_loss: 59.1964\n",
      "Epoch 850/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.1170 - val_loss: 59.1949\n",
      "Epoch 851/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.1113 - val_loss: 59.1874\n",
      "Epoch 852/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.1074 - val_loss: 59.1784\n",
      "Epoch 853/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.0995 - val_loss: 59.1733\n",
      "Epoch 854/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.0937 - val_loss: 59.1628\n",
      "Epoch 855/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.0864 - val_loss: 59.1572\n",
      "Epoch 856/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 48.0854 - val_loss: 59.1489\n",
      "Epoch 857/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 48.0765 - val_loss: 59.1403\n",
      "Epoch 858/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 48.0671 - val_loss: 59.1260\n",
      "Epoch 859/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 48.0603 - val_loss: 59.1198\n",
      "Epoch 860/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 48.0574 - val_loss: 59.1202\n",
      "Epoch 861/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 48.0522 - val_loss: 59.1149\n",
      "Epoch 862/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.0450 - val_loss: 59.1183\n",
      "Epoch 863/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 48.0368 - val_loss: 59.1050\n",
      "Epoch 864/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 48.0312 - val_loss: 59.0979\n",
      "Epoch 865/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.0277 - val_loss: 59.1017\n",
      "Epoch 866/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 48.0224 - val_loss: 59.0949\n",
      "Epoch 867/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.0123 - val_loss: 59.0939\n",
      "Epoch 868/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.0109 - val_loss: 59.0897\n",
      "Epoch 869/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 47.9994 - val_loss: 59.0843\n",
      "Epoch 870/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.9946 - val_loss: 59.0763\n",
      "Epoch 871/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.9910 - val_loss: 59.0725\n",
      "Epoch 872/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.9838 - val_loss: 59.0663\n",
      "Epoch 873/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.9768 - val_loss: 59.0625\n",
      "Epoch 874/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.9775 - val_loss: 59.0544\n",
      "Epoch 875/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 47.9627 - val_loss: 59.0469\n",
      "Epoch 876/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.9625 - val_loss: 59.0399\n",
      "Epoch 877/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.9549 - val_loss: 59.0395\n",
      "Epoch 878/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 47.9470 - val_loss: 59.0342\n",
      "Epoch 879/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.9441 - val_loss: 59.0320\n",
      "Epoch 880/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.9357 - val_loss: 59.0184\n",
      "Epoch 881/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.9354 - val_loss: 59.0156\n",
      "Epoch 882/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.9279 - val_loss: 59.0233\n",
      "Epoch 883/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.9174 - val_loss: 59.0157\n",
      "Epoch 884/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.9150 - val_loss: 59.0126\n",
      "Epoch 885/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.9076 - val_loss: 59.0092\n",
      "Epoch 886/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.9019 - val_loss: 59.0028\n",
      "Epoch 887/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.8975 - val_loss: 58.9992\n",
      "Epoch 888/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.8913 - val_loss: 58.9911\n",
      "Epoch 889/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.8907 - val_loss: 58.9889\n",
      "Epoch 890/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.8791 - val_loss: 58.9831\n",
      "Epoch 891/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.8759 - val_loss: 58.9681\n",
      "Epoch 892/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.8696 - val_loss: 58.9639\n",
      "Epoch 893/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.8616 - val_loss: 58.9600\n",
      "Epoch 894/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.8586 - val_loss: 58.9565\n",
      "Epoch 895/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.8511 - val_loss: 58.9574\n",
      "Epoch 896/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.8481 - val_loss: 58.9570\n",
      "Epoch 897/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.8385 - val_loss: 58.9552\n",
      "Epoch 898/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.8366 - val_loss: 58.9464\n",
      "Epoch 899/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.8334 - val_loss: 58.9461\n",
      "Epoch 900/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 47.8229 - val_loss: 58.9424\n",
      "Epoch 901/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.8212 - val_loss: 58.9377\n",
      "Epoch 902/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.8107 - val_loss: 58.9353\n",
      "Epoch 903/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.8069 - val_loss: 58.9183\n",
      "Epoch 904/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.8062 - val_loss: 58.9167\n",
      "Epoch 905/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.7940 - val_loss: 58.9196\n",
      "Epoch 906/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7915 - val_loss: 58.9185\n",
      "Epoch 907/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7892 - val_loss: 58.9136\n",
      "Epoch 908/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7829 - val_loss: 58.9074\n",
      "Epoch 909/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.7779 - val_loss: 58.9032\n",
      "Epoch 910/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.7713 - val_loss: 58.8968\n",
      "Epoch 911/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.7675 - val_loss: 58.8817\n",
      "Epoch 912/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7603 - val_loss: 58.8715\n",
      "Epoch 913/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7539 - val_loss: 58.8620\n",
      "Epoch 914/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.7519 - val_loss: 58.8610\n",
      "Epoch 915/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7473 - val_loss: 58.8569\n",
      "Epoch 916/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.7458 - val_loss: 58.8532\n",
      "Epoch 917/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.7310 - val_loss: 58.8433\n",
      "Epoch 918/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7273 - val_loss: 58.8356\n",
      "Epoch 919/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.7211 - val_loss: 58.8352\n",
      "Epoch 920/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.7189 - val_loss: 58.8213\n",
      "Epoch 921/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7132 - val_loss: 58.8266\n",
      "Epoch 922/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.7116 - val_loss: 58.8272\n",
      "Epoch 923/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.7007 - val_loss: 58.8241\n",
      "Epoch 924/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.6943 - val_loss: 58.8109\n",
      "Epoch 925/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.6934 - val_loss: 58.8081\n",
      "Epoch 926/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.6875 - val_loss: 58.8017\n",
      "Epoch 927/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.6815 - val_loss: 58.8004\n",
      "Epoch 928/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 47.6735 - val_loss: 58.8019\n",
      "Epoch 929/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.6701 - val_loss: 58.7922\n",
      "Epoch 930/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.6637 - val_loss: 58.7959\n",
      "Epoch 931/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.6614 - val_loss: 58.7920\n",
      "Epoch 932/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.6545 - val_loss: 58.7870\n",
      "Epoch 933/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.6550 - val_loss: 58.7837\n",
      "Epoch 934/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.6451 - val_loss: 58.7851\n",
      "Epoch 935/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.6400 - val_loss: 58.7845\n",
      "Epoch 936/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 47.6342 - val_loss: 58.7811\n",
      "Epoch 937/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.6272 - val_loss: 58.7790\n",
      "Epoch 938/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.6234 - val_loss: 58.7823\n",
      "Epoch 939/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.6178 - val_loss: 58.7775\n",
      "Epoch 940/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.6121 - val_loss: 58.7685\n",
      "Epoch 941/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 47.6092 - val_loss: 58.7564\n",
      "Epoch 942/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.6021 - val_loss: 58.7523\n",
      "Epoch 943/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.5987 - val_loss: 58.7509\n",
      "Epoch 944/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.5936 - val_loss: 58.7515\n",
      "Epoch 945/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.5871 - val_loss: 58.7536\n",
      "Epoch 946/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.5835 - val_loss: 58.7455\n",
      "Epoch 947/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.5750 - val_loss: 58.7474\n",
      "Epoch 948/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.5735 - val_loss: 58.7379\n",
      "Epoch 949/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.5670 - val_loss: 58.7400\n",
      "Epoch 950/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.5634 - val_loss: 58.7378\n",
      "Epoch 951/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.5555 - val_loss: 58.7302\n",
      "Epoch 952/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.5548 - val_loss: 58.7197\n",
      "Epoch 953/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.5482 - val_loss: 58.7141\n",
      "Epoch 954/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.5458 - val_loss: 58.7194\n",
      "Epoch 955/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.5407 - val_loss: 58.7170\n",
      "Epoch 956/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.5335 - val_loss: 58.7117\n",
      "Epoch 957/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.5317 - val_loss: 58.7030\n",
      "Epoch 958/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.5223 - val_loss: 58.7021\n",
      "Epoch 959/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.5194 - val_loss: 58.6921\n",
      "Epoch 960/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.5145 - val_loss: 58.6925\n",
      "Epoch 961/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.5096 - val_loss: 58.6939\n",
      "Epoch 962/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.5031 - val_loss: 58.6904\n",
      "Epoch 963/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.4983 - val_loss: 58.6790\n",
      "Epoch 964/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.4954 - val_loss: 58.6707\n",
      "Epoch 965/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 47.4908 - val_loss: 58.6674\n",
      "Epoch 966/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.4852 - val_loss: 58.6659\n",
      "Epoch 967/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.4818 - val_loss: 58.6592\n",
      "Epoch 968/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 47.4759 - val_loss: 58.6676\n",
      "Epoch 969/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 47.4727 - val_loss: 58.6597\n",
      "Epoch 970/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.4615 - val_loss: 58.6530\n",
      "Epoch 971/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.4597 - val_loss: 58.6490\n",
      "Epoch 972/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.4562 - val_loss: 58.6321\n",
      "Epoch 973/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.4494 - val_loss: 58.6301\n",
      "Epoch 974/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.4465 - val_loss: 58.6277\n",
      "Epoch 975/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.4414 - val_loss: 58.6229\n",
      "Epoch 976/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.4340 - val_loss: 58.6127\n",
      "Epoch 977/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.4343 - val_loss: 58.6101\n",
      "Epoch 978/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.4298 - val_loss: 58.6055\n",
      "Epoch 979/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.4260 - val_loss: 58.6050\n",
      "Epoch 980/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.4235 - val_loss: 58.6076\n",
      "Epoch 981/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.4157 - val_loss: 58.6056\n",
      "Epoch 982/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.4095 - val_loss: 58.6022\n",
      "Epoch 983/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.4042 - val_loss: 58.6051\n",
      "Epoch 984/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.4011 - val_loss: 58.6051\n",
      "Epoch 985/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.3938 - val_loss: 58.6011\n",
      "Epoch 986/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 47.3927 - val_loss: 58.5999\n",
      "Epoch 987/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.3873 - val_loss: 58.5973\n",
      "Epoch 988/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.3828 - val_loss: 58.5965\n",
      "Epoch 989/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.3793 - val_loss: 58.5949\n",
      "Epoch 990/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.3709 - val_loss: 58.5928\n",
      "Epoch 991/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 47.3647 - val_loss: 58.5882\n",
      "Epoch 992/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.3639 - val_loss: 58.5762\n",
      "Epoch 993/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.3550 - val_loss: 58.5713\n",
      "Epoch 994/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.3527 - val_loss: 58.5650\n",
      "Epoch 995/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.3461 - val_loss: 58.5598\n",
      "Epoch 996/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.3422 - val_loss: 58.5597\n",
      "Epoch 997/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.3394 - val_loss: 58.5582\n",
      "Epoch 998/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.3326 - val_loss: 58.5578\n",
      "Epoch 999/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.3265 - val_loss: 58.5534\n",
      "Epoch 1000/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.3263 - val_loss: 58.5495\n",
      "Epoch 1001/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.3200 - val_loss: 58.5487\n",
      "Epoch 1002/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.3137 - val_loss: 58.5425\n",
      "Epoch 1003/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.3124 - val_loss: 58.5451\n",
      "Epoch 1004/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.3057 - val_loss: 58.5416\n",
      "Epoch 1005/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.2996 - val_loss: 58.5498\n",
      "Epoch 1006/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.2995 - val_loss: 58.5413\n",
      "Epoch 1007/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.2905 - val_loss: 58.5334\n",
      "Epoch 1008/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.2876 - val_loss: 58.5306\n",
      "Epoch 1009/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.2819 - val_loss: 58.5322\n",
      "Epoch 1010/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.2736 - val_loss: 58.5346\n",
      "Epoch 1011/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.2712 - val_loss: 58.5310\n",
      "Epoch 1012/5000\n",
      "1126/1126 [==============================] - 0s 46us/step - loss: 47.2679 - val_loss: 58.5254\n",
      "Epoch 1013/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.2619 - val_loss: 58.5236\n",
      "Epoch 1014/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.2553 - val_loss: 58.5134\n",
      "Epoch 1015/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.2511 - val_loss: 58.5106\n",
      "Epoch 1016/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.2478 - val_loss: 58.5045\n",
      "Epoch 1017/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.2433 - val_loss: 58.5053\n",
      "Epoch 1018/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 47.2375 - val_loss: 58.4990\n",
      "Epoch 1019/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.2336 - val_loss: 58.4949\n",
      "Epoch 1020/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.2292 - val_loss: 58.4945\n",
      "Epoch 1021/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.2280 - val_loss: 58.4876\n",
      "Epoch 1022/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.2226 - val_loss: 58.4873\n",
      "Epoch 1023/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.2163 - val_loss: 58.4829\n",
      "Epoch 1024/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.2092 - val_loss: 58.4811\n",
      "Epoch 1025/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.2056 - val_loss: 58.4785\n",
      "Epoch 1026/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.1996 - val_loss: 58.4752\n",
      "Epoch 1027/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.1947 - val_loss: 58.4693\n",
      "Epoch 1028/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.1945 - val_loss: 58.4666\n",
      "Epoch 1029/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.1879 - val_loss: 58.4611\n",
      "Epoch 1030/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.1827 - val_loss: 58.4535\n",
      "Epoch 1031/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.1764 - val_loss: 58.4526\n",
      "Epoch 1032/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.1746 - val_loss: 58.4423\n",
      "Epoch 1033/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 47.1705 - val_loss: 58.4345\n",
      "Epoch 1034/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.1658 - val_loss: 58.4325\n",
      "Epoch 1035/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.1626 - val_loss: 58.4358\n",
      "Epoch 1036/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.1560 - val_loss: 58.4406\n",
      "Epoch 1037/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.1514 - val_loss: 58.4384\n",
      "Epoch 1038/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.1450 - val_loss: 58.4388\n",
      "Epoch 1039/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.1398 - val_loss: 58.4363\n",
      "Epoch 1040/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 47.1360 - val_loss: 58.4321\n",
      "Epoch 1041/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.1310 - val_loss: 58.4299\n",
      "Epoch 1042/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 47.1255 - val_loss: 58.4205\n",
      "Epoch 1043/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.1261 - val_loss: 58.4118\n",
      "Epoch 1044/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.1209 - val_loss: 58.4125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1045/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 47.1155 - val_loss: 58.4142\n",
      "Epoch 1046/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.1143 - val_loss: 58.4085\n",
      "Epoch 1047/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.1061 - val_loss: 58.4032\n",
      "Epoch 1048/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.1004 - val_loss: 58.4007\n",
      "Epoch 1049/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.0986 - val_loss: 58.3976\n",
      "Epoch 1050/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.0919 - val_loss: 58.3912\n",
      "Epoch 1051/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.0906 - val_loss: 58.3975\n",
      "Epoch 1052/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.0860 - val_loss: 58.3976\n",
      "Epoch 1053/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.0792 - val_loss: 58.3932\n",
      "Epoch 1054/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 47.0739 - val_loss: 58.3889\n",
      "Epoch 1055/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 47.0684 - val_loss: 58.3867\n",
      "Epoch 1056/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 47.0642 - val_loss: 58.3927\n",
      "Epoch 1057/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 47.0597 - val_loss: 58.3916\n",
      "Epoch 1058/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 47.0536 - val_loss: 58.3883\n",
      "Epoch 1059/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.0464 - val_loss: 58.3872\n",
      "Epoch 1060/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.0439 - val_loss: 58.3802\n",
      "Epoch 1061/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.0425 - val_loss: 58.3748\n",
      "Epoch 1062/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.0339 - val_loss: 58.3705\n",
      "Epoch 1063/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.0324 - val_loss: 58.3630\n",
      "Epoch 1064/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.0266 - val_loss: 58.3613\n",
      "Epoch 1065/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.0220 - val_loss: 58.3618\n",
      "Epoch 1066/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.0181 - val_loss: 58.3479\n",
      "Epoch 1067/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.0135 - val_loss: 58.3486\n",
      "Epoch 1068/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.0083 - val_loss: 58.3512\n",
      "Epoch 1069/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.0025 - val_loss: 58.3493\n",
      "Epoch 1070/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.9999 - val_loss: 58.3479\n",
      "Epoch 1071/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 46.9987 - val_loss: 58.3460\n",
      "Epoch 1072/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 46.9892 - val_loss: 58.3410\n",
      "Epoch 1073/5000\n",
      "1126/1126 [==============================] - 0s 29us/step - loss: 46.9844 - val_loss: 58.3405\n",
      "Epoch 1074/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 46.9807 - val_loss: 58.3414\n",
      "Epoch 1075/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 46.9741 - val_loss: 58.3405\n",
      "Epoch 1076/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.9758 - val_loss: 58.3415\n",
      "Epoch 1077/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 46.9672 - val_loss: 58.3361\n",
      "Epoch 1078/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.9640 - val_loss: 58.3288\n",
      "Epoch 1079/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.9565 - val_loss: 58.3244\n",
      "Epoch 1080/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.9541 - val_loss: 58.3265\n",
      "Epoch 1081/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.9517 - val_loss: 58.3206\n",
      "Epoch 1082/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 46.9428 - val_loss: 58.3198\n",
      "Epoch 1083/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 46.9418 - val_loss: 58.3212\n",
      "Epoch 1084/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.9339 - val_loss: 58.3207\n",
      "Epoch 1085/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 46.9316 - val_loss: 58.3158\n",
      "Epoch 1086/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 46.9241 - val_loss: 58.3119\n",
      "Epoch 1087/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.9185 - val_loss: 58.3157\n",
      "Epoch 1088/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.9176 - val_loss: 58.3299\n",
      "Epoch 1089/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.9113 - val_loss: 58.3272\n",
      "Epoch 1090/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.9080 - val_loss: 58.3222\n",
      "Epoch 1091/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 46.9064 - val_loss: 58.3200\n",
      "Epoch 1092/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.8991 - val_loss: 58.3199\n",
      "Epoch 1093/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 46.8943 - val_loss: 58.3220\n",
      "Epoch 1094/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 46.8895 - val_loss: 58.3245\n",
      "Epoch 1095/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.8835 - val_loss: 58.3214\n",
      "Epoch 1096/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 46.8803 - val_loss: 58.3145\n",
      "Epoch 01096: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model(32, X_train.shape[1], 'mean_squared_error', 'adagrad')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto', patience=10)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=5000, validation_data=(X_valid, y_valid), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6EVEYk5BLyIScwp6EZGYU9CLiMTc/wc2utT6YXEE2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f475a146c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXv0ZFV15z9fEUXRFWzodBBoGrXR\noEaUjkB0HELTGRQVJ8uARrMgIYNm8iD4os0kK2aWrpAXBEcTwSc+RjGYBANOYk8rSYwIaRAU5KXQ\nRLCBlocIju89f9S9zenT99x7blXdqlt192et3/pV3cc5+56qOvucvffZR2aG4ziOM1weMW8BHMdx\nnPniisBxHGfguCJwHMcZOK4IHMdxBo4rAsdxnIHjisBxHGfguCJw5o6kt0j68Izqequkb0q6cxb1\nBfU+KOlJM6jnA5Le2nU9znLhisAZDJJWA68HDjGzn+qwnksl/Xp4zMweZ2a3dFXnvJC0VdIxUyjn\nZEmfm4ZMTntcEThTRdIj5y1DDauBe8zs7nkL4jh9whXBgJD0RkmfiI69XdI5DfddKumPJV0h6QFJ\nF0laUZxbI8kknSLpP4DPFMePkPR5SfdLukbSUUF5B0n6Z0nflrQJ2Keh/hdLuroo6/OSfiY4t1XS\nGyR9SdK3JF0gaY+KMo4BNgFPLMw0HyiOv1TSdUXZl0r66dyyJR1fyPWApK9JOlbS24D/BLyjqOcd\nxbUm6SnF65+Q9EFJ2yXdJun3JT2iOHeypM9J+nNJ90m6VdILa9rm2ZKuKtryAmCP6Hyy7aLr3inp\nL6Jjn5R0ek3dH2KkXP+heNY3FcfrPvuTJd1SyHurpFcVbf4u4MiinPtTdTodYWb+N5A/YF/gIWCv\n4v0jgbuBwxruuxS4A3gGsCfwCeDDxbk1gAEfLM49BtgPuAd4EaPBxobi/crinsuAs4BHAy8Avl2W\nV1H3swsZDwd2A04CtgKPLs5vBa4AngisAK4HXpso6yjg9uD9wUV7bAB2B94EfBV4VFPZwHOBbxX3\nPqJ45qcF7fXrUd0GPKV4/UHgIuDxRfvdBJxSnDsZ+AHw34rn/Q3gG4AqnudRwG3A6YX8Ly/ufWtO\n20VlPbeo5xHF+32A7wCrGr4bW4FjgvfJz774fjwAPDX4Pj49eO7Pzfs3MtQ/nxEMCDPbBvwL8EvF\noWOBb5rZlRm3f8jMrjWzh4A/AE6QtFtw/i1m9pCZ/T/g1cCnzOxTZvZjM9sEbAFeVNjpfxb4AzP7\nnpn9C/APNfWeCpxrZpeb2Y/M7Hzge8ARwTVvN7NvmNm9RVmHZjwPwInAJWa2ycx+APw5I0X2cxll\nnwK8r7j3x2Z2h5nd0FRh0WavAN5sZt82s63AXwC/Elx2m5m928x+BJzPqMNcVVHcEYwUwF+a2Q/M\n7ELg34PzOW0HgJldwUixrS8OvQK41MzuanqmiORnX5z/MfAMSY8xs21mdl3L8p0OcEUwPM5n9GOl\n+P+hzPu+Hry+jVEHtE/i/IHALxWmgfuLqf7zGXVoTwTuKxRKWF6KA4HXR2UdUJRTEkYAfQd4XOYz\nPTGs28x+XDzHfhllHwB8LbOekH0YtV34zLel6jSz7xQvq57picAdZhZmjgzLzWm7kHG/GyHJz774\nzE8EXgtsk3SJpKeNUYczZVwRDI+/B35G0jOAFwMfybzvgOD1akYmiG8Gx8LO6OuMZhB7BX97mtmZ\nwDbgCZL2jMpL8XXgbVFZjzWzj2bKXcc3GHVcAEgSo+e8I+PerwNPTpyrS+n7TUZtd2BwbHVmnTHb\ngP0KucOyQhnbtN2HgeMlPQv4aUbflSbiZ6377DGzfzKzDYwGBTcA706U48wQVwQDw8y+C1wI/G/g\nCjP7j8xbXy3pEEmPBf4ncGFhuqjiw8BLJP0XSbtJ2kPSUZL2N7PbGJkK/kjSoyQ9H3hJTb3vBl4r\n6XCN2FPScZIenyl3HR8HjpO0XtLujEJLvwd8PuPe9wK/Wtz7CEn7BaPbu4DKNQNFm30ceJukx0s6\nEHgdozZry2XAD4HfkbS7pF9kZOsvadV2ZnY7I9PSh4BPFGa+JuJnTX72klYVDvY9GbXzg4xMRWU5\n+0t6VIvnd6aEK4Jhcj7wTNpN/T8EfICR2WIP4HdSF5rZ14Hjgd8DtjMaJb6Rh79vv8zIgXkv8IeM\nnKepsrYwcpy+A7iPkTP35BZyJzGzGxmZQP4Xo5H6S4CXmNn3M+69AvhV4GxGtvV/5uFR/jnAy4uo\nn7dX3P7bjJzUtwCfY6SU3zeG/N8HfpFRe9zLyOzyt8H5cdqu7Xfjj4HfL8xAb2j47B/BSOl9o5D3\nPzNyhsMo2uw64E5J38SZKdrZvOgMgcJhewPwU2b2QMb1lzKK6nlP17I580XSCxiN6g807xwGg88I\nBkYRr/464GM5SsAZDoV57DTgPa4EhkWfV4E6U6awzd7FKLLk2Ojcg4nbkouZnOWhWNS1BbiGkcmr\nPL4a+EritkNa+JicHuOmIcdxnIHjpiHHcZyBsxCmoX322cfWrFkzbzEcx3EWiiuvvPKbZray6bqF\nUARr1qxhy5Yt8xbDcRxnoZBUt2p/B24achzHGTiuCBzHcQaOKwLHcZyB05kikPTUYkOM8u8BSb8r\naYWkTZJuLv4/oSsZHMdxnGY6UwRmdqOZHWpmhwKHMUrh+3fARmCzma0FNhfvHcdxnDkxK9PQeuBr\nRebJ4xkltqL4/7IZyeA4jjN1zt5007xFmJhZKYJXAGUO9FXFTlkwymRZtfMSkk6VtEXSlu3bt89C\nRsdxnNacs/nmeYswMZ0rgiK/+EuBv4nPFYmtKnNcmNl5ZrbOzNatXNm4HsJxHMcZk1ksKHshcFWw\n9+ldkvY1s22S9mW0ubbjOM7CcPamm3aaCazZeAkAp61fy+kbDp6XWGMzC0XwSh42CwF8EjgJOLP4\nf9EMZHAcx5kap284eEeHv2bjJWw987g5SzQZnZqGirTHGwh2TWKkADZIuhk4pnjvOI7jzIlOZwRm\n9hCwd3TsHkZRRI7jOAvPaevXzluEifGVxY7jOBOwiD6BGFcEjuM4A8cVgeM4zsBxReA4jjNwXBE4\njuMMHFcEjuM4A8cVgeM4zsBxReA4jjNwXBE4jrNwLEPq5z7hisBxnIVjGVI/9wlXBI7jOANnFtlH\nHcdxJmbZUj/3CY32huk369atsy1btsxbDMdxesIypH6eBZKuNLN1Tde5achxHGfguCJwHGfhWIbU\nz33CFYHjOAuH+wSmiysCx3GcgeOKwHEcZ+C4InAcxxk4rggcx3EGTqeKQNJeki6UdIOk6yUdKWmF\npE2Sbi7+P6FLGRzHcZx6up4RnAP8o5k9DXgWcD2wEdhsZmuBzcV7x3EcZ050pggk/QTwAuC9AGb2\nfTO7HzgeOL+47HzgZV3J4DiOU4VnL92ZLmcEBwHbgfdL+qKk90jaE1hlZtuKa+4EVlXdLOlUSVsk\nbdm+fXuHYjqOMzQ8e+nOdKkIHgk8B/hrM3s28BCRGchGiY4qkx2Z2Xlmts7M1q1cubJDMR3HcYZN\nl9lHbwduN7PLi/cXMlIEd0na18y2SdoXuLtDGRzHcQDPXlpHZ4rAzO6U9HVJTzWzG4H1wFeKv5OA\nM4v/F3Ulg+M4TsnpGw7e0eF79tKd6Xo/gt8GPiLpUcAtwK8yMkd9XNIpwG3ACR3L4DiO49TQqSIw\ns6uBqlzY67us13Ecpw7PXrozvrLYcZzBMXSfQIwrAsdxnIHjisBxHGfguCJwHMcZOK4IHMdxBo4r\nAsdxnIHjisBxHGfguCJwHMcZOK4IHMdxBo4rAsdxnIHjisBxHGfguCJwHMcZOK4IHMdxBo4rAsdx\nnIHjisBxHGfguCJwHMfpgLM33TRvEbJxReA4jtMB4f7IfccVgeM4zsDpes9ix3F6ztmbbvIdu6bE\n2Ztu2mkmsGbjJcBoa8w+t7ErAscZOOdsvrnXndQicfqGg3e05ZqNl7D1zOPmLFEenZqGJG2V9GVJ\nV0vaUhxbIWmTpJuL/0/oUgbHcfrDIjlQh8QsfAQ/b2aHmtm64v1GYLOZrQU2F+8dx5khZ2+6iTUb\nL9lhuihfd91RL5IDdVJOW7923iJkMw/T0PHAUcXr84FLgTPmIIfjDJZFNWEsEotkbutaERjwaUkG\nnGtm5wGrzGxbcf5OYFXVjZJOBU4FWL16dcdiOo7TFYvqQB0SXSuC55vZHZJ+Etgk6YbwpJlZoSR2\noVAa5wGsW7eu8hrHcSanaxOGzz76T6c+AjO7o/h/N/B3wHOBuyTtC1D8v7tLGRzHqcdH5U5nikDS\nnpIeX74GfgG4FvgkcFJx2UnARV3J4AwTj0zpL4vkQB0SXc4IVgGfk3QNcAVwiZn9I3AmsEHSzcAx\nxXvHmRpDikxZNHz20U868xGY2S3AsyqO3wOs76pex3Ecpx2+sthZCjwyxXHGR2b9D8hZt26dbdmy\nZd5iOFOmqxw3k0ameO4dZ1mQdGWwmDeJZx915kZfbfl9lctxusIVgbN0eGSK47TDTUPOTIlt+SXz\ntuX3VS7HmYRc05ArAmdu9HWVaV/lcpy2uI/AcRzHycIVgTM3+mrL76tcjtMVbhpyHMdZUtw05DiO\n42ThisBxnEHjSQpdETjO1PAOZTEJw4aH+hm6InCcCQg7jmVckTy0jnEZP8McPOmc40zAOZtvXuoF\nZ8v6fKkkhUPFo4YcZwJSHcg4K5L7mOxuCIvrpvkZ9o3cqCGfEThOS1LpKICJOs2+jL6HmNK7/NyG\noPiqcB+B47Tk9A0Hs/XM43Z0GOHrZSB+vtPWr2XrmcftUAKL6jdIye0LCF0ROM7UGKdDOXvTTazZ\neMmOUXf5el6dbVW98exnUR2qKbnDWc5QlYKbhhxnAsKOYxyzyekbDt5x37zNEqVJKO4YF7XjH4dl\nNX014YrAcSZgmTqOOJ6+LqpmUfwGQ/R3jINHDTlOT5hX1FDTXgzxTGXeM5dxWVS5J6E3uYYk7Sbp\ni5IuLt4fJOlySV+VdIGkR3Utg+MsAn1UAs4wmIWz+DTg+uD9nwBnm9lTgPuAU2Ygg+M4FcQRQsBO\nEUKwqwN1UR2qiyr3LOhUEUjaHzgOeE/xXsDRwIXFJecDL+tSBsdx8qnqLOOZwaLOFBZV7lnQ9Yzg\nL4E3AT8u3u8N3G9mPyze3w7sV3WjpFMlbZG0Zfv27R2L6TjOspqDFnXdwyzpTBFIejFwt5ldOc79\nZnaema0zs3UrV66csnSO0z+aOqzcDm3cjm/RlEDuc/Yx/LVvyqnLGcHzgJdK2gp8jJFJ6BxgL0ll\n2Or+wB0dyuAMnL794Opo6rByO7QuOr4+tmMfO/hc+iZ7Z4rAzN5sZvub2RrgFcBnzOxVwGeBlxeX\nnQRc1JUMjjPtH1wfO8RZ0LeOq4m+rdgel1nJ27iOQNIjA5t+8lhDGUcBbzCzF0t6EqMZwgrgi8Cr\nzex7dff7OgJnXKYdOz7t8prCN3PDO7sOA23z3JOsh2i6d5zn7Mv6gXnInruOADOr/QOuyjnW5d9h\nhx1mjpPLWZ++0Q484+Jd/s769I0Tl33gGRdPQcLxys6tO3Vd2+fPbcf4/SRt1ObeSdvDrH2bTItp\nyJ4DsMUy+tikaUjST0p6FvAYSc+U9DPF3/OBx46tohxnCqSmzOWIsio7aO4oNS57UjND3XWzNGE0\nmXfiOnPbcVyzUd1nOE3q1g/00eQ1D7NWXa6h44BfY+TQfSeg4vi3gT/oTCKnF/Rxk5SQVO7+aeT0\nj8soE8OVP8y2U/U6mdoknctdEDVuFtRJ2m6cnD5lffG952y+mXM239xo1sp9zj5+j+tkn0ciwqQi\nMLP3A++XdIKZfbxzSZxe0ZdNUiZlXqtJu1akdeXX+Q5SHXTTyDhuxxPPvYzLb713l/vLbKVtOq+4\n44M8ZTtLpTVt+vbbynEW/xbwQTN7QNK7gOcAbzazzbMQENxZPA+aRiLzmDGknG2HH7Rip06ppM0P\ne5pl1+1g1nRfnbzhZzKO87bqnhxndbghTdVItXwd/0/J0tVnOA59cSSnmPR3Nk1n8ZeK/7/AKNTz\nWcCVOQ6Iaf25s3g2tHGyduk0zSFV/zTkqis7p/z4umk4b8vPpqnMlDxV9+R83qk6q16X/3OfKyyj\nvCd+zq6Z9/e4a8h0FufsR1BOGV7EaGZwjSTf2WwJ6dMmKYtIUw7/mND8lhr51ZXZ1qQRmndKx2M4\nqg/fp6iqP3wdHmszki3b4vQNB8/UgeuJ6EbkKIJrJH0KOBj4PUmP42Hl4AyItrbVLs1HqR/wNH7Y\ncRk5z11nYskh5ZNJOapzTHcpBRJ2tlVZRnMVWlx/28FDl59hLn2z1c+LHB/BbsBhwFfN7F5J+wAH\nmNkXZyEguI9gHrSxV09yzaKR+9xQPbqu8x+0sd+XDtkcZVslcyxjqpyUXyIus5S1zefteyF0T66P\noHFGYGY/KlYDbwDeBjwG3/R+6fEf4sOME2WSGtVWRcikyi2vq9o8/vCDVux4PYlDPKyzDfH1Zbjn\nODQ5mJ3uaVQEkt4B7A68gJEieAh4F/Cz3Yrm9JnUj74PoXnTpq3vJDSxND1zOMKuaqNJ1zCE8owT\nphl+zuHrlBmrDW19AX1f27LI5Izsf87MXgN8F8DM7gV8e8mBUxfDPsmq3r7SZlVnaYNvG5tfd305\nAyhlabPydJK2jxfWheTIUSVTeV9J+bqpjfu4CnhZyHEW/6CIEjIASXvz8EYzjjMIShPMNB2ZsaO2\nrqO7/NZ7kyP7SWYJk5AjR2y6cr9AP0kqgiDD6DuBTwArJf0RcALwRzOSz1lgli00LzZNVL2vs8G3\nCQ9NmYly5Wy6fl6dblvz1LRNjW5eqiYZNSTpKjN7TvH66cAxjPIN/V8zu3Z2InrUkDMfmkavdaPx\nNjb9eOVv+T5n9FzVsU3iTxiXE8+9jAtec+QOmXJG/Sm/SBXjRCVVMTSn9DSihsokc5jZdcB10xDM\ncRaFcXPg5FJ24rH5pI0tvM3otsvRcJgeItd01WZUP6l/YFYzgUWdcdQpgpWSXpc6aWZndSCP43RO\nmx9r0+KqlKmiyiwW5+2JFUB4Tzn6zfUF1JmlDj9oBRe85sjeJRJsK8u4psaybcr26TKSrW9tnEud\naWgb8NcEM4MQM5uZn8BNQ840Gcc8UGWayDVtVCV9a0o/UZJjhopJrUKe9e5q5TXTyhJaVX4uXbVB\nqp6+kGsayvIRzBtXBLMjx9G4KOSslm1DfF+b/DxlJ5SKDipHu3Xncj+TUK5JOtM234U+drCzilDq\ncyTUVH0EznCoykGzqMRJ3SaNPsk1TcQmoLC+lK07zucP4/sjTlu/li/cck/lrGMcu3zb70Jf7ORV\nvoouZFuGZI11imD9zKRwnI4pf6yTRJ/kKpXyXF2eoJKUuaK8ZpyOqyqKqKynLvx1EmL/xrQ722mF\nIk9ipuqDcuuK5MriYgXx2EjaQ9IVkq6RdF2xBgFJB0m6XNJXJV0gyVcpz5l4hSh0v09ql+XWrXYN\nO+FxZDjx3MuSG6vEq3DDFdYp00+VDOHCtWmups1ZyTzud6HrTnLS8idVJLmfw6KunclZWTwu3wOO\nNrMHJe0OfE7S/wFeB5xtZh8rdjw7hZFT2pkTXYdJVtFVdEVqmp5Ka1Dek8sRT9q7cietuMw4mVtZ\nR+n4bTLRdNU2OdeM812YV46p3JG6h47W05kiKHbHebB4u3vxZ8DRwC8Xx88H3oIrgsHT5Y+oLvXz\nOGaXsKMsTT1HPGnvHQuqUnbiurw9dfLWdap17VZ1rqsOe1528i7DNdu21aKGjkK3M4JyL4Mrgacw\nSlXxNeD+InUFwO3Afol7TwVOBVi9enWXYi41bTvYLqe2dT+sLu3KZblVyiC1yUxuh1v6BOrkj49X\nmWhiJZHbqabqrYudz93cZlHNHNNiGZzAuXS6r4CZ/cjMDgX2B54LPK3FveeZ2TozW7dy5crOZFx2\n6mybKft0V6Oa2G5e/u+yvrjukrrsqKGjNj5WEkcDla9zMoLGDtuq15NS1jFJFthxvwtdK5C22VeH\nIsskdDojKDGz+yV9FjgS2CtIaLc/cMcsZHB2Zd5T2RPPvQzYdb/bLu3KTVk+Q1LtE+bVyd1trCSV\nRyjls0itUE7NrGKZwhTPqZnJtM1ys3Acz3qkftr6tZXttCyzhs5mBJJWStqreP0YRjucXQ98Fnh5\ncdlJwEVdyTBUmkYpOaOVrkaqYXmx07U0W3TZkYQROWFHWNVm5f/4dSl3WBY0O1XDDjw1Q6kK7ywV\nZvgMqT0f4nPlc6bMWjDsPP+53+0wLHgZ6dI0tC/wWUlfAv4d2GRmFwNnAK+T9FVgb+C9HcowSOo6\nirIzaprKhl/6af8AcjrBcWjzow7/5z5f3MGW95abxsRmolSbpkI0y//lveX1qSilXBbVgZnDrMJC\nc1hkn0qXUUNfAp5dcfwWRv4CZw6UI5uucs/kpC2oSo4W7sCVW1bMJKausl3qTEep8NMLXnNkZT6h\nkviZq1YRj0uVySIn2mVRtxSNn7VrWbvYL6KPJHMN9QnPNTQ+dQ5PqO8cqqjrKNoqlrp4+lSHWvdj\na5NGoOlZy046zBEUx9en7slp0ziZXBxBlaLMJFr13FXkfCbx8/UtHj6UZxqDl3FzAy2iDyA311Cn\nUUPLziJEBpQj3SpzUdUXv8qkFL6edgfRpryclbBrNl7COZtvTu6VG9cbRzCl2qWpncpr4o68ymYf\nmulKmVPPWJobyjJiJTAtujQF5lD3W+rKNLls+2pPgiuCCVh051H8xR/neSYJn4ttqrllxR16bkhq\nbnqJqk46lCU2Y8X31hE+cyz7aevX7tTx15WX21aLYrduSr3RhxDNRWnLcXDT0ATMa6rYNHWvyqtT\nUpfSOE7J0NZUMK32CFMb5E7jc64LVwJXXQfpdkmt6m1jSgvDTqvqyDERVckxbrtPagqcJrnmN+hm\nl7hlZRppqJ0KZuVkq/uCNjlF2+xu1RSTDvN1glXFaa/ZeMkuMoWRQHU5huKOL7dTqWrzVAx5qr3r\non/C9i6/S23s4m07tDrFOY29gceRoVwJHc+K4radJsusBNrgpqGWzMq+OG2zU2oa3Rd7aSqkMl77\nUGceSMXKV4V9VtWRIrWoq+5YG7NFHNJbvm5jDqkze6VWN6d8F7Mi9dmEaTHijj/3s3Da4TOCBaFp\nJlJ3vqtcPtOkaQScGvFXUWfLrRpZ1tnhc3MjhcfC1zkzyC/cck9l/WWEUE5Iall2lWw5n308I5kV\ndeapcFZXkvL99Pm7vQi4j2ACpm1fzLWHN3WEVTbtLswLMLJ7V5k8JjGVjfN8OTT5Tur8JrFMVTKG\n4atV5pXcUM5c30hOJ5qqdxwfUJfUPcsyhnXOion3LO4TfVUEXTJJbPg4DsdpyDmtH2RTx1Qqn3Hr\nahNHHiqCcReAtdmAvk7B1N3ThSyzps13ady1AEPDncVLTNPUPTQPTHMhzqxo+iFPK+VC2ZE0mV3C\njrauo4ojf+LzOUne6kJTU8QO3pzZyyzoMgX6on63+4orgp5S96MYx6Y9TVL1jNOJTaPenFFg3CnV\njezbdDJ1SiM2YYUKKCVvVXhp0+dXLhpsYtZpJdra7mOfizM7XBH0lHF+mLMaJc1jNJYyBcR7BadI\nOW9hPJ9DuO6gKrx1mp1r23LiTrRO1r5SflY5z+5KY3I8fHRJaAqhW3S7aSrcsY2ZqM4hmUpLkepk\nwtXHOecnWYGdIlVmlSyzYprPmeuPWfTvdh/wGcGSUBXO2DVnb7qp860tUz/ynHpzs36GIbi59Zfl\nVbV5uEFMaBaa9mh83DK7/NwWadbhPIzPCJaUWYySuo7fTo0IDz9oRdaeCk2L5eIdveL62kYIxb6A\nvtLnuPsuZk5OMz4jWGC6cv71Ia68jiOetPcOp2oqQqeJsI3adPjjLuw7/KAVO5mxpu2o7aOdfByZ\nFnVG0fffTBO+jmBJGLdDTJWVm5uoZFodWm7yuHiFcNvFcjkJ11L1l+TE95fnw4Rzs+zgyudexLj7\nRVIEfZXV1xE4ndA2tHLanUyYe6jNbChWAqlon6r4+6okd22ZdO3DuITrSRZtpN3HWc6y4j6CnjCu\nDTTOrjmuTfXEcy+bum12nFW4cYcb2vjXbLxkF3t+vHFLbihpW6ocyTkL+9ocT9U1VPo6UylZJn+G\nzwh6Qp0Dr25kPa2RXpiyIbecrheqlbKEaZmrVvnmLqaqmhXArtE+5fmy/rKOcBvKnFTNX7jlnl2U\nNDQvvJvUmds0W/KR9nRYxFlWis4UgaQDgA8CqwADzjOzcyStAC4A1gBbgRPM7L6u5FgG+hrlUSVT\nnIQu1ylaZ8MOy4nvye3Yyo48fh/vu5CbyC2HcJVwqqPownzW1EH18bvkzJcuZwQ/BF5vZldJejxw\npaRNwMnAZjM7U9JGYCNwRody9JZpRP1MmnahLj1CW1lgvJlFSZinp3xfyllFVWceEneyqfJDH0Dc\niYak3qfaKKeTb5Ou2ukviz7L6kwRmNk2YFvx+tuSrgf2A44HjiouOx+4lAVRBNMevdWN3OrCEMOR\nZtiBte14U/WHmTarzCllxzzNENW6BXGxWagusVtYfjwLaOrYqwjXGtQlcqv6boTP1GQO6srMsOgd\n1KKw6Mp6Js5iSWuAZwOXA6sKJQFwJyPTUdU9p0raImnL9u3bZyFmI7PcrD61GCqOPik7vGk7qKqe\nNXTUxjtiVTnN9ttrj6zyY3t8eX4ajuqtZx6X1RlWOfrabOjT9N0IlfcsnYyL3kE5s6FzZ7GkxwGf\nAH7XzB6QtOOcmZmkyoUMZnYecB6M1hF0Lee8GXfkFnbOk4z+whTJITkZTOtmFjHxhijjbL5SZ8Jq\nSiEdh4qmNpEpnyuOTgplrCLHxJNqr7LtfRTvzJpOF5RJ2h24GPgnMzurOHYjcJSZbZO0L3CpmT21\nrpx5Lijrw0Kc1C5gVbSVK6djblNnrAjqzF3h/eHx3A152pQPO5vP6nZWg7xdzJq+Gzkmnrr2cpxJ\nmfuCMo2G/u8Fri+VQMEngZOAM4v/F3UlwzToQ4hYnFKhbqes8nisDEL7fso2XxWiCdX7/MaU5R5+\n0IraEXs5+o5H5CHlM1Y9R1goKjIZAAASmklEQVRfTJWjN/V5xSkq4mtzPvNpfDd89O/0gS59BM8D\nfgU4WtLVxd+LGCmADZJuBo4p3js1xPby0n8QU9cRpRKr5RDas8M6Tlu/dscirlLGC15z5E52+fJ1\nnCQOHlYecWrpsMyQsNOs8jHEpMxdsY0+fM4Tz70so0XSjGP/n9eipEVc+OR0Q5dRQ58DlDi9vqt6\nu2Seo7dy5F4lQzxDaHJw1tnRqwjz5cQO3dA3EdYbll81ck5FYFUdr+rIQ6qeN04qV5WOOk4EB6Pw\n16rFZk2Mu/nLPGecfV2f4sweTzrXU+p25Mr1FzRdG+91W9Jk568yH1WV25SobVyfRKrOVKdW9zwp\nZ/I0iJ+1qdOdtSJwn8Tyk+sj8FxDcyBMnJYiNfq//NZ7d5hk4GFTSu614T05o8HT1q/dSc7QxJMi\nNEPFZo4wnj5nVXDcUaU6rriuut276kxD4bWT7h6WMmWlmNVmQsuSH8eZHq4I5kCuvT6VgC2VXTNl\nv68jtKOnOs5YzlDxhIomlDG8LpQhnqE0KYOmRWClYonbJrUOo5QnPhf/z1WUKdqYXbrqhFMO9ap2\ncRPRsHFF0EPqRqzh6C3lL4D6BVthOU0dZ2i/Du/PVWbl+apOqXzONuahUr7T1q/ltPVrdyiW3M50\nlh1e7uh7Ekd+HbNcAOksNp59dEakHLS5C46q7LmpmQE0O2tTMuasKQidx5ffeu8u4aJlJx0/e1le\n+MxhuojQZ9G0MC1+zroReN2MozxXziyaUkHUEbdZuBgtJ1vprPHQVafEFcGMiDvjsHOYRg6jcpQ5\nSeKyMDKpbrVw00KquOPP7RDDMNS43JB4rULYBnXKMVUnPGyymmQDmTqFG7dXm4FBG9okr3NzkFPi\nUUNzoE2kSmohWHgempOixeWl5Kq6J+UcTo3gw7rqVvo2mS7iVBM5q3rj+3JJzbzGVdJtyqmb9U2C\nRwU5c19Z7KQJwyubCM1FVcS+gKZOqypGv2kEmUohEdZf9SyplcTxM1WZgeIOLDb9VC04a9Pp1c2g\nYlPVOIogbg8ffTt9xhVBJtMy31RtjgLt9xEoZwkhqbTLdWXm+A/q5GlKBZHbIY6bj7/NuoqQUkE1\n+WLGdbi2+a5U7ZA2DdwH4OTipqFMupy2ty27aTFXuOCrrtzY7JQjx7gKMbViODZ7hdlA2yw4i/dp\naKJqYVmpCFK5nOpMVY7TR3xBWQ+pi9VvS2oRWbzgKxVWGXayYcqFJsbt/Kruq0qQF7+uW6MQHq9S\nAk05hqrCOcPOPq4jlM1DM51lwk1DNUx7+8C6SJwmUnsBx1TlHapK91DVkVWZWNrkBJoWuRvJxK/j\nWUGVX6HJ1+GjfGeIuGkok3mbhnIVR1UenaaNXkJihVEXSTROe+Tu79DGLFTVjnUbzpTX1qXzboPv\nK+z0FY8amiM5o+WmvP1NxJ1f2HGmnNI5jtXUDKLNs9XRFEkUXpcavYf2/Cr5cmZxdWsl4vdV56Bd\nlJLj9BlXBJm0icAITRKpjjM0YdTF/Fd1avvttUelEikpO9uw46/KMFoejyNmyrQPcURTWV5upFOu\n0pgkHXKsUHNDSn0E7zgP487iTGKzRS5VK0rb1FmV/+ffNq5POotDZ2jsU4gdo4cftKIyDxHsnEyu\n/H/7fd+plPMLt9xTeTxe4xA7aoGsjWDidBXh/U0znKrcPmU5qayocZ1lBtbYuZ8q23EWDfcRjEGb\nVbSwq92+anTexkcQHgvLb/Id1NnQm1bq5tj1c2Quj49bZqr8qrZo2qMgvj7X1OMrdp1FwcNHW9K0\nC1YT8eg9pGo0Pu5IsikPT8qE1VRfHDIZzjhSW0amzEFNIZrlvXF45ripIVKjdDf/OE4ePiOgOsKk\nKldMXd6cVKRN2+iUNhE+KTnCjjG37vj+plnGfnvtwb9trN9xNDVyjkNhQ9qmiUg5e+NFamEyvCaa\nFJIvJnMWhdwZAWbW+7/DDjvMuuTAMy62A8+4eJdjZ336xuT1de/D+1LXluVX1X3Cuz6flK98Hf7F\nch54xsV2wrs+v+Oe8nxYT1W9dfJX1VW+PuvTN1a2Var8+Joq+dpSd2/Vufj5J6nbcfoKsMUy+tjO\nooYkvQ94MXC3mT2jOLYCuABYA2wFTjCz+7qSoYmmTdybQinLMsLXsVO5dDRW1ZManaZGy6nRedXG\nJmUZ8T1V71N7C1e9rlqUllqMlRtpNW7OpXHqchxnVzozDUl6AfAg8MFAEfwpcK+ZnSlpI/AEMzuj\nqawuTENNC5uqYsXjZG+p+1Nx8nFWy7q6x1ns1PaenM42djDHJrCQcReYNSW9q7o2p9ymPROAXcxH\njrNM5JqGOvURSFoDXBwoghuBo8xsm6R9gUvN7KlN5XTtIwg7/boOpGqlalM8fvx/XNqko2hbZh25\nvpKQcVfaNimCcaN1PMrHGSp9jRpaZWbbitd3AqtmXH+S0FkaRsyUHUhs8qmKVsn5XxLGrcfRM+X/\nqhDVaTBJp3j6hvRm8+Xag3FH1m7ecZz5MOsZwf1mtldw/j4ze0Li3lOBUwFWr1592G233daZnCmz\nwJqNlyTTMoRmnDLZWTjyrzP/lIxr+illCmcwcTx8m1lIPIJPRfXESd2mYRqqImfv5DazDjf7OEOl\nr7mG7pK0b2Aaujt1oZmdB5wHI9NQl0LVbQGZ6hBDB2e4gXuTIzg+V6cwyuNxlsxS6aRkL+9vItVx\n56S/CGWc9kg+TDmRs3FOE64EHKeeWZuGPgmcVLw+CbhoxvVXEqcbgOoFTyUXvObIXTqk0pzU1CnG\nnX6VEojNK6n0DFULp+J1DaVMXdjISzNR2Fk7jrN4dBk19FHgKGAf4C7gD4G/Bz4OrAZuYxQ+2rjP\n4CydxdBuIVdMHDWUu1F7Trm5u4ilCE1WuaaVE8+9bJdNX7owteSYgNzE4zjtmLtpyMxemThVvxy1\nJ9TlsKki7LDiFNB1s4TQjh9HJk0z2iUOec1ZIwFU7vw1SbbQFJPunew4zvgMNg111Qg0tXAqpsqu\nn9o4vjx3+EErOOJJe9fWGWfrTNU9DtOwtfcBnxU4zvQZbNK5qiRxcbx8HB4avg+vLW3wqaRzsLPT\nuQwdDa8vy8g1Jc06/XFuMrlpUKfsfK9gx5k+g50RVFE1Os8Z/TeNUGPlUNWZpVbsxikXSrPMuOaZ\nMu1FW2Y5o/ARv+PMlsHOCODhaKF4U5IUdfvfhiPj/fbaA6jeUCWM5ikpX08jZr6JLuz7XTPL2Yjj\nDJHBpaGOc9vAw6kl4nxAbdJB15l06nIApTr5Nqmkx93MZVzmaadfZP+G48yauUcN9Ymw40qNiGNz\nT/w+Jt7xqySVsK5NNFA80o3NVPHK4aZOOXdD91wWbUbhOE49g1AEcefflJo5JM5GGt9T/t9vrz24\n4/7v1pabmzAuXFUbK41xnKXLEjEEno/Icbpg6RVBvNl5W3JmBjFVOf7jdM5N1KWOqNtwftlH68v+\nfI4zD5ZWEeRsJh+nkG5KFBfn/qlTLnUd1iQbroSzhVKGNiN8H1E7jhOztFFDVbmCqjrMsGNM5RdK\n5dJJdapxFNK4IZtl3dPCF2M5jlPFUs4IUquGqzrjMJwz5VQt/z/+0bvxa89/0i73xsRpGao2tMl5\nhro6StoomEUMHXUcp3uWUhHEztE4D1DVgq3UvgMwvTz7bUjtAxzjHbvjOJOylIqgipQ9P+XsLc+N\n62SedsjmuPRFDsdx+svSLygLN5yPwzFTjtacDKNtyHXo1jm4p9FxL3roqOM47fAFZQV1C8niFBBN\nUUZdE5u0Zlm34zjDZWmjhlLEUULh6zCyqC6T6CR1Totx8ux46KjjOFUs9YwgZR+HtJM17mCn0XmO\nY9LJ2fKybbnuE3Acp4qlVgTjpFaIdxSbV+fpnbbjOLNiqRXBuPS1E/YIIMdxumDpo4ZK6lbVzmIf\ngGnjEUCO4zThUUMRTbl/liU7p+M4TlvmEjUk6VhJN0r6qqSN85Bh0fEIIMdxpsXMFYGk3YB3Ai8E\nDgFeKemQWcuRYlE62L6arBzHWTzmMSN4LvBVM7vFzL4PfAw4fg5yVOIdrOM4Q2MeimA/4OvB+9uL\nYzsh6VRJWyRt2b59+8yEcxzHGRq9XVlsZueZ2TozW7dy5cp5i+M4jrO0zEMR3AEcELzfvzjmOI7j\nzIF5KIJ/B9ZKOkjSo4BXAJ+cgxyO4zgOc1hHYGY/lPRbwD8BuwHvM7PrZi2H4ziOM2IhVhZL2g7c\nNm85KtgH+Oa8hWjAZZweiyCnyzgdFkFGaJbzQDNrdLIuhCLoK5K25Czfnicu4/RYBDldxumwCDLC\n9OTsbdSQ4ziOMxtcETiO4wwcVwSTcd68BcjAZZweiyCnyzgdFkFGmJKc7iNwHMcZOD4jcBzHGTiu\nCBzHcQaOK4IMJL1P0t2Srg2OrZC0SdLNxf8nzFPGQqYqOd8i6Q5JVxd/L5qzjAdI+qykr0i6TtJp\nxfHetGeNjL1pS0l7SLpC0jWFjH9UHD9I0uXFXh8XFKv350aNnB+QdGvQlofOU85Cpt0kfVHSxcX7\nXrVlQsaptKMrgjw+ABwbHdsIbDaztcDm4v28+QC7yglwtpkdWvx9asYyxfwQeL2ZHQIcAfxmsR9F\nn9ozJSP0py2/BxxtZs8CDgWOlXQE8CeFjE8B7gNOmaOMkJYT4I1BW149PxF3cBpwffC+b20Ju8oI\nU2hHVwQZmNm/APdGh48Hzi9enw+8bKZCVZCQs1eY2TYzu6p4/W1GX+r96FF71sjYG2zEg8Xb3Ys/\nA44GLiyOz/17WSNnr5C0P3Ac8J7ivehZW8YyThNXBOOzysy2Fa/vBFbNU5gGfkvSlwrT0dxNWCWS\n1gDPBi6np+0ZyQg9asvCTHA1cDewCfgacL+Z/bC4pHKvj1kTy2lmZVu+rWjLsyU9eo4iAvwl8Cbg\nx8X7velfW8Yylkzcjq4IpoCNYnB7N8op+GvgyYym5duAv5ivOCMkPQ74BPC7ZvZAeK4v7VkhY6/a\n0sx+ZGaHMkrl/lzgafOUJ0Usp6RnAG9mJO/PAiuAM+Yln6QXA3eb2ZXzkqGJGhmn0o6uCMbnLkn7\nAhT/756zPJWY2V3FD/HHwLsZdRhzRdLujDrYj5jZ3xaHe9WeVTL2sS0BzOx+4LPAkcBeksqswr3a\n6yOQ89jC/GZm9j3g/cy3LZ8HvFTSVkZb5x4NnEO/2nIXGSV9eFrt6IpgfD4JnFS8Pgm4aI6yJCk7\n14L/ClybunYWFLbX9wLXm9lZwanetGdKxj61paSVkvYqXj8G2MDIl/FZ4OXFZXP/XibkvCFQ+mJk\ne59bW5rZm81sfzNbw2h/lM+Y2avoUVsmZHz1tNpx5vsRLCKSPgocBewj6XbgD4EzgY9LOoVRiuwT\n5ifhiIScRxUhZQZsBV4zNwFHPA/4FeDLhd0Y4PfoV3umZHxlj9pyX+B8SbsxGtB93MwulvQV4GOS\n3gp8kZFCmycpOT8jaSUg4GrgtfMUMsEZ9Kstq/jINNrRU0w4juMMHDcNOY7jDBxXBI7jOAPHFYHj\nOM7AcUXgOI4zcFwROE6ApKdLeum85XCcWeKKwFlqJP2oyMp4raS/kfTYmmtXA/8DuDRx/qgg6+NL\nJSUT40naS9J/D94/UdKFqesdZ554+Kiz1Eh60MweV7z+CHBltEhMjH4Hcf6WqrKOAt5gZi/OuHYN\ncLGZPWNM0R1nZviMwBkS/wo8RdIaSTdK+iCjlZgHSPoFSZdJuqqYOZTK41hJN0i6CvjFsiBJJ0t6\nR/F6laS/0yjn/jWSfo7RArknF7ORPyvqvLa4fg9J75f0ZY1yy/98UObfSvpHjfZl+NPZNo8zVFwR\nOIOgyBnzQuDLxaG1wF+Z2dOBh4DfB44xs+cAW4DXSdqDUU6hlwCHAT+VKP7twD8XOfefA1zHaD+F\nrxU54t8YXf+bjHLrPRN4JaOVt3sU5w4FTgSeCZwo6YAJH91xGnFF4Cw7jynSRGwB/oOH0wTcZmZf\nKF4fARwC/Ftx7UnAgYyyOt5qZjcXGVE/nKjjaEaZSctMm99qkOn5ZVlmdgOjlBoHF+c2m9m3zOy7\nwFcKORynUzzXkLPs/L8iBfIORm4BHgoPMcqT/8rounlsn/i94PWP8N+oMwN8RuA48AXgeZKeAiBp\nT0kHAzcAayQ9ubjulYn7NwO/Udy7m6SfAL4NPD5x/b8CryquPxhYDdw4jQdxnHFwReAMHjPbDpwM\nfFTSl4DLgKcV5plTgUsKZ3Fqj4TTgJ+X9GXgSuAQM7uHkanpWkl/Fl3/V8AjiusvAE4u8sk7zlzw\n8FHHcZyB4zMCx3GcgeOKwHEcZ+C4InAcxxk4rggcx3EGjisCx3GcgeOKwHEcZ+C4InAcxxk4/x+C\n+XHO6mL3ewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f474a586550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "plt.title('Coût et coût de validation')\n",
    "line1,=plt.plot(history.history['loss'], label=\"Loss\", linestyle='-', color='r')\n",
    "line2,=plt.plot(history.history['val_loss'], label=\"Val loss\", linestyle='-', color='b')\n",
    "first_legend = plt.legend(handles=[line1, line2], loc=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.title('y_pred en fonction de y_test')\n",
    "\n",
    "plt.plot(y_pred[:], y_test[:], '+')\n",
    "plt.ylabel('Test')\n",
    "plt.xlabel('Prédiction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deux couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 929\n",
      "Trainable params: 929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "def double_dense_model(dense_size, input_dim, loss='mean_squared_error', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_size, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(dense_size//2, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = double_dense_model(32, X_train.shape[1], 'mean_squared_error', 'adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1126 samples, validate on 563 samples\n",
      "Epoch 1/5000\n",
      "1126/1126 [==============================] - 0s 217us/step - loss: 491.1893 - val_loss: 398.6684\n",
      "Epoch 2/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 291.6874 - val_loss: 236.4999\n",
      "Epoch 3/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 196.3494 - val_loss: 192.0124\n",
      "Epoch 4/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 168.3906 - val_loss: 171.9573\n",
      "Epoch 5/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 152.3064 - val_loss: 155.4443\n",
      "Epoch 6/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 138.6696 - val_loss: 142.7433\n",
      "Epoch 7/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 127.5782 - val_loss: 132.2642\n",
      "Epoch 8/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 118.4621 - val_loss: 123.2699\n",
      "Epoch 9/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 110.7452 - val_loss: 115.8584\n",
      "Epoch 10/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 104.1761 - val_loss: 109.2723\n",
      "Epoch 11/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 98.4839 - val_loss: 103.7805\n",
      "Epoch 12/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 93.6289 - val_loss: 99.4740\n",
      "Epoch 13/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 89.6955 - val_loss: 95.6870\n",
      "Epoch 14/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 86.3138 - val_loss: 92.6458\n",
      "Epoch 15/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 67.93 - 0s 37us/step - loss: 83.4602 - val_loss: 89.8628\n",
      "Epoch 16/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 80.8597 - val_loss: 87.4006\n",
      "Epoch 17/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 78.6301 - val_loss: 85.1954\n",
      "Epoch 18/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 76.5243 - val_loss: 83.2801\n",
      "Epoch 19/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 74.6234 - val_loss: 81.6665\n",
      "Epoch 20/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 72.9725 - val_loss: 80.2042\n",
      "Epoch 21/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 71.6464 - val_loss: 78.9111\n",
      "Epoch 22/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 70.5094 - val_loss: 77.8112\n",
      "Epoch 23/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 69.4486 - val_loss: 76.7563\n",
      "Epoch 24/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 68.5601 - val_loss: 76.1293\n",
      "Epoch 25/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 67.8123 - val_loss: 75.5646\n",
      "Epoch 26/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 67.1668 - val_loss: 75.0058\n",
      "Epoch 27/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 66.5332 - val_loss: 74.4727\n",
      "Epoch 28/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 66.0150 - val_loss: 74.1301\n",
      "Epoch 29/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 65.5292 - val_loss: 73.8595\n",
      "Epoch 30/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 65.1418 - val_loss: 73.5671\n",
      "Epoch 31/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 64.7630 - val_loss: 73.2466\n",
      "Epoch 32/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 64.3928 - val_loss: 73.0097\n",
      "Epoch 33/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 64.0630 - val_loss: 72.7292\n",
      "Epoch 34/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 63.7999 - val_loss: 72.5558\n",
      "Epoch 35/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 63.4739 - val_loss: 72.3080\n",
      "Epoch 36/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 63.2354 - val_loss: 72.1356\n",
      "Epoch 37/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 62.9516 - val_loss: 72.0578\n",
      "Epoch 38/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 62.7207 - val_loss: 71.8737\n",
      "Epoch 39/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 62.4991 - val_loss: 71.7306\n",
      "Epoch 40/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 62.2926 - val_loss: 71.5090\n",
      "Epoch 41/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 62.0604 - val_loss: 71.4146\n",
      "Epoch 42/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 61.8784 - val_loss: 71.2508\n",
      "Epoch 43/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 61.6459 - val_loss: 71.1042\n",
      "Epoch 44/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 61.4669 - val_loss: 70.9987\n",
      "Epoch 45/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 61.2686 - val_loss: 70.8776\n",
      "Epoch 46/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 61.1348 - val_loss: 70.7285\n",
      "Epoch 47/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 60.9444 - val_loss: 70.5679\n",
      "Epoch 48/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 60.7898 - val_loss: 70.6349\n",
      "Epoch 49/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 60.6453 - val_loss: 70.6915\n",
      "Epoch 50/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 60.5574 - val_loss: 70.7203\n",
      "Epoch 51/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 60.3994 - val_loss: 70.5733\n",
      "Epoch 52/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 60.2682 - val_loss: 70.3545\n",
      "Epoch 53/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 60.0906 - val_loss: 70.2660\n",
      "Epoch 54/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 60.0057 - val_loss: 70.2364\n",
      "Epoch 55/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 59.9017 - val_loss: 70.1342\n",
      "Epoch 56/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 59.7526 - val_loss: 70.0425\n",
      "Epoch 57/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 59.6901 - val_loss: 69.9592\n",
      "Epoch 58/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 59.5694 - val_loss: 69.8729\n",
      "Epoch 59/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 59.5033 - val_loss: 69.7897\n",
      "Epoch 60/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 59.3732 - val_loss: 69.6490\n",
      "Epoch 61/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 59.2768 - val_loss: 69.5986\n",
      "Epoch 62/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 59.2103 - val_loss: 69.5978\n",
      "Epoch 63/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 59.1421 - val_loss: 69.7521\n",
      "Epoch 64/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 59.0494 - val_loss: 69.5902\n",
      "Epoch 65/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 58.9567 - val_loss: 69.4175\n",
      "Epoch 66/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 58.8601 - val_loss: 69.3783\n",
      "Epoch 67/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 58.8003 - val_loss: 69.2985\n",
      "Epoch 68/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 58.6840 - val_loss: 69.1492\n",
      "Epoch 69/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 58.6139 - val_loss: 69.1431\n",
      "Epoch 70/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 58.5054 - val_loss: 69.0561\n",
      "Epoch 71/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 58.4408 - val_loss: 69.0273\n",
      "Epoch 72/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 58.3559 - val_loss: 68.9623\n",
      "Epoch 73/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 58.2927 - val_loss: 68.8829\n",
      "Epoch 74/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 58.2221 - val_loss: 68.8005\n",
      "Epoch 75/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 58.1555 - val_loss: 68.7095\n",
      "Epoch 76/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 40us/step - loss: 58.0507 - val_loss: 68.6009\n",
      "Epoch 77/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 57.9866 - val_loss: 68.5749\n",
      "Epoch 78/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 57.9270 - val_loss: 68.5191\n",
      "Epoch 79/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 57.8502 - val_loss: 68.4694\n",
      "Epoch 80/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 57.7585 - val_loss: 68.3207\n",
      "Epoch 81/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 57.6963 - val_loss: 68.2825\n",
      "Epoch 82/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 57.6257 - val_loss: 68.2221\n",
      "Epoch 83/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 57.5610 - val_loss: 68.1827\n",
      "Epoch 84/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 57.4998 - val_loss: 68.1346\n",
      "Epoch 85/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 57.4158 - val_loss: 68.0685\n",
      "Epoch 86/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 57.3741 - val_loss: 68.0267\n",
      "Epoch 87/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 57.3152 - val_loss: 67.9652\n",
      "Epoch 88/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 57.2427 - val_loss: 67.8254\n",
      "Epoch 89/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 57.1753 - val_loss: 67.7978\n",
      "Epoch 90/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 57.1243 - val_loss: 67.7119\n",
      "Epoch 91/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 57.0749 - val_loss: 67.6308\n",
      "Epoch 92/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.9931 - val_loss: 67.5368\n",
      "Epoch 93/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 56.9400 - val_loss: 67.4738\n",
      "Epoch 94/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.8654 - val_loss: 67.4167\n",
      "Epoch 95/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 56.8192 - val_loss: 67.3806\n",
      "Epoch 96/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 56.7758 - val_loss: 67.2966\n",
      "Epoch 97/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.7347 - val_loss: 67.2300\n",
      "Epoch 98/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 56.6595 - val_loss: 67.1700\n",
      "Epoch 99/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.5833 - val_loss: 67.1418\n",
      "Epoch 100/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 56.5758 - val_loss: 67.1264\n",
      "Epoch 101/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 56.5052 - val_loss: 67.0640\n",
      "Epoch 102/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.4526 - val_loss: 66.9950\n",
      "Epoch 103/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 56.3958 - val_loss: 66.9758\n",
      "Epoch 104/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 56.3567 - val_loss: 66.9220\n",
      "Epoch 105/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.2763 - val_loss: 66.8872\n",
      "Epoch 106/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.2326 - val_loss: 66.8134\n",
      "Epoch 107/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 56.1670 - val_loss: 66.7397\n",
      "Epoch 108/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.1162 - val_loss: 66.7242\n",
      "Epoch 109/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.0830 - val_loss: 66.6296\n",
      "Epoch 110/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 56.0415 - val_loss: 66.5968\n",
      "Epoch 111/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 55.9976 - val_loss: 66.5190\n",
      "Epoch 112/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 55.9497 - val_loss: 66.4776\n",
      "Epoch 113/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 55.8901 - val_loss: 66.4278\n",
      "Epoch 114/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 55.8348 - val_loss: 66.2840\n",
      "Epoch 115/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 55.7995 - val_loss: 66.1989\n",
      "Epoch 116/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 55.7359 - val_loss: 66.1313\n",
      "Epoch 117/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 55.6765 - val_loss: 66.0668\n",
      "Epoch 118/5000\n",
      "1126/1126 [==============================] - 0s 46us/step - loss: 55.6453 - val_loss: 66.0028\n",
      "Epoch 119/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 55.5775 - val_loss: 65.9681\n",
      "Epoch 120/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 55.5153 - val_loss: 65.9086\n",
      "Epoch 121/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 55.5014 - val_loss: 65.8569\n",
      "Epoch 122/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 55.4357 - val_loss: 65.8265\n",
      "Epoch 123/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 55.3949 - val_loss: 65.7474\n",
      "Epoch 124/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 55.3127 - val_loss: 65.6844\n",
      "Epoch 125/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 55.2968 - val_loss: 65.6938\n",
      "Epoch 126/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 55.2199 - val_loss: 65.6413\n",
      "Epoch 127/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 55.2013 - val_loss: 65.5670\n",
      "Epoch 128/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 55.1154 - val_loss: 65.5495\n",
      "Epoch 129/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 55.0990 - val_loss: 65.6790\n",
      "Epoch 130/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 55.0919 - val_loss: 65.5233\n",
      "Epoch 131/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.9969 - val_loss: 65.4447\n",
      "Epoch 132/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 54.9412 - val_loss: 65.4811\n",
      "Epoch 133/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 54.9064 - val_loss: 65.3528\n",
      "Epoch 134/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 54.8521 - val_loss: 65.3002\n",
      "Epoch 135/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.7865 - val_loss: 65.2378\n",
      "Epoch 136/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.7416 - val_loss: 65.1878\n",
      "Epoch 137/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.6906 - val_loss: 65.1048\n",
      "Epoch 138/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 54.6582 - val_loss: 65.0496\n",
      "Epoch 139/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.6030 - val_loss: 64.9989\n",
      "Epoch 140/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.5489 - val_loss: 64.9543\n",
      "Epoch 141/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.5017 - val_loss: 64.9376\n",
      "Epoch 142/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.4678 - val_loss: 64.8518\n",
      "Epoch 143/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.4148 - val_loss: 64.7820\n",
      "Epoch 144/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 54.3761 - val_loss: 64.7159\n",
      "Epoch 145/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.3100 - val_loss: 64.6445\n",
      "Epoch 146/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.2583 - val_loss: 64.5956\n",
      "Epoch 147/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.2412 - val_loss: 64.5743\n",
      "Epoch 148/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.1583 - val_loss: 64.4093\n",
      "Epoch 149/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.1200 - val_loss: 64.3708\n",
      "Epoch 150/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 54.0814 - val_loss: 64.3145\n",
      "Epoch 151/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 32us/step - loss: 54.0198 - val_loss: 64.2355\n",
      "Epoch 152/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.9784 - val_loss: 64.1710\n",
      "Epoch 153/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.9343 - val_loss: 64.1475\n",
      "Epoch 154/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 53.8876 - val_loss: 64.0867\n",
      "Epoch 155/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 53.8592 - val_loss: 64.0589\n",
      "Epoch 156/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 53.7907 - val_loss: 64.0232\n",
      "Epoch 157/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 53.7493 - val_loss: 63.9757\n",
      "Epoch 158/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 53.7093 - val_loss: 63.9164\n",
      "Epoch 159/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.6561 - val_loss: 63.8784\n",
      "Epoch 160/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.6180 - val_loss: 63.8228\n",
      "Epoch 161/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.5712 - val_loss: 63.7366\n",
      "Epoch 162/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.5115 - val_loss: 63.6945\n",
      "Epoch 163/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.4733 - val_loss: 63.6387\n",
      "Epoch 164/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.4275 - val_loss: 63.5958\n",
      "Epoch 165/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.3813 - val_loss: 63.5694\n",
      "Epoch 166/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.3452 - val_loss: 63.4820\n",
      "Epoch 167/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.2910 - val_loss: 63.4087\n",
      "Epoch 168/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.2305 - val_loss: 63.3693\n",
      "Epoch 169/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.2105 - val_loss: 63.3272\n",
      "Epoch 170/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 53.1519 - val_loss: 63.2939\n",
      "Epoch 171/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.1129 - val_loss: 63.2538\n",
      "Epoch 172/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 53.0596 - val_loss: 63.2155\n",
      "Epoch 173/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 53.0011 - val_loss: 63.1647\n",
      "Epoch 174/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.9715 - val_loss: 63.1119\n",
      "Epoch 175/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 52.9321 - val_loss: 63.0546\n",
      "Epoch 176/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.8666 - val_loss: 63.0126\n",
      "Epoch 177/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.8308 - val_loss: 62.9893\n",
      "Epoch 178/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.8071 - val_loss: 62.9408\n",
      "Epoch 179/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.7388 - val_loss: 62.8713\n",
      "Epoch 180/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.6814 - val_loss: 62.8450\n",
      "Epoch 181/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.6468 - val_loss: 62.7949\n",
      "Epoch 182/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 52.5961 - val_loss: 62.7553\n",
      "Epoch 183/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.5438 - val_loss: 62.7091\n",
      "Epoch 184/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.5025 - val_loss: 62.6650\n",
      "Epoch 185/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.4465 - val_loss: 62.6286\n",
      "Epoch 186/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 52.4035 - val_loss: 62.5779\n",
      "Epoch 187/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.3525 - val_loss: 62.5767\n",
      "Epoch 188/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.3206 - val_loss: 62.5134\n",
      "Epoch 189/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.2785 - val_loss: 62.4548\n",
      "Epoch 190/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.2335 - val_loss: 62.4683\n",
      "Epoch 191/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.1815 - val_loss: 62.4152\n",
      "Epoch 192/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.1277 - val_loss: 62.3767\n",
      "Epoch 193/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 52.0934 - val_loss: 62.3242\n",
      "Epoch 194/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.0489 - val_loss: 62.2802\n",
      "Epoch 195/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 52.0090 - val_loss: 62.1907\n",
      "Epoch 196/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.9645 - val_loss: 62.1483\n",
      "Epoch 197/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.9278 - val_loss: 62.1244\n",
      "Epoch 198/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.8717 - val_loss: 62.0866\n",
      "Epoch 199/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.8225 - val_loss: 62.0483\n",
      "Epoch 200/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.7929 - val_loss: 62.0174\n",
      "Epoch 201/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.7376 - val_loss: 61.9502\n",
      "Epoch 202/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.6889 - val_loss: 61.9027\n",
      "Epoch 203/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 51.6402 - val_loss: 61.8589\n",
      "Epoch 204/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.5945 - val_loss: 61.8159\n",
      "Epoch 205/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 51.5483 - val_loss: 61.7565\n",
      "Epoch 206/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.5095 - val_loss: 61.7564\n",
      "Epoch 207/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.4647 - val_loss: 61.7035\n",
      "Epoch 208/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 51.4300 - val_loss: 61.6558\n",
      "Epoch 209/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 51.3637 - val_loss: 61.5945\n",
      "Epoch 210/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.3377 - val_loss: 61.5473\n",
      "Epoch 211/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 51.2911 - val_loss: 61.5039\n",
      "Epoch 212/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.2727 - val_loss: 61.5305\n",
      "Epoch 213/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 51.2135 - val_loss: 61.4659\n",
      "Epoch 214/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.1740 - val_loss: 61.4295\n",
      "Epoch 215/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.1186 - val_loss: 61.3656\n",
      "Epoch 216/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.0674 - val_loss: 61.3016\n",
      "Epoch 217/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 51.0299 - val_loss: 61.2378\n",
      "Epoch 218/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.9897 - val_loss: 61.2078\n",
      "Epoch 219/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.9441 - val_loss: 61.1760\n",
      "Epoch 220/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.9099 - val_loss: 61.1383\n",
      "Epoch 221/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.8660 - val_loss: 61.0813\n",
      "Epoch 222/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 50.8391 - val_loss: 61.0116\n",
      "Epoch 223/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.7836 - val_loss: 60.9585\n",
      "Epoch 224/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.7449 - val_loss: 60.9156\n",
      "Epoch 225/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.7015 - val_loss: 60.8741\n",
      "Epoch 226/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.6732 - val_loss: 60.8369\n",
      "Epoch 227/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.6205 - val_loss: 60.8063\n",
      "Epoch 228/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.5916 - val_loss: 60.7557\n",
      "Epoch 229/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.5330 - val_loss: 60.7034\n",
      "Epoch 230/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 50.4906 - val_loss: 60.6718\n",
      "Epoch 231/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.4524 - val_loss: 60.6263\n",
      "Epoch 232/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.4185 - val_loss: 60.5877\n",
      "Epoch 233/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.3705 - val_loss: 60.5227\n",
      "Epoch 234/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.3375 - val_loss: 60.4839\n",
      "Epoch 235/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.3128 - val_loss: 60.4371\n",
      "Epoch 236/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 50.2683 - val_loss: 60.4015\n",
      "Epoch 237/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 50.2303 - val_loss: 60.3605\n",
      "Epoch 238/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 50.1943 - val_loss: 60.3132\n",
      "Epoch 239/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.1370 - val_loss: 60.2902\n",
      "Epoch 240/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 50.0982 - val_loss: 60.2455\n",
      "Epoch 241/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 50.0686 - val_loss: 60.2168\n",
      "Epoch 242/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 50.0234 - val_loss: 60.1746\n",
      "Epoch 243/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.9864 - val_loss: 60.1089\n",
      "Epoch 244/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.9434 - val_loss: 60.0690\n",
      "Epoch 245/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.9099 - val_loss: 60.0399\n",
      "Epoch 246/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.8738 - val_loss: 59.9945\n",
      "Epoch 247/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.8251 - val_loss: 59.9772\n",
      "Epoch 248/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.7749 - val_loss: 59.9383\n",
      "Epoch 249/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.7491 - val_loss: 59.8990\n",
      "Epoch 250/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.7178 - val_loss: 59.8670\n",
      "Epoch 251/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.6759 - val_loss: 59.8040\n",
      "Epoch 252/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.6639 - val_loss: 59.7626\n",
      "Epoch 253/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.5956 - val_loss: 59.7253\n",
      "Epoch 254/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.5598 - val_loss: 59.6915\n",
      "Epoch 255/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.5181 - val_loss: 59.6836\n",
      "Epoch 256/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.4942 - val_loss: 59.6289\n",
      "Epoch 257/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.4493 - val_loss: 59.5924\n",
      "Epoch 258/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.4124 - val_loss: 59.5383\n",
      "Epoch 259/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.3686 - val_loss: 59.5080\n",
      "Epoch 260/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.3533 - val_loss: 59.4620\n",
      "Epoch 261/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 49.2989 - val_loss: 59.4193\n",
      "Epoch 262/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.2589 - val_loss: 59.3686\n",
      "Epoch 263/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.2455 - val_loss: 59.3223\n",
      "Epoch 264/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 49.2214 - val_loss: 59.3018\n",
      "Epoch 265/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.1652 - val_loss: 59.2634\n",
      "Epoch 266/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 49.1239 - val_loss: 59.2271\n",
      "Epoch 267/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 49.1028 - val_loss: 59.1739\n",
      "Epoch 268/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.0590 - val_loss: 59.1493\n",
      "Epoch 269/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 49.0229 - val_loss: 59.1212\n",
      "Epoch 270/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.9915 - val_loss: 59.0987\n",
      "Epoch 271/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.9563 - val_loss: 59.0748\n",
      "Epoch 272/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.9213 - val_loss: 59.0319\n",
      "Epoch 273/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.8943 - val_loss: 59.0207\n",
      "Epoch 274/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.8590 - val_loss: 58.9734\n",
      "Epoch 275/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.8189 - val_loss: 58.9270\n",
      "Epoch 276/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.7939 - val_loss: 58.8825\n",
      "Epoch 277/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.7494 - val_loss: 58.8628\n",
      "Epoch 278/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.7178 - val_loss: 58.8292\n",
      "Epoch 279/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.6866 - val_loss: 58.7976\n",
      "Epoch 280/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.6476 - val_loss: 58.7551\n",
      "Epoch 281/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.6102 - val_loss: 58.7168\n",
      "Epoch 282/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.5804 - val_loss: 58.6835\n",
      "Epoch 283/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.5540 - val_loss: 58.6452\n",
      "Epoch 284/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.5150 - val_loss: 58.6109\n",
      "Epoch 285/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 48.4955 - val_loss: 58.5838\n",
      "Epoch 286/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.4562 - val_loss: 58.5583\n",
      "Epoch 287/5000\n",
      "1126/1126 [==============================] - 0s 41us/step - loss: 48.4093 - val_loss: 58.5343\n",
      "Epoch 288/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.4002 - val_loss: 58.4894\n",
      "Epoch 289/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.3870 - val_loss: 58.4694\n",
      "Epoch 290/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.3287 - val_loss: 58.4346\n",
      "Epoch 291/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 48.2802 - val_loss: 58.4064\n",
      "Epoch 292/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.2575 - val_loss: 58.3911\n",
      "Epoch 293/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 48.2235 - val_loss: 58.3449\n",
      "Epoch 294/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 48.1890 - val_loss: 58.3293\n",
      "Epoch 295/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.1562 - val_loss: 58.3022\n",
      "Epoch 296/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.1198 - val_loss: 58.2813\n",
      "Epoch 297/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.1087 - val_loss: 58.2606\n",
      "Epoch 298/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 48.0550 - val_loss: 58.2233\n",
      "Epoch 299/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 48.0205 - val_loss: 58.2081\n",
      "Epoch 300/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 48.0028 - val_loss: 58.1697\n",
      "Epoch 301/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 34us/step - loss: 47.9776 - val_loss: 58.1444\n",
      "Epoch 302/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.9511 - val_loss: 58.1400\n",
      "Epoch 303/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.9085 - val_loss: 58.1193\n",
      "Epoch 304/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.8784 - val_loss: 58.1040\n",
      "Epoch 305/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.8590 - val_loss: 58.0771\n",
      "Epoch 306/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.8191 - val_loss: 58.0385\n",
      "Epoch 307/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.7979 - val_loss: 58.0300\n",
      "Epoch 308/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7569 - val_loss: 58.0287\n",
      "Epoch 309/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7367 - val_loss: 58.0089\n",
      "Epoch 310/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.7040 - val_loss: 57.9822\n",
      "Epoch 311/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.6757 - val_loss: 57.9460\n",
      "Epoch 312/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.6292 - val_loss: 57.9725\n",
      "Epoch 313/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.6099 - val_loss: 57.9534\n",
      "Epoch 314/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.5714 - val_loss: 57.9460\n",
      "Epoch 315/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.5514 - val_loss: 57.9108\n",
      "Epoch 316/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.5237 - val_loss: 57.8939\n",
      "Epoch 317/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.4860 - val_loss: 57.9246\n",
      "Epoch 318/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 47.4710 - val_loss: 57.9091\n",
      "Epoch 319/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.4411 - val_loss: 57.8709\n",
      "Epoch 320/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.4055 - val_loss: 57.8352\n",
      "Epoch 321/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.3597 - val_loss: 57.8108\n",
      "Epoch 322/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.3548 - val_loss: 57.8455\n",
      "Epoch 323/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.3258 - val_loss: 57.8000\n",
      "Epoch 324/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.2827 - val_loss: 57.7602\n",
      "Epoch 325/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.2593 - val_loss: 57.7353\n",
      "Epoch 326/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.2334 - val_loss: 57.7064\n",
      "Epoch 327/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.2107 - val_loss: 57.6881\n",
      "Epoch 328/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 47.1649 - val_loss: 57.6556\n",
      "Epoch 329/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.1423 - val_loss: 57.6213\n",
      "Epoch 330/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.1075 - val_loss: 57.5955\n",
      "Epoch 331/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 47.0831 - val_loss: 57.5424\n",
      "Epoch 332/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 47.0518 - val_loss: 57.5080\n",
      "Epoch 333/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 47.0297 - val_loss: 57.4947\n",
      "Epoch 334/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 47.0062 - val_loss: 57.4758\n",
      "Epoch 335/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.9840 - val_loss: 57.4362\n",
      "Epoch 336/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 46.9502 - val_loss: 57.4242\n",
      "Epoch 337/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 46.9115 - val_loss: 57.4151\n",
      "Epoch 338/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.8987 - val_loss: 57.3809\n",
      "Epoch 339/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 46.8641 - val_loss: 57.3698\n",
      "Epoch 340/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.8472 - val_loss: 57.3502\n",
      "Epoch 341/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.8167 - val_loss: 57.3207\n",
      "Epoch 342/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.7931 - val_loss: 57.3159\n",
      "Epoch 343/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.7688 - val_loss: 57.2935\n",
      "Epoch 344/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 46.7554 - val_loss: 57.2800\n",
      "Epoch 345/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.7073 - val_loss: 57.2693\n",
      "Epoch 346/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.6825 - val_loss: 57.2914\n",
      "Epoch 347/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.6598 - val_loss: 57.2715\n",
      "Epoch 348/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 46.6281 - val_loss: 57.2545\n",
      "Epoch 349/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 46.6173 - val_loss: 57.2380\n",
      "Epoch 350/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 46.5716 - val_loss: 57.2263\n",
      "Epoch 351/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 46.5543 - val_loss: 57.2095\n",
      "Epoch 352/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 46.5295 - val_loss: 57.1805\n",
      "Epoch 353/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 46.5055 - val_loss: 57.1582\n",
      "Epoch 354/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 46.4555 - val_loss: 57.1310\n",
      "Epoch 355/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.4456 - val_loss: 57.1182\n",
      "Epoch 356/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 46.4235 - val_loss: 57.1269\n",
      "Epoch 357/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 46.3934 - val_loss: 57.1025\n",
      "Epoch 358/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.3934 - val_loss: 57.0696\n",
      "Epoch 359/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 46.3429 - val_loss: 57.0643\n",
      "Epoch 360/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 46.3222 - val_loss: 57.0668\n",
      "Epoch 361/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 46.3027 - val_loss: 57.0618\n",
      "Epoch 362/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 46.2671 - val_loss: 57.0451\n",
      "Epoch 363/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 46.2505 - val_loss: 57.0211\n",
      "Epoch 364/5000\n",
      "1126/1126 [==============================] - 0s 48us/step - loss: 46.2220 - val_loss: 57.0033\n",
      "Epoch 365/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 46.1882 - val_loss: 56.9673\n",
      "Epoch 366/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 46.1792 - val_loss: 56.9795\n",
      "Epoch 367/5000\n",
      "1126/1126 [==============================] - 0s 42us/step - loss: 46.1494 - val_loss: 56.9456\n",
      "Epoch 368/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 46.1209 - val_loss: 56.9174\n",
      "Epoch 369/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 46.0900 - val_loss: 56.9199\n",
      "Epoch 370/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 46.0814 - val_loss: 56.9065\n",
      "Epoch 371/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.0554 - val_loss: 56.8979\n",
      "Epoch 372/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 46.0344 - val_loss: 56.8822\n",
      "Epoch 373/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 46.0118 - val_loss: 56.8693\n",
      "Epoch 374/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 45.9830 - val_loss: 56.8525\n",
      "Epoch 375/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 45.9618 - val_loss: 56.8364\n",
      "Epoch 376/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 32us/step - loss: 45.9381 - val_loss: 56.8403\n",
      "Epoch 377/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 45.9170 - val_loss: 56.8158\n",
      "Epoch 378/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 45.9079 - val_loss: 56.8059\n",
      "Epoch 379/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 45.8752 - val_loss: 56.8004\n",
      "Epoch 380/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 45.8556 - val_loss: 56.7801\n",
      "Epoch 381/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 45.8218 - val_loss: 56.7740\n",
      "Epoch 382/5000\n",
      "1126/1126 [==============================] - 0s 46us/step - loss: 45.8171 - val_loss: 56.7207\n",
      "Epoch 383/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 45.7930 - val_loss: 56.7179\n",
      "Epoch 384/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 45.7667 - val_loss: 56.7074\n",
      "Epoch 385/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 45.7472 - val_loss: 56.6968\n",
      "Epoch 386/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 45.7313 - val_loss: 56.6963\n",
      "Epoch 387/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 45.6928 - val_loss: 56.6934\n",
      "Epoch 388/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 45.6805 - val_loss: 56.6684\n",
      "Epoch 389/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 45.6593 - val_loss: 56.6347\n",
      "Epoch 390/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 45.6295 - val_loss: 56.6349\n",
      "Epoch 391/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 45.6208 - val_loss: 56.6308\n",
      "Epoch 392/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 45.5919 - val_loss: 56.6144\n",
      "Epoch 393/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 45.5801 - val_loss: 56.6139\n",
      "Epoch 394/5000\n",
      "1126/1126 [==============================] - 0s 44us/step - loss: 45.5599 - val_loss: 56.6011\n",
      "Epoch 395/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 45.5378 - val_loss: 56.5635\n",
      "Epoch 396/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 45.5145 - val_loss: 56.5560\n",
      "Epoch 397/5000\n",
      "1126/1126 [==============================] - 0s 42us/step - loss: 45.4866 - val_loss: 56.5209\n",
      "Epoch 398/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 45.4796 - val_loss: 56.5383\n",
      "Epoch 399/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 45.4596 - val_loss: 56.5329\n",
      "Epoch 400/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 45.4381 - val_loss: 56.5645\n",
      "Epoch 401/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 45.4232 - val_loss: 56.5039\n",
      "Epoch 402/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 45.3881 - val_loss: 56.4966\n",
      "Epoch 403/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 45.3692 - val_loss: 56.4749\n",
      "Epoch 404/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 45.3488 - val_loss: 56.4591\n",
      "Epoch 405/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 45.3307 - val_loss: 56.4540\n",
      "Epoch 406/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 45.3179 - val_loss: 56.4446\n",
      "Epoch 407/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 45.2942 - val_loss: 56.4500\n",
      "Epoch 408/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 45.2788 - val_loss: 56.4423\n",
      "Epoch 409/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 45.2530 - val_loss: 56.4291\n",
      "Epoch 410/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 45.2328 - val_loss: 56.3941\n",
      "Epoch 411/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 45.2176 - val_loss: 56.3766\n",
      "Epoch 412/5000\n",
      "1126/1126 [==============================] - 0s 41us/step - loss: 45.1939 - val_loss: 56.3730\n",
      "Epoch 413/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 45.1825 - val_loss: 56.3780\n",
      "Epoch 414/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 45.1715 - val_loss: 56.3587\n",
      "Epoch 415/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 45.1349 - val_loss: 56.3602\n",
      "Epoch 416/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 45.1388 - val_loss: 56.3215\n",
      "Epoch 417/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 45.1035 - val_loss: 56.3011\n",
      "Epoch 418/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 45.0902 - val_loss: 56.2861\n",
      "Epoch 419/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 45.0759 - val_loss: 56.2464\n",
      "Epoch 420/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 45.0555 - val_loss: 56.2225\n",
      "Epoch 421/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 45.0358 - val_loss: 56.2055\n",
      "Epoch 422/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 45.0196 - val_loss: 56.1846\n",
      "Epoch 423/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.9943 - val_loss: 56.1614\n",
      "Epoch 424/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.9736 - val_loss: 56.1664\n",
      "Epoch 425/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.9657 - val_loss: 56.1699\n",
      "Epoch 426/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.9360 - val_loss: 56.1318\n",
      "Epoch 427/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.9193 - val_loss: 56.1256\n",
      "Epoch 428/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.9088 - val_loss: 56.1075\n",
      "Epoch 429/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.8877 - val_loss: 56.0905\n",
      "Epoch 430/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.8817 - val_loss: 56.0612\n",
      "Epoch 431/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.8619 - val_loss: 56.0579\n",
      "Epoch 432/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.8416 - val_loss: 56.0493\n",
      "Epoch 433/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.8117 - val_loss: 56.0272\n",
      "Epoch 434/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 44.8029 - val_loss: 56.0218\n",
      "Epoch 435/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.7918 - val_loss: 55.9914\n",
      "Epoch 436/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.7646 - val_loss: 55.9838\n",
      "Epoch 437/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.7525 - val_loss: 56.0340\n",
      "Epoch 438/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 44.7409 - val_loss: 55.9996\n",
      "Epoch 439/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.7190 - val_loss: 55.9902\n",
      "Epoch 440/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.7024 - val_loss: 55.9971\n",
      "Epoch 441/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 44.6792 - val_loss: 56.0030\n",
      "Epoch 442/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.6764 - val_loss: 55.9664\n",
      "Epoch 443/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 44.6608 - val_loss: 55.9390\n",
      "Epoch 444/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 44.6422 - val_loss: 55.9424\n",
      "Epoch 445/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 44.6241 - val_loss: 55.9191\n",
      "Epoch 446/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 44.6034 - val_loss: 55.9027\n",
      "Epoch 447/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 44.5840 - val_loss: 55.9092\n",
      "Epoch 448/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 44.5838 - val_loss: 55.9060\n",
      "Epoch 449/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 44.5698 - val_loss: 55.8921\n",
      "Epoch 450/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 44.5437 - val_loss: 55.9207\n",
      "Epoch 451/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.5335 - val_loss: 55.8921\n",
      "Epoch 452/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.5253 - val_loss: 55.8573\n",
      "Epoch 453/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.4921 - val_loss: 55.8383\n",
      "Epoch 454/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.4768 - val_loss: 55.8317\n",
      "Epoch 455/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.4651 - val_loss: 55.8082\n",
      "Epoch 456/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.4555 - val_loss: 55.8023\n",
      "Epoch 457/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.4419 - val_loss: 55.7884\n",
      "Epoch 458/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.4253 - val_loss: 55.7713\n",
      "Epoch 459/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.4106 - val_loss: 55.7488\n",
      "Epoch 460/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.3872 - val_loss: 55.7410\n",
      "Epoch 461/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.3838 - val_loss: 55.7286\n",
      "Epoch 462/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.3596 - val_loss: 55.7300\n",
      "Epoch 463/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.3479 - val_loss: 55.7078\n",
      "Epoch 464/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.3415 - val_loss: 55.7007\n",
      "Epoch 465/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.3213 - val_loss: 55.6793\n",
      "Epoch 466/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.3029 - val_loss: 55.6624\n",
      "Epoch 467/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 44.2860 - val_loss: 55.6638\n",
      "Epoch 468/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 44.2776 - val_loss: 55.6479\n",
      "Epoch 469/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 44.2659 - val_loss: 55.6449\n",
      "Epoch 470/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 44.2534 - val_loss: 55.6171\n",
      "Epoch 471/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 44.2413 - val_loss: 55.5989\n",
      "Epoch 472/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.2201 - val_loss: 55.5920\n",
      "Epoch 473/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 44.2149 - val_loss: 55.5729\n",
      "Epoch 474/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 44.1989 - val_loss: 55.5590\n",
      "Epoch 475/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.1848 - val_loss: 55.5385\n",
      "Epoch 476/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.1643 - val_loss: 55.5387\n",
      "Epoch 477/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.1534 - val_loss: 55.5325\n",
      "Epoch 478/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 44.1423 - val_loss: 55.5292\n",
      "Epoch 479/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 44.1205 - val_loss: 55.5224\n",
      "Epoch 480/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 44.1111 - val_loss: 55.5140\n",
      "Epoch 481/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 44.0960 - val_loss: 55.5043\n",
      "Epoch 482/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 44.0807 - val_loss: 55.5042\n",
      "Epoch 483/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 44.0679 - val_loss: 55.4944\n",
      "Epoch 484/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 44.0477 - val_loss: 55.4796\n",
      "Epoch 485/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 44.0466 - val_loss: 55.4795\n",
      "Epoch 486/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 44.0228 - val_loss: 55.4550\n",
      "Epoch 487/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 44.0080 - val_loss: 55.4582\n",
      "Epoch 488/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 43.9953 - val_loss: 55.4540\n",
      "Epoch 489/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.9870 - val_loss: 55.4540\n",
      "Epoch 490/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.9799 - val_loss: 55.4392\n",
      "Epoch 491/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 43.9766 - val_loss: 55.4270\n",
      "Epoch 492/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.9473 - val_loss: 55.4146\n",
      "Epoch 493/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 43.9341 - val_loss: 55.4097\n",
      "Epoch 494/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.9173 - val_loss: 55.4142\n",
      "Epoch 495/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.9100 - val_loss: 55.4097\n",
      "Epoch 496/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.8958 - val_loss: 55.4112\n",
      "Epoch 497/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.8798 - val_loss: 55.3972\n",
      "Epoch 498/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.8643 - val_loss: 55.3868\n",
      "Epoch 499/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 43.8561 - val_loss: 55.3917\n",
      "Epoch 500/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 43.8438 - val_loss: 55.3747\n",
      "Epoch 501/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 43.8322 - val_loss: 55.3455\n",
      "Epoch 502/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 43.8129 - val_loss: 55.3406\n",
      "Epoch 503/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 43.8040 - val_loss: 55.3255\n",
      "Epoch 504/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 43.7903 - val_loss: 55.2992\n",
      "Epoch 505/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 43.7856 - val_loss: 55.2811\n",
      "Epoch 506/5000\n",
      "1126/1126 [==============================] - 0s 47us/step - loss: 43.7671 - val_loss: 55.2702\n",
      "Epoch 507/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 43.7544 - val_loss: 55.2556\n",
      "Epoch 508/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 43.7437 - val_loss: 55.2566\n",
      "Epoch 509/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 43.7331 - val_loss: 55.2294\n",
      "Epoch 510/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.7105 - val_loss: 55.2198\n",
      "Epoch 511/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.6965 - val_loss: 55.2308\n",
      "Epoch 512/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.6856 - val_loss: 55.2279\n",
      "Epoch 513/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.6736 - val_loss: 55.2222\n",
      "Epoch 514/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 43.6630 - val_loss: 55.2175\n",
      "Epoch 515/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.6496 - val_loss: 55.2083\n",
      "Epoch 516/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.6395 - val_loss: 55.1972\n",
      "Epoch 517/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.6296 - val_loss: 55.1842\n",
      "Epoch 518/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.6131 - val_loss: 55.1750\n",
      "Epoch 519/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 43.5960 - val_loss: 55.1622\n",
      "Epoch 520/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.5906 - val_loss: 55.1631\n",
      "Epoch 521/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 43.5824 - val_loss: 55.1630\n",
      "Epoch 522/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.5595 - val_loss: 55.1662\n",
      "Epoch 523/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.5448 - val_loss: 55.1426\n",
      "Epoch 524/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.5455 - val_loss: 55.1365\n",
      "Epoch 525/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 43.5264 - val_loss: 55.1365\n",
      "Epoch 526/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 35us/step - loss: 43.5232 - val_loss: 55.1197\n",
      "Epoch 527/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 43.5063 - val_loss: 55.1113\n",
      "Epoch 528/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 43.4902 - val_loss: 55.1563\n",
      "Epoch 529/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.4879 - val_loss: 55.1344\n",
      "Epoch 530/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.4743 - val_loss: 55.1227\n",
      "Epoch 531/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.4659 - val_loss: 55.1012\n",
      "Epoch 532/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.4500 - val_loss: 55.0935\n",
      "Epoch 533/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.4328 - val_loss: 55.0824\n",
      "Epoch 534/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.4160 - val_loss: 55.0718\n",
      "Epoch 535/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 43.4004 - val_loss: 55.0731\n",
      "Epoch 536/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 43.3948 - val_loss: 55.0677\n",
      "Epoch 537/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 43.3936 - val_loss: 55.0438\n",
      "Epoch 538/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 43.3730 - val_loss: 55.0266\n",
      "Epoch 539/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 43.3650 - val_loss: 55.0206\n",
      "Epoch 540/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.3490 - val_loss: 55.0188\n",
      "Epoch 541/5000\n",
      "1126/1126 [==============================] - 0s 30us/step - loss: 43.3363 - val_loss: 55.0270\n",
      "Epoch 542/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.3277 - val_loss: 55.0234\n",
      "Epoch 543/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 43.3097 - val_loss: 55.0302\n",
      "Epoch 544/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.3045 - val_loss: 55.0202\n",
      "Epoch 545/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 43.2850 - val_loss: 55.0237\n",
      "Epoch 546/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 43.2687 - val_loss: 55.0216\n",
      "Epoch 547/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 43.2776 - val_loss: 55.0309\n",
      "Epoch 548/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 43.2643 - val_loss: 55.0291\n",
      "Epoch 549/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 43.2470 - val_loss: 55.0239\n",
      "Epoch 550/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 43.2357 - val_loss: 55.0121\n",
      "Epoch 551/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 43.2176 - val_loss: 55.0061\n",
      "Epoch 552/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 43.2120 - val_loss: 55.0073\n",
      "Epoch 553/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 43.1999 - val_loss: 55.0026\n",
      "Epoch 554/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 43.1996 - val_loss: 54.9867\n",
      "Epoch 555/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 43.1750 - val_loss: 54.9735\n",
      "Epoch 556/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.1707 - val_loss: 54.9717\n",
      "Epoch 557/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.1546 - val_loss: 54.9593\n",
      "Epoch 558/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.1388 - val_loss: 54.9545\n",
      "Epoch 559/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.1328 - val_loss: 54.9387\n",
      "Epoch 560/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.1277 - val_loss: 54.9338\n",
      "Epoch 561/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.1080 - val_loss: 54.9199\n",
      "Epoch 562/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.0960 - val_loss: 54.9009\n",
      "Epoch 563/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.0845 - val_loss: 54.9270\n",
      "Epoch 564/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.0840 - val_loss: 54.9062\n",
      "Epoch 565/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.0745 - val_loss: 54.9115\n",
      "Epoch 566/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 43.0594 - val_loss: 54.9103\n",
      "Epoch 567/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 43.0433 - val_loss: 54.8840\n",
      "Epoch 568/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 43.0284 - val_loss: 54.8581\n",
      "Epoch 569/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 43.0283 - val_loss: 54.8463\n",
      "Epoch 570/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.0105 - val_loss: 54.8456\n",
      "Epoch 571/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 43.0030 - val_loss: 54.8327\n",
      "Epoch 572/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 42.9883 - val_loss: 54.8271\n",
      "Epoch 573/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.9916 - val_loss: 54.8252\n",
      "Epoch 574/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.9690 - val_loss: 54.8373\n",
      "Epoch 575/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.9609 - val_loss: 54.8315\n",
      "Epoch 576/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.9458 - val_loss: 54.8272\n",
      "Epoch 577/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.9363 - val_loss: 54.8690\n",
      "Epoch 578/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 42.9222 - val_loss: 54.8346\n",
      "Epoch 579/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.9137 - val_loss: 54.8261\n",
      "Epoch 580/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 42.8940 - val_loss: 54.8036\n",
      "Epoch 581/5000\n",
      "1126/1126 [==============================] - 0s 43us/step - loss: 42.8924 - val_loss: 54.7903\n",
      "Epoch 582/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.8863 - val_loss: 54.7795\n",
      "Epoch 583/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 42.8649 - val_loss: 54.7700\n",
      "Epoch 584/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 42.8554 - val_loss: 54.7595\n",
      "Epoch 585/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 42.8481 - val_loss: 54.7615\n",
      "Epoch 586/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.8446 - val_loss: 54.7467\n",
      "Epoch 587/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.8207 - val_loss: 54.7437\n",
      "Epoch 588/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.8089 - val_loss: 54.7360\n",
      "Epoch 589/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 42.8088 - val_loss: 54.7268\n",
      "Epoch 590/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.7904 - val_loss: 54.7219\n",
      "Epoch 591/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 42.7830 - val_loss: 54.7197\n",
      "Epoch 592/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 42.7807 - val_loss: 54.7101\n",
      "Epoch 593/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 42.7603 - val_loss: 54.7078\n",
      "Epoch 594/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 42.7494 - val_loss: 54.7080\n",
      "Epoch 595/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.7410 - val_loss: 54.7050\n",
      "Epoch 596/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.7300 - val_loss: 54.6950\n",
      "Epoch 597/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.7273 - val_loss: 54.6843\n",
      "Epoch 598/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 42.7122 - val_loss: 54.6769\n",
      "Epoch 599/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.7033 - val_loss: 54.6691\n",
      "Epoch 600/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.6907 - val_loss: 54.6555\n",
      "Epoch 601/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.6968 - val_loss: 54.6528\n",
      "Epoch 602/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.6669 - val_loss: 54.6333\n",
      "Epoch 603/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 42.6513 - val_loss: 54.6341\n",
      "Epoch 604/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 42.6408 - val_loss: 54.6263\n",
      "Epoch 605/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.6349 - val_loss: 54.6138\n",
      "Epoch 606/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.6231 - val_loss: 54.6181\n",
      "Epoch 607/5000\n",
      "1126/1126 [==============================] - ETA: 0s - loss: 21.07 - 0s 32us/step - loss: 42.6140 - val_loss: 54.6132\n",
      "Epoch 608/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 42.6005 - val_loss: 54.6123\n",
      "Epoch 609/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 42.5865 - val_loss: 54.6091\n",
      "Epoch 610/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 42.5823 - val_loss: 54.5978\n",
      "Epoch 611/5000\n",
      "1126/1126 [==============================] - 0s 43us/step - loss: 42.5758 - val_loss: 54.5733\n",
      "Epoch 612/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 42.5700 - val_loss: 54.5441\n",
      "Epoch 613/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 42.5393 - val_loss: 54.5331\n",
      "Epoch 614/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 42.5461 - val_loss: 54.5313\n",
      "Epoch 615/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 42.5430 - val_loss: 54.5392\n",
      "Epoch 616/5000\n",
      "1126/1126 [==============================] - 0s 49us/step - loss: 42.5260 - val_loss: 54.5315\n",
      "Epoch 617/5000\n",
      "1126/1126 [==============================] - 0s 41us/step - loss: 42.5111 - val_loss: 54.5257\n",
      "Epoch 618/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 42.5011 - val_loss: 54.5215\n",
      "Epoch 619/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.4870 - val_loss: 54.5110\n",
      "Epoch 620/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.4719 - val_loss: 54.5352\n",
      "Epoch 621/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.4732 - val_loss: 54.5246\n",
      "Epoch 622/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.4495 - val_loss: 54.5150\n",
      "Epoch 623/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.4449 - val_loss: 54.5137\n",
      "Epoch 624/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.4389 - val_loss: 54.4990\n",
      "Epoch 625/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.4235 - val_loss: 54.4935\n",
      "Epoch 626/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 42.4103 - val_loss: 54.4910\n",
      "Epoch 627/5000\n",
      "1126/1126 [==============================] - 0s 43us/step - loss: 42.3986 - val_loss: 54.4988\n",
      "Epoch 628/5000\n",
      "1126/1126 [==============================] - 0s 45us/step - loss: 42.3939 - val_loss: 54.5016\n",
      "Epoch 629/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.3811 - val_loss: 54.4838\n",
      "Epoch 630/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.3710 - val_loss: 54.4806\n",
      "Epoch 631/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.3589 - val_loss: 54.4879\n",
      "Epoch 632/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.3561 - val_loss: 54.4765\n",
      "Epoch 633/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.3461 - val_loss: 54.4506\n",
      "Epoch 634/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.3327 - val_loss: 54.4463\n",
      "Epoch 635/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.3177 - val_loss: 54.4419\n",
      "Epoch 636/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.3057 - val_loss: 54.4251\n",
      "Epoch 637/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.2935 - val_loss: 54.4265\n",
      "Epoch 638/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.2781 - val_loss: 54.4241\n",
      "Epoch 639/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.2659 - val_loss: 54.4079\n",
      "Epoch 640/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.2651 - val_loss: 54.3970\n",
      "Epoch 641/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.2488 - val_loss: 54.3868\n",
      "Epoch 642/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 42.2474 - val_loss: 54.3766\n",
      "Epoch 643/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 42.2319 - val_loss: 54.3791\n",
      "Epoch 644/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 42.2260 - val_loss: 54.3730\n",
      "Epoch 645/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 42.2102 - val_loss: 54.3741\n",
      "Epoch 646/5000\n",
      "1126/1126 [==============================] - 0s 46us/step - loss: 42.1961 - val_loss: 54.3830\n",
      "Epoch 647/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.1869 - val_loss: 54.3845\n",
      "Epoch 648/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.1800 - val_loss: 54.3781\n",
      "Epoch 649/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.1719 - val_loss: 54.3734\n",
      "Epoch 650/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.1565 - val_loss: 54.3784\n",
      "Epoch 651/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 42.1411 - val_loss: 54.3562\n",
      "Epoch 652/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 42.1345 - val_loss: 54.3420\n",
      "Epoch 653/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.1274 - val_loss: 54.3334\n",
      "Epoch 654/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.1149 - val_loss: 54.3178\n",
      "Epoch 655/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 42.1023 - val_loss: 54.3174\n",
      "Epoch 656/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.1053 - val_loss: 54.3039\n",
      "Epoch 657/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.0777 - val_loss: 54.3161\n",
      "Epoch 658/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.0747 - val_loss: 54.3073\n",
      "Epoch 659/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.0625 - val_loss: 54.2892\n",
      "Epoch 660/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.0537 - val_loss: 54.2681\n",
      "Epoch 661/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.0436 - val_loss: 54.3053\n",
      "Epoch 662/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.0409 - val_loss: 54.3023\n",
      "Epoch 663/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.0241 - val_loss: 54.2791\n",
      "Epoch 664/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 42.0263 - val_loss: 54.2728\n",
      "Epoch 665/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 42.0052 - val_loss: 54.2738\n",
      "Epoch 666/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 41.9950 - val_loss: 54.2451\n",
      "Epoch 667/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 41.9951 - val_loss: 54.2380\n",
      "Epoch 668/5000\n",
      "1126/1126 [==============================] - 0s 31us/step - loss: 41.9755 - val_loss: 54.2283\n",
      "Epoch 669/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 41.9606 - val_loss: 54.2044\n",
      "Epoch 670/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 41.9572 - val_loss: 54.1967\n",
      "Epoch 671/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 41.9463 - val_loss: 54.1888\n",
      "Epoch 672/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 41.9341 - val_loss: 54.1916\n",
      "Epoch 673/5000\n",
      "1126/1126 [==============================] - 0s 39us/step - loss: 41.9250 - val_loss: 54.1781\n",
      "Epoch 674/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 41.9199 - val_loss: 54.1784\n",
      "Epoch 675/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 41.9027 - val_loss: 54.1652\n",
      "Epoch 676/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126/1126 [==============================] - 0s 34us/step - loss: 41.8983 - val_loss: 54.1646\n",
      "Epoch 677/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 41.8937 - val_loss: 54.1603\n",
      "Epoch 678/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 41.8754 - val_loss: 54.1591\n",
      "Epoch 679/5000\n",
      "1126/1126 [==============================] - 0s 40us/step - loss: 41.8722 - val_loss: 54.1607\n",
      "Epoch 680/5000\n",
      "1126/1126 [==============================] - 0s 37us/step - loss: 41.8533 - val_loss: 54.1431\n",
      "Epoch 681/5000\n",
      "1126/1126 [==============================] - 0s 36us/step - loss: 41.8378 - val_loss: 54.1509\n",
      "Epoch 682/5000\n",
      "1126/1126 [==============================] - 0s 38us/step - loss: 41.8320 - val_loss: 54.1534\n",
      "Epoch 683/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 41.8238 - val_loss: 54.1358\n",
      "Epoch 684/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 41.8196 - val_loss: 54.1366\n",
      "Epoch 685/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 41.8037 - val_loss: 54.1136\n",
      "Epoch 686/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 41.7963 - val_loss: 54.1179\n",
      "Epoch 687/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 41.7826 - val_loss: 54.1022\n",
      "Epoch 688/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 41.7747 - val_loss: 54.0839\n",
      "Epoch 689/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 41.7746 - val_loss: 54.0936\n",
      "Epoch 690/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 41.7494 - val_loss: 54.1151\n",
      "Epoch 691/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 41.7529 - val_loss: 54.1108\n",
      "Epoch 692/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 41.7357 - val_loss: 54.1100\n",
      "Epoch 693/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 41.7318 - val_loss: 54.1059\n",
      "Epoch 694/5000\n",
      "1126/1126 [==============================] - 0s 34us/step - loss: 41.7118 - val_loss: 54.0996\n",
      "Epoch 695/5000\n",
      "1126/1126 [==============================] - 0s 32us/step - loss: 41.7014 - val_loss: 54.0894\n",
      "Epoch 696/5000\n",
      "1126/1126 [==============================] - 0s 35us/step - loss: 41.6999 - val_loss: 54.0887\n",
      "Epoch 697/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 41.6904 - val_loss: 54.1303\n",
      "Epoch 698/5000\n",
      "1126/1126 [==============================] - 0s 33us/step - loss: 41.6807 - val_loss: 54.1315\n",
      "Epoch 00698: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, mode='auto', patience=10)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=5000, validation_data=(X_valid, y_valid), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4748279a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/H+tvoYkofY5gQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4748203fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "plt.title('Coût et coût de validation')\n",
    "line1,=plt.plot(history.history['loss'], label=\"Loss\", linestyle='-', color='r')\n",
    "line2,=plt.plot(history.history['val_loss'], label=\"Val loss\", linestyle='-', color='b')\n",
    "first_legend = plt.legend(handles=[line1, line2], loc=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.title('y_pred en fonction de y_test')\n",
    "\n",
    "plt.plot(y_pred[:], y_test[:], '+')\n",
    "plt.ylabel('Test')\n",
    "plt.xlabel('Prédiction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
